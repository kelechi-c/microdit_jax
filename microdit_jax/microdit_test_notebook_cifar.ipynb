{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIOS8m-3hkT1",
        "outputId": "8f40b74f-f1ba-4894-8041-02804a12fd92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/480.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m471.0/480.6 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/116.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "! pip install jax flax einops diffusers transformers datasets wandb tqdm numpy -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "2c38a75b7eb1447c81610e43c507dcd6",
            "19c1bee13d9647468555c4b04d4ae166",
            "c1127e9a09ee429eb320429dac03f32c",
            "2fed7e9265d44ffa9f62987502013fcd",
            "028272169cc24756b0dd515348038cf7",
            "d8186960486b4662b41a5ddbc5a9d2c6",
            "0d499f7caab2472aa08debe5c8cf2ee8",
            "5accd3e7541f4a89bcf05b916f064bd5",
            "ded02ace9cea4e639dd3ceab36899aaa",
            "a5a3b162c9cc4c0b882aa1def06a77df",
            "dea114a4d9c348be8898e7a61aa2d224"
          ]
        },
        "id": "6vuI7Wq6hkT3",
        "outputId": "2cbad199-5352-434c-c0c1-5a2daa7fdf8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2c38a75b7eb1447c81610e43c507dcd6"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import jax, math, flax, cv2\n",
        "import os, wandb, time, optax\n",
        "from jax import Array, numpy as jnp, random as jrand\n",
        "import numpy as np\n",
        "from flax import nnx\n",
        "from einops import rearrange\n",
        "from tqdm.auto import tqdm\n",
        "from typing import List, Tuple\n",
        "from functools import partial\n",
        "# from diffusers import AutoencoderKL\n",
        "from datasets import load_dataset\n",
        "from torch.utils.data import DataLoader, IterableDataset\n",
        "from collections import namedtuple\n",
        "import flax.traverse_util\n",
        "from flax.serialization import to_state_dict\n",
        "import safetensors.flax as safejax\n",
        "from PIL import Image as pillow\n",
        "from diffusers.models.autoencoders.autoencoder_kl import AutoencoderKL\n",
        "# from transformers import AutoTokenizer, T5EncoderModel\n",
        "from urllib.request import urlopen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZX8CfdNJhkT5",
        "outputId": "45add57d-af7b-4c1a-a38c-a6837f44360b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "found 1 JAX devices => [CudaDevice(id=0)]\n",
            "cuda:0 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "rkey = jrand.key(3)\n",
        "rngs = nnx.Rngs(3)\n",
        "randkey = jrand.key(3)\n",
        "\n",
        "num_devices = jax.device_count()\n",
        "devices = jax.devices()\n",
        "print(f\"found {num_devices} JAX devices => {devices}\")\n",
        "for device in devices:\n",
        "    print(f\"{device} \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "InQBQ3vchkT7"
      },
      "outputs": [],
      "source": [
        "class config:\n",
        "    vaescale_factor = 0.13025\n",
        "    batch_size = 128\n",
        "    img_size = 32\n",
        "    patch_size = (4, 4)\n",
        "    lr = 1e-4\n",
        "    mask_ratio = 0.75\n",
        "    epochs = 5\n",
        "    data_split = 10_000\n",
        "    cfg_scale = 2.0\n",
        "    vae_channels = 4\n",
        "    celebv_id = \"SwayStar123/CelebV-HQ\"\n",
        "    finevid_id = \"HuggingFaceFV/finevideo\"\n",
        "    pd12_id = \"Spawning/PD12M\"\n",
        "    vae_id = \"madebyollin/sdxl-vae-fp16-fix\"\n",
        "    t5_id = \"google-t5/t5-small\"\n",
        "    mini_data_id = \"uoft-cs/cifar10\"\n",
        "    device_0 = jax.default_device()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gMM87VZ4hkT9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "XSc-5AIAhkT-"
      },
      "outputs": [],
      "source": [
        "# jax/numpy implementation of topk selection\n",
        "def jnp_topk(array: Array, k: int):\n",
        "    topk_tuple = namedtuple(\"topk\", [\"values\", \"ids\"])\n",
        "    array = jnp.asarray(array)\n",
        "    flat = array.ravel()\n",
        "\n",
        "    sort_indices = jnp.argpartition(flat, -k)[-k:]\n",
        "    argsort = jnp.argsort(-flat[sort_indices])  # get sorting ids\n",
        "\n",
        "    sort_idx = sort_indices[argsort]\n",
        "    values = flat[sort_idx]\n",
        "\n",
        "    idx = jnp.unravel_index(sort_idx, array.shape)\n",
        "\n",
        "    if len(idx) == 1:\n",
        "        (idx,) = idx\n",
        "\n",
        "    return topk_tuple(values=values, ids=idx)\n",
        "\n",
        "\n",
        "# save model params in safetensors file\n",
        "def save_model(model: nnx.Module, file: str, dtype):\n",
        "    _, state = nnx.split(model)\n",
        "    params = state.filter(nnx.Param)\n",
        "    state_dict = to_state_dict(params)\n",
        "\n",
        "    state_dict = flax.traverse_util.flatten_dict(state_dict, sep=\".\")\n",
        "\n",
        "    for key in list(state_dict.keys()):\n",
        "        if not isinstance(state_dict[key], Array):\n",
        "            state_dict[key] = jnp.array(state_dict[key])  # type: ignore\n",
        "\n",
        "        state_dict[key] = state_dict[key].astype(dtype)  # type: ignore\n",
        "\n",
        "    safejax.save_file(state_dict, file)  # type: ignore\n",
        "\n",
        "\n",
        "def apply_mask(x: Array, mask, patch_size):\n",
        "    # basically turns the masked values to 0s\n",
        "    bs, c, h, w = x.shape\n",
        "    numpatch_h = h // patch_size[0]\n",
        "    numpatch_w = w // patch_size[1]\n",
        "\n",
        "    mask = jnp.reshape(mask, shape=(bs, numpatch_h, numpatch_w))\n",
        "\n",
        "    mask = jnp.expand_dims(mask, axis=1)\n",
        "    mask = jnp.tile(mask, reps=(1, 1, patch_size[0], patch_size[1]))\n",
        "    mask = jnp.reshape(mask, shape=(bs, 1, h, w))\n",
        "\n",
        "    x_masked = x * mask\n",
        "\n",
        "    return x_masked\n",
        "\n",
        "\n",
        "def random_mask(bs, height, width, patch_size, mask_ratio):\n",
        "    num_patches = (height // patch_size[0]) * (width // patch_size[1])\n",
        "    num_patches_to_mask = int(num_patches * mask_ratio)\n",
        "\n",
        "    rand_array = jrand.normal(randkey, shape=(bs, num_patches))\n",
        "    indices = jnp.argsort(rand_array, axis=1)\n",
        "\n",
        "    mask = jnp.ones(shape=(bs, num_patches))\n",
        "\n",
        "    batch_mask_array = jnp.expand_dims(jnp.arange(bs), axis=1)\n",
        "    # mask[batch_mask_array, indices[:, :num_patches_to_mask]] = 0\n",
        "    new_mask = mask.at[batch_mask_array, indices[:, :num_patches_to_mask]].set(0)\n",
        "    mask = new_mask\n",
        "    mask = jnp.reshape(mask, shape=(bs, num_patches))\n",
        "\n",
        "    return mask\n",
        "\n",
        "\n",
        "def remove_masked_patches(patches: Array, mask: Array):\n",
        "    mask = jnp.logical_not(jnp.bool(mask))\n",
        "\n",
        "    bs, num_patches, embed_dim = patches.shape\n",
        "    mask = jnp.expand_dims(mask, axis=-1)\n",
        "    mask = jnp.broadcast_to(mask, shape=(-1, -1, embed_dim))\n",
        "    mask_ids = jnp.nonzero(jnp.reshape(mask, (-1)))\n",
        "    unmasked_patches = jnp.reshape(patches, shape=-1)\n",
        "    unmasked_patches = jnp.take(unmasked_patches, mask_ids[0]).reshape(\n",
        "        bs, -1, embed_dim\n",
        "    )\n",
        "\n",
        "    return unmasked_patches\n",
        "\n",
        "\n",
        "def add_masked_patches(patches: Array, mask: Array):\n",
        "    # Ensure mask is a boolean tensor\n",
        "    mask = jnp.bool(mask)\n",
        "\n",
        "    bs, num_patches, embed_dim = mask.shape[0], mask.shape[1], patches.shape[-1]\n",
        "\n",
        "    # Create a tensor of zeros with the same shape and dtype as the patches tensor\n",
        "    full_patches = jnp.zeros(shape=(bs, num_patches, embed_dim))\n",
        "\n",
        "    # Iterate over each batch and place unmasked patches back in their original positions\n",
        "    for b in range(bs):\n",
        "        # Use the mask to place unmasked patches back in the correct positions\n",
        "        full_patches[b, mask[b]] = patches[b].astype(full_patches.dtype)\n",
        "\n",
        "    return full_patches\n",
        "\n",
        "\n",
        "## nov_14_0453\n",
        "\n",
        "# T5 text encoder\n",
        "# t5_tokenizer = AutoTokenizer.from_pretrained(config.t5_id)\n",
        "# t5_model = T5EncoderModel.from_pretrained(config.t5_id)\n",
        "\n",
        "\n",
        "# def text_t5_encode(text_input: str, tokenizer=t5_tokenizer, model=t5_model):\n",
        "#     input_ids = tokenizer(text_input, return_tensors=\"np\").input_ids  # Batch size 1\n",
        "#     outputs = model(input_ids=input_ids)\n",
        "#     last_hidden_states = outputs.last_hidden_state\n",
        "\n",
        "#     return last_hidden_states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "rZ8sw2u2hkUC"
      },
      "outputs": [],
      "source": [
        "## data loading\n",
        "image_data = load_dataset(\n",
        "    config.mini_data_id, streaming=True, split=\"train\", trust_remote_code=True\n",
        ").take(config.data_split)\n",
        "\n",
        "vae = AutoencoderKL.from_pretrained(config.vae_id)#.to(config.device_0)\n",
        "\n",
        "def load_image(image):\n",
        "    # image = pillow.open(urlopen(url=url))\n",
        "    img_array = np.array(image)\n",
        "    resized = cv2.resize(img_array, dsize=(config.img_size, config.img_size))\n",
        "\n",
        "    return resized / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9oc8B6QohkUE",
        "outputId": "f957a7b3-9e00-4f8d-a73d-09bd5b88024c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "import torch\n",
        "randkey = jrand.key(3)\n",
        "\n",
        "\n",
        "# class ImageData(IterableDataset):\n",
        "#     def __init__(self, dataset=image_data):\n",
        "#         super().__init__()\n",
        "#         self.dataset = dataset\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return config.data_split\n",
        "\n",
        "#     def __iter__(self):\n",
        "#         for sample in self.dataset:\n",
        "#             image = sample[\"img_url\"]  # type: ignore\n",
        "#             image = load_image(image)\n",
        "#             img_latents = vae.encode(image)\n",
        "#             img_latents = img_latents.numpy()\n",
        "#             caption_encoded = text_t5_encode(sample[\"caption\"])  # type: ignore\n",
        "\n",
        "#             image = jnp.array(image)\n",
        "#             text_encoding = jnp.array(caption_encoded)\n",
        "\n",
        "#             yield image, text_encoding\n",
        "\n",
        "\n",
        "class ImageClassData(IterableDataset):\n",
        "    def __init__(self, dataset=image_data):\n",
        "        super().__init__()\n",
        "        self.dataset = dataset\n",
        "\n",
        "    def __len__(self):\n",
        "        return config.data_split\n",
        "\n",
        "    def __iter__(self):\n",
        "        for sample in self.dataset:\n",
        "            image = sample[\"img\"]  # type: ignore\n",
        "            image = load_image(image)\n",
        "            # img_latents = vae.encode(torch.tensor(image))\n",
        "            # img_latents = img_latents.\n",
        "\n",
        "            image = jnp.array(image)\n",
        "            label = jnp.array(sample[\"label\"])\n",
        "\n",
        "            yield image, label\n",
        "\n",
        "def jax_collate(batch):\n",
        "    images, labels = zip(*batch)\n",
        "    batch = (jnp.array(images), jnp.array(labels))\n",
        "    batch = jax.tree_util.tree_map(jnp.array, batch)\n",
        "\n",
        "    return batch\n",
        "\n",
        "dataset = ImageClassData()\n",
        "\n",
        "train_loader = DataLoader(dataset, batch_size=4, collate_fn=jax_collate)\n",
        "\n",
        "iv = next(iter(train_loader))\n",
        "iv[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iv[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zJDdGL_-dFE",
        "outputId": "252f78d7-d5e5-4fc9-ff65-6ffd4f05a91d"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([0, 6, 0, 2], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "o_k8aAkMhkUH"
      },
      "outputs": [],
      "source": [
        "# modulation with shift and scale\n",
        "def modulate(x_array: Array, shift, scale) -> Array:\n",
        "    x = x_array * scale.unsqueeze(1)\n",
        "    x = x + shift.unsqueeze(1)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "# equivalnet of F.lineat\n",
        "def linear(array: Array, weight: Array, bias: Array | None = None) -> Array:\n",
        "    out = jnp.dot(array, weight)\n",
        "\n",
        "    if bias is not None:\n",
        "        out += bias\n",
        "\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "se36QaX-hkUI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Svm9UMGahkUI"
      },
      "outputs": [],
      "source": [
        "# Adapted from https://github.com/facebookresearch/mae/blob/main/util/pos_embed.py\n",
        "def get_2d_sincos_pos_embed(embed_dim, grid_size, cls_token=False, extra_tokens=0):\n",
        "    \"\"\"\n",
        "    grid_size: int of the grid height and width\n",
        "    return:\n",
        "    pos_embed: [grid_size*grid_size, embed_dim] or [1+grid_size*grid_size, embed_dim] (w/ or w/o cls_token)\n",
        "    \"\"\"\n",
        "    grid_h = jnp.arange(grid_size, dtype=jnp.float32)\n",
        "    grid_w = jnp.arange(grid_size, dtype=jnp.float32)\n",
        "    grid = jnp.meshgrid(grid_w, grid_h)  # here w goes first\n",
        "    grid = jnp.stack(grid, axis=0)\n",
        "\n",
        "    grid = grid.reshape([2, 1, grid_size, grid_size])\n",
        "    pos_embed = get_2d_sincos_pos_embed_from_grid(embed_dim, grid)\n",
        "    if cls_token and extra_tokens > 0:\n",
        "        pos_embed = jnp.concatenate(\n",
        "            [jnp.zeros([extra_tokens, embed_dim]), pos_embed], axis=0\n",
        "        )\n",
        "    return pos_embed\n",
        "\n",
        "\n",
        "def get_2d_sincos_pos_embed_from_grid(embed_dim, grid):\n",
        "    assert embed_dim % 2 == 0\n",
        "\n",
        "    # use half of dimensions to encode grid_h\n",
        "    emb_h = get_1d_sincos_pos_embed_from_grid(embed_dim // 2, grid[0])  # (H*W, D/2)\n",
        "    emb_w = get_1d_sincos_pos_embed_from_grid(embed_dim // 2, grid[1])  # (H*W, D/2)\n",
        "\n",
        "    emb = jnp.concatenate([emb_h, emb_w], axis=1)  # (H*W, D)\n",
        "    return emb\n",
        "\n",
        "\n",
        "def get_1d_sincos_pos_embed_from_grid(embed_dim, pos):\n",
        "    \"\"\"\n",
        "    embed_dim: output dimension for each position\n",
        "    pos: a list of positions to be encoded: size (M,)\n",
        "    out: (M, D)\n",
        "    \"\"\"\n",
        "    assert embed_dim % 2 == 0\n",
        "    omega = jnp.arange(embed_dim // 2, dtype=jnp.float64)\n",
        "    omega /= embed_dim / 2.0\n",
        "    omega = 1.0 / 10000**omega  # (D/2,)\n",
        "\n",
        "    pos = pos.reshape(-1)  # (M,)\n",
        "    out = jnp.einsum(\"m,d->md\", pos, omega)  # (M, D/2), outer product\n",
        "\n",
        "    emb_sin = jnp.sin(out)  # (M, D/2)\n",
        "    emb_cos = jnp.cos(out)  # (M, D/2)\n",
        "\n",
        "    emb = jnp.concatenate([emb_sin, emb_cos], axis=1)  # (M, D)\n",
        "\n",
        "    return emb"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jjNQSobC-647"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTK2dh1whkUJ",
        "outputId": "eb881e01-dbc0-47da-b0d6-b0b2d1a19d1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "patchembed shape => (4, 49152)\n"
          ]
        }
      ],
      "source": [
        "# input patchify layer, 2D image to patches\n",
        "class PatchEmbed(nnx.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        rngs: nnx.Rngs = rngs,\n",
        "        patch_size=(4,4),\n",
        "        img_size=(32, 32),\n",
        "        in_chan: int = 3,\n",
        "        embed_dim: int = 768,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.patch_size = (patch_size, patch_size)\n",
        "        self.img_size = img_size\n",
        "        self.gridsize = tuple([s // p for s, p in zip(img_size, patch_size)])\n",
        "        self.num_patches = self.gridsize[0] * self.gridsize[1]\n",
        "        linear_init = nnx.initializers.constant(0)\n",
        "\n",
        "        self.conv_project = nnx.Conv(\n",
        "            in_chan,\n",
        "            embed_dim,\n",
        "            kernel_size=patch_size,\n",
        "            strides=patch_size,\n",
        "            rngs=rngs,\n",
        "        )\n",
        "\n",
        "    def __call__(self, img: Array) -> Array:\n",
        "        x = self.conv_project(img)\n",
        "        x = jnp.reshape(x, shape=(x.shape[0], -1))\n",
        "        print(f'patchembed shape => {x.shape}')\n",
        "        return x\n",
        "\n",
        "patchem = PatchEmbed()\n",
        "patchimg = patchem(iv[0])\n",
        "\n",
        "# embeds a flat vector\n",
        "class VectorEmbedder(nnx.Module):\n",
        "    def __init__(self, input_dim, hidden_size, rngs=rngs):\n",
        "        super().__init__()\n",
        "        self.linear_1 = nnx.Linear(input_dim, hidden_size, rngs=rngs)\n",
        "        self.linear_2 = nnx.Linear(hidden_size, hidden_size, rngs=rngs)\n",
        "\n",
        "    def __call__(self, x: Array):\n",
        "        x = nnx.silu(self.linear_1(x))\n",
        "        x = self.linear_2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class TimestepEmbedder(nnx.Module):\n",
        "    def __init__(self, hidden_size, freq_embed_size=256):\n",
        "        super().__init__()\n",
        "        self.lin_1 = nnx.Linear(freq_embed_size, hidden_size, rngs=rngs)\n",
        "        self.lin_2 = nnx.Linear(hidden_size, hidden_size, rngs=rngs)\n",
        "        self.freq_embed_size = freq_embed_size\n",
        "\n",
        "    @staticmethod\n",
        "    def timestep_embedding(time_array: Array, dim, max_period=10000):\n",
        "        half = dim // 2\n",
        "        freqs = jnp.exp(-math.log(max_period) * jnp.arange(0, half) / half).to_device(\n",
        "            time_array.device\n",
        "        )\n",
        "        args = jnp.float_(time_array[:, None]) * freqs[None]\n",
        "\n",
        "        embedding = jnp.concat([jnp.cos(args), jnp.sin(args)], axis=-1)\n",
        "        if dim % 2:\n",
        "            embedding = jnp.concat(\n",
        "                [embedding, jnp.zeros_like(embedding[:, :1])], axis=-1\n",
        "            )\n",
        "\n",
        "        return embedding\n",
        "\n",
        "    def __call__(self, x: Array) -> Array:\n",
        "        t_freq = self.timestep_embedding(x, self.freq_embed_size)\n",
        "        t_embed = nnx.silu(self.lin_1(t_freq))\n",
        "\n",
        "        return self.lin_2(t_embed)\n",
        "\n",
        "\n",
        "class LabelEmbedder(nnx.Module):\n",
        "    def __init__(self, num_classes, hidden_size, drop):\n",
        "        super().__init__()\n",
        "        use_cfg_embeddings = drop > 0\n",
        "        self.embedding_table = nnx.Embed(\n",
        "            num_classes + use_cfg_embeddings, hidden_size, rngs=rngs\n",
        "        )\n",
        "        self.num_classes = num_classes\n",
        "        self.dropout = drop\n",
        "\n",
        "    def token_drop(self, labels, force_drop_ids=None) -> Array:\n",
        "        if force_drop_ids is None:\n",
        "            drop_ids = jrand.normal(key=rkey, shape=labels.shape[0]).to_device(\n",
        "                labels.device\n",
        "            )\n",
        "        else:\n",
        "            drop_ids = force_drop_ids == 1\n",
        "\n",
        "        labels = jnp.where(drop_ids, self.num_classes, labels)\n",
        "\n",
        "        return labels\n",
        "\n",
        "    def __call__(self, labels, train: bool, force_drop_ids=None) -> Array:\n",
        "        use_drop = self.dropout > 0\n",
        "        if (train and use_drop) or (force_drop_ids is not None):\n",
        "            labels = self.token_drop(labels, force_drop_ids)\n",
        "\n",
        "        label_embeds = self.embedding_table(labels)\n",
        "\n",
        "        return label_embeds\n",
        "\n",
        "\n",
        "class CaptionEmbedder(nnx.Module):\n",
        "    def __init__(self, cap_embed_dim, embed_dim):\n",
        "        super().__init__()\n",
        "        self.linear_1 = nnx.Linear(cap_embed_dim, embed_dim, rngs=rngs)\n",
        "        self.linear_2 = nnx.Linear(embed_dim, embed_dim, rngs=rngs)\n",
        "\n",
        "    def __call__(self, x: Array) -> Array:\n",
        "        x = nnx.silu(self.linear_1(x))\n",
        "        x = self.linear_2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# self attention block\n",
        "class SelfAttention(nnx.Module):\n",
        "    def __init__(self, attn_heads, embed_dim, rngs: nnx.Rngs, drop=0.1):\n",
        "        super().__init__()\n",
        "        self.attn_heads = attn_heads\n",
        "        self.head_dim = embed_dim // attn_heads\n",
        "\n",
        "        linear_init = nnx.initializers.xavier_uniform()\n",
        "        linear_bias_init = nnx.initializers.constant(0)\n",
        "\n",
        "        self.q_linear = nnx.Linear(\n",
        "            embed_dim,\n",
        "            embed_dim,\n",
        "            rngs=rngs,\n",
        "            bias_init=linear_bias_init,\n",
        "            kernel_init=linear_init,\n",
        "        )\n",
        "        self.k_linear = nnx.Linear(embed_dim, embed_dim, rngs=rngs)\n",
        "        self.v_linear = nnx.Linear(embed_dim, embed_dim, rngs=rngs)\n",
        "\n",
        "        self.outproject = nnx.Linear(\n",
        "            embed_dim, embed_dim, rngs=rngs, bias_init=linear_bias_init\n",
        "        )\n",
        "        self.dropout = nnx.Dropout(drop, rngs=rngs)\n",
        "\n",
        "    def __call__(self, x_input: jax.Array) -> jax.Array:\n",
        "        q = self.q_linear(x_input)\n",
        "        k = self.k_linear(x_input)\n",
        "        v = self.v_linear(x_input)\n",
        "\n",
        "        q, k, v = map(\n",
        "            lambda x: rearrange(x, \"b l (h d) -> b h l d\", h=self.attn_heads), (q, k, v)\n",
        "        )\n",
        "\n",
        "        qk = q @ jnp.matrix_transpose(k)\n",
        "        attn_logits = qk / math.sqrt(self.head_dim)  # attention computation\n",
        "\n",
        "        attn_score = nnx.softmax(attn_logits, axis=-1)\n",
        "        attn_output = attn_score @ v\n",
        "\n",
        "        output = rearrange(attn_output, \"b h l d -> b l (h d)\")\n",
        "        output = self.dropout(self.outproject(output))\n",
        "        print(f\"attn out shape => {output.shape}\")\n",
        "        return output\n",
        "\n",
        "\n",
        "class CrossAttention(nnx.Module):\n",
        "    def __init__(self, attn_heads, embed_dim, cond_dim, rngs: nnx.Rngs, drop=0.1):\n",
        "        super().__init__()\n",
        "        self.attn_heads = attn_heads\n",
        "        self.head_dim = embed_dim // attn_heads\n",
        "\n",
        "        linear_init = nnx.initializers.xavier_uniform()\n",
        "        linear_bias_init = nnx.initializers.constant(0)\n",
        "\n",
        "        self.q_linear = nnx.Linear(\n",
        "            embed_dim,\n",
        "            embed_dim,\n",
        "            rngs=rngs,\n",
        "            bias_init=linear_bias_init,\n",
        "            kernel_init=linear_init,\n",
        "        )\n",
        "\n",
        "        self.k_linear = nnx.Linear(cond_dim, embed_dim, rngs=rngs)\n",
        "        self.v_linear = nnx.Linear(cond_dim, embed_dim, rngs=rngs)\n",
        "\n",
        "        self.outproject = nnx.Linear(\n",
        "            embed_dim, embed_dim, rngs=rngs, bias_init=linear_bias_init\n",
        "        )\n",
        "        self.dropout = nnx.Dropout(drop, rngs=rngs)\n",
        "\n",
        "    def __call__(self, x_input: jax.Array, y_cond: Array) -> jax.Array:\n",
        "        q = self.q_linear(x_input)\n",
        "        k = self.k_linear(y_cond)\n",
        "        v = self.v_linear(y_cond)\n",
        "\n",
        "        q, k, v = map(\n",
        "            lambda x: rearrange(x, \"b l (h d) -> b h l d\", h=self.attn_heads), (q, k, v)\n",
        "        )\n",
        "\n",
        "        qk = q @ jnp.matrix_transpose(k)\n",
        "        attn_logits = qk / math.sqrt(self.head_dim)  # attention computation\n",
        "\n",
        "        attn_score = nnx.softmax(attn_logits, axis=-1)\n",
        "        attn_output = attn_score @ v\n",
        "\n",
        "        output = rearrange(attn_output, \"b h l d -> b l (h d)\")\n",
        "        output = self.dropout(self.outproject(output))\n",
        "        print(f\"attn out shape => {output.shape}\")\n",
        "        return output\n",
        "\n",
        "\n",
        "########################\n",
        "# Patch Mixer components\n",
        "########################\n",
        "\n",
        "\n",
        "class EncoderMLP(nnx.Module):\n",
        "    def __init__(self, hidden_size, rngs: nnx.Rngs, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.layernorm = nnx.LayerNorm(hidden_size, rngs=rngs)\n",
        "\n",
        "        self.linear1 = nnx.Linear(hidden_size, 2 * hidden_size, rngs=rngs)\n",
        "        self.linear2 = nnx.Linear(2 * hidden_size, hidden_size, rngs=rngs)\n",
        "        self.dropout = nnx.Dropout(dropout, rngs=rngs)\n",
        "\n",
        "    def __call__(self, x_input: jax.Array) -> jax.Array:\n",
        "        x = self.layernorm(x_input)\n",
        "        x = nnx.silu(self.linear1(x))\n",
        "        x = self.linear2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class TransformerEncoderBlock(nnx.Module):\n",
        "    def __init__(self, embed_dim, num_heads):\n",
        "        super().__init__()\n",
        "        self.layernorm = nnx.LayerNorm(embed_dim, epsilon=1e-6, rngs=rngs)\n",
        "        self.self_attention = SelfAttention(num_heads, embed_dim, rngs=rngs)\n",
        "        self.mlp_layer = EncoderMLP(embed_dim, rngs=rngs)\n",
        "\n",
        "    def __call__(self, x: Array):\n",
        "        x = x + self.layernorm(self.self_attention(x))\n",
        "        x = x + self.layernorm(self.mlp_layer(x))\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class SimpleMLP(nnx.Module):\n",
        "    def __init__(self, embed_dim):\n",
        "        super().__init__()\n",
        "        self.linear_1 = nnx.Linear(embed_dim, embed_dim, rngs=rngs)\n",
        "        self.linear_2 = nnx.Linear(embed_dim, embed_dim, rngs=rngs)\n",
        "\n",
        "    def __call__(self, x: Array) -> Array:\n",
        "        x = nnx.silu(self.linear_1(x))\n",
        "        x = self.linear_2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "# Pool + MLP for (MHA + MLP)\n",
        "class PoolMLP(nnx.Module):\n",
        "    def __init__(self, embed_dim):\n",
        "        super().__init__()\n",
        "        self.linear_1 = nnx.Linear(embed_dim, embed_dim, rngs=rngs)\n",
        "        self.linear_2 = nnx.Linear(embed_dim, embed_dim, rngs=rngs)\n",
        "\n",
        "    def __call__(self, x: Array) -> Array:\n",
        "        x = nnx.avg_pool(x, 1, 1)\n",
        "        x = jnp.reshape(x, shape=(x.shape[0], -1))\n",
        "        x = nnx.gelu(self.linear_1(x))\n",
        "        x = self.linear_2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "#### MoE Gate\n",
        "class MoEGate(nnx.Module):\n",
        "    def __init__(\n",
        "        self, embed_dim, num_experts=8, experts_per_token=2, aux_loss_alpha=0.01\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.top_k = experts_per_token\n",
        "        self.routed_exoerts = num_experts\n",
        "        self.score_func = \"softmax\"\n",
        "        self.alpha = aux_loss_alpha\n",
        "        self.seq_aux = False\n",
        "\n",
        "        # top_k selection algo\n",
        "        self.norm_topk_prob = False\n",
        "        self.gating_dim = embed_dim\n",
        "        param_init = nnx.initializers.he_uniform()\n",
        "        self.weight = nnx.Param(jnp.empty((self.routed_exoerts, self.gating_dim)))\n",
        "        # self.linear_gate = nnx.Linear()\n",
        "\n",
        "    def __call__(self, hidden_states: Array) -> Tuple:\n",
        "        bsize, seq_len, h = hidden_states.shape\n",
        "        # gating score\n",
        "        hidden_states = jnp.reshape(hidden_states, (-1, h))\n",
        "        logits = jnp.dot(hidden_states, self.weight[\"Array\"])\n",
        "        scores = nnx.softmax(logits, axis=-1)\n",
        "\n",
        "        topk_idx, topk_weight = jax.lax.top_k(scores, k=self.top_k)\n",
        "\n",
        "        # normalize to sum to 1\n",
        "        if self.top_k > 1 and self.norm_topk_prob:\n",
        "            denominator = jnp.sum(topk_weight, axis=-1, keepdims=True) + 1e-20\n",
        "            topk_weight = topk_weight / denominator\n",
        "\n",
        "        # expert level computation of auxiliary loss\n",
        "        # always compute topk based on naive greedy topk method\n",
        "        if self.train and self.alpha > 0.0:\n",
        "            scores_for_aux = scores\n",
        "            aux_topk = self.top_k\n",
        "            aux_loss = 0.0\n",
        "\n",
        "            topk_idx_for_auxloss = jnp.reshape(topk_idx, (bsize, -1))\n",
        "            if self.seq_aux:\n",
        "                scores_for_seq_aux = jnp.reshape(scores_for_aux, (bsize, seq_len, -1))\n",
        "                ce = jnp.zeros(\n",
        "                    (bsize, self.routed_exoerts), device=hidden_states.device\n",
        "                )\n",
        "                ones_add = jnp.ones((bsize, seq_len * aux_topk))\n",
        "                ce = jnp.add.at(ce, 1, ones_add)\n",
        "                ce /= seq_len * aux_topk / self.routed_exoerts\n",
        "\n",
        "                aux_loss = (ce * scores_for_seq_aux.mean(axis=1)).sum(\n",
        "                    axis=1\n",
        "                ).mean() * self.alpha\n",
        "\n",
        "            else:\n",
        "                mask_ce = nnx.one_hot(\n",
        "                    jnp.reshape(topk_idx_for_auxloss, (-1)),\n",
        "                    num_classes=self.routed_exoerts,\n",
        "                )\n",
        "                ce = mask_ce.astype(jnp.float32).mean(0)\n",
        "                pi = scores_for_aux.mean()\n",
        "                fi = ce * self.routed_exoerts\n",
        "                aux_loss = (pi * fi).sum() * self.alpha\n",
        "\n",
        "        else:\n",
        "            aux_loss = None\n",
        "\n",
        "        print(f\"gate shape => {topk_weight.shape}\")\n",
        "\n",
        "        return topk_idx, topk_weight, aux_loss"
      ],
      "metadata": {
        "id": "uHfjqUuP-lOT"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7h5PEJ-fA5W7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mixture of experts MLP layer\n",
        "class MoEMLP(nnx.Module):\n",
        "    def __init__(self, hidden_size, intersize, pretrain_tp=2):\n",
        "        self.hidden_size = hidden_size\n",
        "        self.intersize = intersize\n",
        "        self.pretrain_tp = pretrain_tp\n",
        "        self.gate_project = nnx.Linear(\n",
        "            self.hidden_size, self.intersize, use_bias=False, rngs=rngs\n",
        "        )\n",
        "        self.up_project = nnx.Linear(\n",
        "            self.hidden_size, self.intersize, use_bias=False, rngs=rngs\n",
        "        )\n",
        "        self.down_project = nnx.Linear(\n",
        "            self.intersize, self.hidden_size, use_bias=False, rngs=rngs\n",
        "        )\n",
        "\n",
        "    def __call__(self, x_input: Array):\n",
        "        down_proj = None\n",
        "\n",
        "        if self.pretrain_tp > 1:\n",
        "            w_slice = self.intersize // self.pretrain_tp\n",
        "            gate_slices = jnp.split(self.gate_project.kernel[1:], w_slice, axis=0)\n",
        "            up_slices = jnp.split(self.up_project.kernel[1:], w_slice, axis=0)\n",
        "            down_slices = jnp.split(self.down_project.kernel[1:], w_slice, axis=1)\n",
        "\n",
        "            gate_proj = jnp.concat(\n",
        "                [linear(x_input, gate_slices[k]) for k in range(self.pretrain_tp)],\n",
        "                axis=-1,\n",
        "            )\n",
        "            up_proj = jnp.concat(\n",
        "                [linear(x_input, up_slices[k]) for k in range(self.pretrain_tp)],\n",
        "                axis=-1,\n",
        "            )\n",
        "            inter_states = jnp.split((nnx.silu(gate_proj) * up_proj), w_slice, axis=-1)\n",
        "            down_proj = [\n",
        "                linear(inter_states[k], down_slices[k]) for k in range(self.pretrain_tp)\n",
        "            ]\n",
        "            down_proj = sum(down_proj)\n",
        "\n",
        "        else:\n",
        "            activated_x = nnx.silu(self.gate_project(x_input)) * self.up_project(\n",
        "                x_input\n",
        "            )\n",
        "            down_proj = self.down_project(activated_x)\n",
        "\n",
        "\n",
        "        print(f\"moe mlp shape => {down_proj.shape}\")\n",
        "\n",
        "        return down_proj\n",
        "\n",
        "\n",
        "class SparseMoEBlock(nnx.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        embed_dim,\n",
        "        mlp_ratio=4,\n",
        "        num_experts=8,\n",
        "        experts_per_token=2,\n",
        "        train: bool = True,\n",
        "        rngs=rngs,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.experts_pertoken = experts_per_token\n",
        "        self.expert_models = [\n",
        "            MoEMLP(hidden_size=embed_dim, intersize=mlp_ratio * embed_dim)\n",
        "            for _ in range(num_experts)\n",
        "        ]\n",
        "        # self.experts = nnx.Sequential(*self.expert_models)\n",
        "        self.router_gate = MoEGate(embed_dim, num_experts)\n",
        "        self.n_shared_experts = 2\n",
        "        self.training = train\n",
        "\n",
        "        if self.n_shared_experts is not None:\n",
        "            intermediate_size = embed_dim * self.n_shared_experts\n",
        "            self.shared_experts = MoEMLP(\n",
        "                hidden_size=embed_dim, intersize=intermediate_size\n",
        "            )\n",
        "\n",
        "    def __call__(self, hidden_states: Array):\n",
        "        identity = hidden_states\n",
        "        og_shape = hidden_states.shape\n",
        "        topk_idx, topk_weight, aux_loss = self.router_gate(hidden_states)\n",
        "        y = jrand.normal(rkey, shape=og_shape)  # init as random array\n",
        "\n",
        "        hidden_states = jnp.reshape(hidden_states, (-1, hidden_states.shape[1:]))\n",
        "        flat_topk_idx = jnp.reshape(topk_idx, shape=(-1))\n",
        "\n",
        "        if self.train:\n",
        "            hidden_states = jnp.repeat(\n",
        "                hidden_states, repeats=self.experts_pertoken, axis=0\n",
        "            )\n",
        "            y = jnp.empty_like(hidden_states, dtype=hidden_states.dtype)\n",
        "\n",
        "            for k, expert in enumerate(self.expert_models):\n",
        "                y[flat_topk_idx == k] = expert(hidden_states[flat_topk_idx == k]).astype(hidden_states.dtype)  # type: ignore\n",
        "\n",
        "            y = jnp.reshape(y, shape=(*topk_weight.shape, -1)) * jnp.expand_dims(\n",
        "                topk_weight, axis=-1\n",
        "            ).sum(axis=1)\n",
        "            y = jnp.reshape(y, shape=(og_shape))\n",
        "\n",
        "            # TODO: Auxiliary loss add\n",
        "\n",
        "        else:\n",
        "            y = None\n",
        "\n",
        "        if self.shared_experts is not None:\n",
        "            y = y + self.shared_experts(identity)  # type: ignore\n",
        "\n",
        "        # if aux_loss is not None:\n",
        "        #     return y, aux_loss\n",
        "        print(f'sparse moe shape =>{y.shape}')\n",
        "        return y\n",
        "\n",
        "    def moe_infer(self, x_input):\n",
        "        pass\n",
        "\n",
        "moeblock = SparseMoEBlock(embed_dim=1024)\n",
        "\n",
        "# moeblock(iv[0])"
      ],
      "metadata": {
        "id": "gZ1NATHaA5Uh"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jibFZcXNA5RY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "###############\n",
        "# DiT blocks_ #\n",
        "###############\n",
        "\n",
        "\n",
        "class DiTBlock(nnx.Module):\n",
        "    def __init__(self, hidden_size=1024, num_heads=6):\n",
        "        super().__init__()\n",
        "\n",
        "        # initializations\n",
        "        linear_init = nnx.initializers.xavier_uniform()\n",
        "        lnbias_init = nnx.initializers.constant(0)\n",
        "        lnweight_init = nnx.initializers.constant(0)\n",
        "\n",
        "        self.norm_1 = nnx.LayerNorm(\n",
        "            hidden_size, epsilon=1e-6, rngs=rngs, bias_init=lnbias_init\n",
        "        )\n",
        "        self.attention = SelfAttention(num_heads, hidden_size, rngs=rngs)\n",
        "        self.norm_2 = nnx.LayerNorm(hidden_size, epsilon=1e-6, rngs=rngs)\n",
        "\n",
        "        self.adaln_linear = nnx.Linear(\n",
        "            in_features=hidden_size,\n",
        "            out_features=hidden_size,\n",
        "            use_bias=True,\n",
        "            # bias_init=linear_init,\n",
        "            rngs=rngs,\n",
        "            # kernel_init=lnweight_init,\n",
        "        )\n",
        "        self.moe_block = SparseMoEBlock(hidden_size)\n",
        "        print('dit block online')\n",
        "\n",
        "    def __call__(self, x_img: Array):\n",
        "        x_input = self.adaln_linear(nnx.silu(x_img))\n",
        "        shift_msa, scale_msa, gate_msa, shift_mlp, scale_mlp, gate_mlp = (\n",
        "            jnp.array_split(x_input, 6)\n",
        "        )\n",
        "\n",
        "        attn_mod_x = self.attention(\n",
        "            modulate(self.norm_1(x_input), shift_msa, scale_msa)\n",
        "        )\n",
        "        x = x_input + jnp.expand_dims(gate_msa, 1) * attn_mod_x\n",
        "\n",
        "        mlp_mod_x = self.moe_block(modulate(self.norm_2(x), shift_mlp, scale_mlp))\n",
        "        x = x + jnp.expand_dims(gate_mlp, 1) * mlp_mod_x\n",
        "        print(f'x dit block {type(x)} {x.shape}')\n",
        "        return x\n",
        "\n",
        "\n",
        "class FinalMLP(nnx.Module):\n",
        "    def __init__(self, hidden_size, patch_size, out_channels):\n",
        "        super().__init__()\n",
        "        # linear_init = nnx.initializers.xavier_uniform()\n",
        "        linear_init = nnx.initializers.constant(0)\n",
        "\n",
        "        self.norm_final = nnx.LayerNorm(hidden_size, epsilon=1e-6, rngs=rngs)\n",
        "        self.linear = nnx.Linear(\n",
        "            hidden_size,\n",
        "            patch_size * patch_size * out_channels,\n",
        "            rngs=rngs,\n",
        "            kernel_init=linear_init,\n",
        "            bias_init=linear_init,\n",
        "        )\n",
        "        self.adaln_linear = nnx.Linear(\n",
        "            hidden_size,\n",
        "            2 * hidden_size,\n",
        "            rngs=rngs,\n",
        "            kernel_init=linear_init,\n",
        "            bias_init=linear_init,\n",
        "        )\n",
        "\n",
        "    def __call__(self, x_input: Array, cond: Array):\n",
        "        linear_cond = nnx.silu(self.adaln_linear(cond))\n",
        "        shift, scale = jnp.array_split(linear_cond, 2, axis=1)\n",
        "\n",
        "        x = modulate(self.norm_final(x_input), shift, scale)\n",
        "        x = self.linear(x)\n",
        "        print(f'final dit mlp {type(x)} {x.shape}')\n",
        "        return\n",
        "\n",
        "\n",
        "class DiTBackbone(nnx.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        patch_size=(4,4),\n",
        "        in_channels=3,\n",
        "        hidden_size=1024,\n",
        "        depth=4,\n",
        "        attn_heads=6,\n",
        "        learn_sigma=False,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.learn_sigma = learn_sigma\n",
        "        self.in_chan = in_channels\n",
        "        self.out_channels = in_channels * 2 if learn_sigma else in_channels\n",
        "        self.patch_size = patch_size\n",
        "        self.attn_heads = attn_heads\n",
        "\n",
        "        self.img_embedder = PatchEmbed(\n",
        "            img_size=(config.img_size, config.img_size), in_chan=in_channels, embed_dim=hidden_size\n",
        "        )\n",
        "        self.time_embedder = TimestepEmbedder(hidden_size)\n",
        "\n",
        "        num_patches = self.img_embedder.num_patches\n",
        "\n",
        "        self.pos_embed = nnx.Param(jnp.zeros(shape=(1, num_patches, hidden_size)))\n",
        "        pos_embed = get_2d_sincos_pos_embed(\n",
        "            self.pos_embed.value.shape[-1], int(self.img_embedder.num_patches**0.5)\n",
        "        )\n",
        "        sincos2d_data = jnp.expand_dims(pos_embed.astype(jnp.float32), axis=0)\n",
        "        print(f'sincos {type(sincos2d_data)} {sincos2d_data.shape}')\n",
        "        # self.pos_embed.value.copy_from(sincos2d_data)  # type: ignore\n",
        "        self.pos_embed.value = jnp.copy(sincos2d_data)\n",
        "\n",
        "        dit_blocks = [DiTBlock(hidden_size, num_heads=attn_heads) for _ in tqdm(range(depth))]\n",
        "        self.final_mlp = FinalMLP(hidden_size, patch_size[0], self.out_channels)\n",
        "        self.dit_layers = nnx.Sequential(*dit_blocks)\n",
        "        print('ditbackbone online')\n",
        "\n",
        "    def unpatchify(self, x: Array) -> Array:\n",
        "        c = self.out_channels\n",
        "        p = self.img_embedder.patch_size[0]\n",
        "        h = w = int(x.shape[1] ** 0.5)\n",
        "        assert h * w == x.shape[1]\n",
        "\n",
        "        x = jnp.reshape(x, shape=(x.shape[0], h, w, p, p, c))\n",
        "        x = jnp.einsum(\"nhwpqc->nchpwq\", x)\n",
        "        img = jnp.reshape(x, shape=(x.shape[0], c, h * p, w * p))\n",
        "\n",
        "        return img\n",
        "\n",
        "    def __call__(self, x: Array, t: Array, y_cond: Array):\n",
        "        x = self.img_embedder(x) + self.pos_embed\n",
        "        t_embed = self.time_embedder(t)\n",
        "\n",
        "        cond = t_embed + y_cond\n",
        "        x = self.dit_layers(x, cond)\n",
        "        x = self.final_mlp(x, cond)  # type: ignore\n",
        "        x = self.unpatchify(x)\n",
        "\n",
        "        print(f'ditback out -> {x.shape}')\n",
        "\n",
        "        return x\n",
        "\n",
        "    def cfg_forward(self, x_img, t, y_cond, cfg_scale):\n",
        "        half = x_img[: len(x_img) // 2]\n",
        "        combined = jnp.concat([half, half], axis=0)\n",
        "        model_out = self.__call__(combined, t, y_cond)\n",
        "\n",
        "        eps, rest = model_out[:, :3], model_out[:, 3:]\n",
        "        cond_eps, uncond_eps = jnp.split(eps, len(eps) // 2, axis=0)\n",
        "\n",
        "        half_eps = uncond_eps + cfg_scale * (cond_eps - uncond_eps)\n",
        "        eps = jnp.concat([half_eps, half_eps], axis=0)\n",
        "        cfg_out = jnp.concat([eps, rest], axis=1)\n",
        "\n",
        "        return cfg_out\n",
        "\n",
        "backbone = DiTBackbone()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208,
          "referenced_widgets": [
            "cdec84504c174422ba9c8e99c5ae1dd1",
            "0976f85e431645e98222f8b2063ee223",
            "2bd4a506aaed4d5d91fff4def6932498",
            "85644367060f4cb0b0a068a86a5d2b23",
            "102f27c0a9344e11a6bb0e614baeb97a",
            "abece1ae08f34e278ea96213691f50b3",
            "f7a3aa96342b440c8702746cf747603b",
            "881d5b59f8b9438eb30ad49649fefa09",
            "a32afe4d938d4df3becfcfbb1be044f1",
            "e4efb4ee931445a985f78063b9be142d",
            "c6d16bc44ec24d77a8ebfca8d3fdaa3a"
          ]
        },
        "id": "9F3lQnNY_FDZ",
        "outputId": "2758c871-8d72-4955-bc5a-41068864ca2b"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sincos <class 'jaxlib.xla_extension.ArrayImpl'> (1, 64, 1024)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/jax/_src/numpy/lax_numpy.py:5037: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in arange is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
            "  output = _arange(start, stop=stop, step=step, dtype=dtype)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cdec84504c174422ba9c8e99c5ae1dd1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dit block online\n",
            "dit block online\n",
            "dit block online\n",
            "dit block online\n",
            "ditbackbone online\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# backbone(iv[0]).shape"
      ],
      "metadata": {
        "id": "HYhNiVNVI2Rw"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "sKOWZVSzhkUM"
      },
      "outputs": [],
      "source": [
        "# patch mixer module\n",
        "class PatchMixer(nnx.Module):\n",
        "    def __init__(self, embed_dim, attn_heads, n_layers=2):\n",
        "        super().__init__()\n",
        "        layers = [\n",
        "            TransformerEncoderBlock(embed_dim, attn_heads) for _ in range(n_layers)\n",
        "        ]\n",
        "        self.encoder_layers = nnx.Sequential(*layers)\n",
        "\n",
        "    def __call__(self, x: Array) -> Array:\n",
        "        x = self.encoder_layers(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512,
          "referenced_widgets": [
            "887e4c382fae4b74b9b64446c9393936",
            "17132346ffcb4f19aa8648b754d13416",
            "500aa0e1276148ba948fdcd124d55135",
            "5eb5c51d934f4239bbdf073165b4f649",
            "d7550837fd074c18bb7f87f455985756",
            "78f1df6989b74a969bdef7c3ab421ddb",
            "07f1807428a24ca7acd2aefde132b27b",
            "cd4742586ac640dfa5c7b4a3c12f2858",
            "666d89e6fad241ca9889c264b27732f3",
            "e4468268705c41da88047ac1ae29f8ac",
            "15ae19a6c2fb46a7a4f1c5a0ed51f8e3"
          ]
        },
        "id": "XhjbydUPhkUM",
        "outputId": "5f59bd95-70ba-474b-c4a1-9895c4e00c71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sincos <class 'jaxlib.xla_extension.ArrayImpl'> (1, 64, 1024)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/jax/_src/numpy/lax_numpy.py:5037: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in arange is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
            "  output = _arange(start, stop=stop, step=step, dtype=dtype)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "887e4c382fae4b74b9b64446c9393936"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dit block online\n",
            "dit block online\n",
            "dit block online\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "RESOURCE_EXHAUSTED: Out of memory while trying to allocate 16777732 bytes.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-106-a43b23ee205a>\u001b[0m in \u001b[0;36m<cell line: 139>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0mrandin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjrand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m microdit = MicroDiT(\n\u001b[0m\u001b[1;32m    140\u001b[0m     \u001b[0minchannels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0mpatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/flax/nnx/nnx/object.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0m_graph_node_meta_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_object_meta_construct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/flax/nnx/nnx/object.py\u001b[0m in \u001b[0;36m_graph_node_meta_call\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m   \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m   \u001b[0mvars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_object__state'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mObjectState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m   \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object_meta_construct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/flax/nnx/nnx/object.py\u001b[0m in \u001b[0;36m_object_meta_construct\u001b[0;34m(cls, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_object_meta_construct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-106-a43b23ee205a>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inchannels, patch_size, embed_dim, num_layers, attn_heads, mlp_dim, cond_embed_dim, num_experts, active_experts, dropout, patchmix_layers, rngs, num_classes)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch_mixer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPatchMixer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membed_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatchmix_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         self.ditbackbone = DiTBackbone(\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0mpatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0min_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minchannels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/flax/nnx/nnx/object.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0m_graph_node_meta_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_object_meta_construct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/flax/nnx/nnx/object.py\u001b[0m in \u001b[0;36m_graph_node_meta_call\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m   \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m   \u001b[0mvars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_object__state'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mObjectState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m   \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object_meta_construct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/flax/nnx/nnx/object.py\u001b[0m in \u001b[0;36m_object_meta_construct\u001b[0;34m(cls, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_object_meta_construct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-102-e7f6e1040d8f>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, patch_size, in_channels, hidden_size, depth, attn_heads, learn_sigma)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_embed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msincos2d_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mdit_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mDiTBlock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_heads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattn_heads\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_mlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFinalMLP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdit_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdit_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-102-e7f6e1040d8f>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_embed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msincos2d_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mdit_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mDiTBlock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_heads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattn_heads\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_mlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFinalMLP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdit_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdit_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/flax/nnx/nnx/object.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0m_graph_node_meta_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_object_meta_construct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/flax/nnx/nnx/object.py\u001b[0m in \u001b[0;36m_graph_node_meta_call\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m   \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m   \u001b[0mvars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_object__state'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mObjectState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m   \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object_meta_construct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/flax/nnx/nnx/object.py\u001b[0m in \u001b[0;36m_object_meta_construct\u001b[0;34m(cls, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_object_meta_construct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-102-e7f6e1040d8f>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, hidden_size, num_heads)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;31m# kernel_init=lnweight_init,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         )\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoe_block\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparseMoEBlock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dit block online'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/flax/nnx/nnx/object.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0m_graph_node_meta_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_object_meta_construct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/flax/nnx/nnx/object.py\u001b[0m in \u001b[0;36m_graph_node_meta_call\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m   \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m   \u001b[0mvars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_object__state'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mObjectState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m   \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object_meta_construct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/flax/nnx/nnx/object.py\u001b[0m in \u001b[0;36m_object_meta_construct\u001b[0;34m(cls, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_object_meta_construct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-52-a2d0cd42e4b3>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, embed_dim, mlp_ratio, num_experts, experts_per_token, train, rngs)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperts_pertoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperts_per_token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         self.expert_models = [\n\u001b[0m\u001b[1;32m     65\u001b[0m             \u001b[0mMoEMLP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membed_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintersize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmlp_ratio\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0membed_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_experts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-52-a2d0cd42e4b3>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperts_pertoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperts_per_token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         self.expert_models = [\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0mMoEMLP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membed_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintersize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmlp_ratio\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0membed_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_experts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         ]\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/flax/nnx/nnx/object.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0m_graph_node_meta_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_object_meta_construct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/flax/nnx/nnx/object.py\u001b[0m in \u001b[0;36m_graph_node_meta_call\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m   \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m   \u001b[0mvars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_object__state'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mObjectState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m   \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object_meta_construct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/flax/nnx/nnx/object.py\u001b[0m in \u001b[0;36m_object_meta_construct\u001b[0;34m(cls, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_object_meta_construct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-52-a2d0cd42e4b3>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, hidden_size, intersize, pretrain_tp)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mintersize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretrain_tp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpretrain_tp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         self.gate_project = nnx.Linear(\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_bias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrngs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrngs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/flax/nnx/nnx/object.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0m_graph_node_meta_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_object_meta_construct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/flax/nnx/nnx/object.py\u001b[0m in \u001b[0;36m_graph_node_meta_call\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m   \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m   \u001b[0mvars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_object__state'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mObjectState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m   \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object_meta_construct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/flax/nnx/nnx/object.py\u001b[0m in \u001b[0;36m_object_meta_construct\u001b[0;34m(cls, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_object_meta_construct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/flax/nnx/nnx/nn/linear.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_features, out_features, use_bias, dtype, param_dtype, precision, kernel_init, bias_init, dot_general, rngs)\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0mkernel_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrngs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m     self.kernel = nnx.Param(\n\u001b[0;32m--> 348\u001b[0;31m       \u001b[0mkernel_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0min_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m     )\n\u001b[1;32m    350\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/nn/initializers.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(key, shape, dtype)\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# constant is stddev of standard normal truncated to (-2, 2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0mstddev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariance\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m.87962566103423978\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtruncated_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mstddev\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;31m# constant is stddev of complex standard normal truncated to 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/random.py\u001b[0m in \u001b[0;36mtruncated_normal\u001b[0;34m(key, lower, upper, shape, dtype)\u001b[0m\n\u001b[1;32m    845\u001b[0m                      f\"dtype, got {dtype}\")\n\u001b[1;32m    846\u001b[0m   \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanonicalize_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_truncated_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatic_argnums\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 16777732 bytes."
          ]
        }
      ],
      "source": [
        "#####################\n",
        "# Full Microdit model\n",
        "####################\n",
        "class MicroDiT(nnx.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        inchannels,\n",
        "        patch_size,\n",
        "        embed_dim,\n",
        "        num_layers,\n",
        "        attn_heads,\n",
        "        mlp_dim,\n",
        "        cond_embed_dim,\n",
        "        num_experts=4,\n",
        "        active_experts=2,\n",
        "        dropout=0.1,\n",
        "        patchmix_layers=2,\n",
        "        rngs=rngs,\n",
        "        num_classes=10,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.patch_size = patch_size\n",
        "        self.embed_dim = embed_dim\n",
        "\n",
        "        self.patch_embedder = PatchEmbed(\n",
        "            rngs=rngs, patch_size=patch_size, in_chan=inchannels, embed_dim=embed_dim\n",
        "        )\n",
        "\n",
        "        # conditioning layers\n",
        "        self.time_embedder = TimestepEmbedder(embed_dim)\n",
        "        self.cap_embedder = CaptionEmbedder(cond_embed_dim, embed_dim)\n",
        "        self.label_embedder = LabelEmbedder(\n",
        "            num_classes=num_classes, hidden_size=embed_dim, drop=dropout)\n",
        "        self.cond_attention = CrossAttention(\n",
        "            attn_heads, embed_dim, cond_embed_dim, rngs=rngs\n",
        "        )\n",
        "        self.cond_mlp = SimpleMLP(embed_dim)\n",
        "\n",
        "        # pooling layer\n",
        "        self.pool_mlp = PoolMLP(embed_dim)\n",
        "\n",
        "        self.linear = nnx.Linear(self.embed_dim, self.embed_dim, rngs=rngs)\n",
        "\n",
        "        self.patch_mixer = PatchMixer(embed_dim, attn_heads, patchmix_layers)\n",
        "        self.ditbackbone = DiTBackbone(\n",
        "            patch_size=patch_size,\n",
        "            in_channels=inchannels,\n",
        "            hidden_size=embed_dim,\n",
        "            depth=num_layers,\n",
        "        )\n",
        "\n",
        "        self.outlin_1 = nnx.Linear(embed_dim, embed_dim, rngs=rngs)\n",
        "        self.final_linear = nnx.Linear(\n",
        "            embed_dim, patch_size[0] * patch_size[1] * inchannels, rngs=rngs\n",
        "        )\n",
        "\n",
        "    def __call__(self, x: Array, t: Array, y_cap: Array, mask=None):\n",
        "        bsize, channels, height, width = x.shape\n",
        "        psize_h, psize_w = self.patch_size\n",
        "\n",
        "        x = self.patch_embedder(x)\n",
        "\n",
        "        pos_embed = get_2d_sincos_pos_embed(self.embed_dim, height // psize_h)\n",
        "        pos_embed = jnp.expand_dims(pos_embed, axis=0)\n",
        "        pos_embed = jnp.broadcast_to(pos_embed, (bsize, -1, -1))\n",
        "        x = x + pos_embed\n",
        "\n",
        "        # cond_embed = self.cap_embedder(y_cap) # (b, embdim)\n",
        "        cond_embed = self.label_embedder(y_cap)\n",
        "        time_embed = self.time_embedder(t)\n",
        "        time_embed_unsqueeze = jnp.expand_dims(time_embed, axis=0)\n",
        "\n",
        "        mha_out = self.cond_attention(time_embed_unsqueeze, cond_embed).squeeze(axis=1)\n",
        "        mlp_out = self.cond_mlp(mha_out)\n",
        "\n",
        "        # pooling the conditions\n",
        "        pool_out = self.pool_mlp(jnp.expand_dims(mlp_out, axis=2))\n",
        "        pool_out = jnp.expand_dims((pool_out + time_embed), axis=1)\n",
        "\n",
        "        cond_signal = jnp.expand_dims(self.linear(mlp_out), axis=1)\n",
        "        cond_signal = jnp.broadcast_to(\n",
        "            (cond_signal + pool_out), shape=(-1, x.shape[1], -1)\n",
        "        )\n",
        "\n",
        "        x = x + cond_signal\n",
        "        x = self.patch_mixer(x)\n",
        "\n",
        "        if mask is not None:\n",
        "            x = remove_masked_patches(x, mask)\n",
        "\n",
        "        mlp_out_us = jnp.expand_dims(mlp_out, axis=1)  # unqueezed mlp output\n",
        "        cond = jnp.broadcast_to((mlp_out_us + pool_out), shape=(-1, x.shape[1], -1))\n",
        "\n",
        "        x = x + cond\n",
        "\n",
        "        x = self.ditbackbone(x, time_embed, cond_embed)\n",
        "\n",
        "        x = self.final_linear(x)\n",
        "\n",
        "        # add back masked patches\n",
        "        if mask is not None:\n",
        "            x = add_masked_patches(x, mask)\n",
        "\n",
        "        x = self.ditbackbone.unpatchify(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    # ahhhhhhhh, yess, full model\n",
        "    # wed_nov_13, 4:49\n",
        "\n",
        "    def sample(self, z_latent, cond, sample_steps=50, cfg=2.0):\n",
        "        b_size = z_latent.shape[0]\n",
        "        dt = 1.0 / sample_steps\n",
        "\n",
        "        dt = jnp.array([dt] * b_size)\n",
        "        dt = jnp.reshape(dt, shape=(b_size, *([1] * len(z_latent.shape[1:]))))\n",
        "\n",
        "        images = [z_latent]\n",
        "\n",
        "        for i in range(sample_steps, 0, -1):\n",
        "            t = i / sample_steps\n",
        "            t = (\n",
        "                jnp.array([t] * b_size)\n",
        "                # .to_device(z_latent.device)\n",
        "                .astype(z_latent.dtype)\n",
        "            )\n",
        "\n",
        "            vc = self(z_latent, t, cond, None)\n",
        "            null_cond = jnp.zeros_like(cond)\n",
        "            vu = self.__call__(z_latent, t, null_cond)\n",
        "            vc = vu + cfg * (vc - vu)\n",
        "\n",
        "            z = z_latent - dt * vc\n",
        "            images.append(z)\n",
        "\n",
        "        return images[-1] / config.vaescale_factor\n",
        "\n",
        "randin = jrand.normal(randkey, (1, 4, 32, 32))\n",
        "microdit = MicroDiT(\n",
        "    inchannels=3,\n",
        "    patch_size=(4, 4),\n",
        "    embed_dim=1024,\n",
        "    num_layers=4,\n",
        "    attn_heads=6,\n",
        "    mlp_dim=4 * 1024,\n",
        "    cond_embed_dim=768,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "\n",
        "jax.clear_caches()\n",
        "\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "lGLrvyc4JlJx",
        "outputId": "10965488-ef7e-469b-83ef-98624135ea7a"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "807"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOq2gW7FhkUN",
        "outputId": "c35053a7-b856-4bc1-dd9c-c2bb21046894"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of parameters: 482.471M\n"
          ]
        }
      ],
      "source": [
        "# rectifed flow forward pass, loss, and smapling\n",
        "class RectFlow(nnx.Module):\n",
        "    def __init__(self, model: nnx.Module, sigln: bool = True):\n",
        "        self.model = model\n",
        "        self.sigln = sigln\n",
        "\n",
        "    def __call__(self, x_input: Array, cond: Array, mask) -> Array:\n",
        "\n",
        "        b_size = x_input.shape[0]  # batch_sie\n",
        "        rand_t = None\n",
        "\n",
        "        if self.sigln:\n",
        "            rand = jrand.normal(randkey, (b_size,))#.to_device(x_input.device)\n",
        "            rand_t = nnx.sigmoid(rand)\n",
        "        else:\n",
        "            rand_t = jrand.normal(randkey, (b_size,))#.to_device(x_input.device)\n",
        "\n",
        "        inshape = [1] * len(x_input.shape[1:])\n",
        "        texp = rand_t.reshape([b_size, *(inshape)])\n",
        "\n",
        "        z_noise = jrand.normal(\n",
        "            randkey, x_input.shape\n",
        "        )  # input noise with same dim as image\n",
        "        z_noise_t = (1 - texp) * x_input + texp * z_noise\n",
        "\n",
        "        v_thetha = self.model(z_noise_t, rand_t, cond, mask)\n",
        "\n",
        "        mean_dim = list(\n",
        "            range(1, len(x_input.shape))\n",
        "        )  # across all dimensions except the batch dim\n",
        "        mean_square = (z_noise - x_input - v_thetha) ** 2  # squared difference\n",
        "        batchwise_mse_loss = jnp.mean(mean_square, axis=mean_dim)  # mean loss\n",
        "\n",
        "        return jnp.mean(batchwise_mse_loss)\n",
        "\n",
        "    def sample(\n",
        "        self,\n",
        "        input_noise: jax.Array,\n",
        "        cond,\n",
        "        zero_cond=None,\n",
        "        sample_steps: int = 50,\n",
        "        cfg=2.0,\n",
        "    ) -> List[jax.Array]:\n",
        "\n",
        "        batch_size = input_noise.shape[0]\n",
        "\n",
        "        # array reciprocal of sampling steps\n",
        "        d_steps = 1.0 / sample_steps\n",
        "\n",
        "        d_steps = jnp.array([d_steps] * batch_size)#.to_device(input_noise.device)\n",
        "        steps_dim = [1] * len(input_noise.shape[1:])\n",
        "        d_steps = d_steps.reshape([batch_size], *steps_dim)\n",
        "\n",
        "        images = [input_noise]  # noise sequence\n",
        "\n",
        "        for t_step in range(sample_steps):\n",
        "\n",
        "            genstep = t_step / sample_steps  # current step\n",
        "\n",
        "            genstep_batched = jnp.array([genstep] * batch_size)#.to_device(input_noise.device)\n",
        "\n",
        "            cond_output = self.model(\n",
        "                input_noise, genstep_batched, cond\n",
        "            )  # get model output for step\n",
        "\n",
        "            if zero_cond is not None:\n",
        "                # output for zero conditioning\n",
        "                uncond_output = self.model(input_noise, genstep_batched, zero_cond)\n",
        "                cond_output = uncond_output + cfg * (cond_output - uncond_output)\n",
        "\n",
        "            out_noise = input_noise - d_steps * cond_output\n",
        "\n",
        "            images.append(out_noise)\n",
        "\n",
        "        return images\n",
        "\n",
        "\n",
        "# model = MicroDiT(\n",
        "#     inchannels=3,\n",
        "#     patch_size=(4, 4),\n",
        "#     embed_dim=1024,\n",
        "#     num_layers=12,\n",
        "#     attn_heads=6,\n",
        "#     mlp_dim=4 * 1024,\n",
        "#     caption_embed_dim=768,\n",
        "# )\n",
        "\n",
        "rf_engine = RectFlow(microdit)\n",
        "graph, state = nnx.split(rf_engine)\n",
        "n_params = sum([p.size for p in jax.tree.leaves(state)])\n",
        "print(f\"number of parameters: {n_params/1e6:.3f}M\")\n",
        "\n",
        "# optimizer = nnx.Optimizer(rf_engine, optax.adamw(learning_rate=config.lr))\n",
        "\n",
        "# def preprocess_image(image_array):\n",
        "\n",
        "def wandb_logger(key: str, project_name, run_name):  # wandb logger\n",
        "    # initilaize wandb\n",
        "    wandb.login(key=key)\n",
        "    wandb.init(project=project_name, name=run_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "vY09lxpbhkUN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f1981c49ef7e43d4ab4b1642cc119c51",
            "40602dc7e8444f3ba8081f907794b0f9",
            "5cf87bfab367419c9397503c554be84f",
            "f6c9b62b5897453089bcb2513e2babb2",
            "11d306e6ddfd4b5dbae42a09cb3dad33",
            "63a8a2b3e91a49518efcd0e4178c7947",
            "0fd9f7a9a9a043ec9e19f5966bf77380",
            "48e408ce26ca45d486b86e18b929bebd",
            "31583619dc604c5c9730b6f3632a2223",
            "24f1c781437d49b8b5bc39bc6f5086b9",
            "0e0cec1d1e83477ea91b19baf87710c4",
            "0eaa2c619fbc46a59331abb7de75b771",
            "67df6b5090344c5b8e2e3e405dae9b68",
            "dd3518da98aa44a68a50c6ca77133f91",
            "d18ef27d30624ecb8ecb9970f391a245",
            "f23d8493ee1c47418d24e48e142f97e7",
            "d822f15f78e54a9ba7bc062328517352",
            "d3f0efb5f1d1417fa16f23537fc9ae20",
            "4e7852f255c240118a9603e59e1c8315",
            "895ef9e5d09344558215e16e80ef115b",
            "ecb9b129e1bf446bb710683bd08e1411",
            "10148f9f9d6b4cdcafa6c9b1d9701645"
          ]
        },
        "id": "dfNOgrzFhkUO",
        "outputId": "d2577e90-664f-4950-d66a-b4ae7f91d5dc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f1981c49ef7e43d4ab4b1642cc119c51"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/2500 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0eaa2c619fbc46a59331abb7de75b771"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4, 32, 32, 3)\n",
            "mask shape (4, 64)\n",
            "patchembed shape => (4, 65536)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/jax/_src/numpy/lax_numpy.py:5037: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in arange is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
            "  output = _arange(start, stop=stop, step=step, dtype=dtype)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Incompatible shapes for broadcasting: (1, 64, 1024) and requested shape (4, -1, -1)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-111-1770eea1d049>\u001b[0m in \u001b[0;36m<cell line: 61>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;31m# wandb.finish()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"microdit test training in JAX\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-111-1770eea1d049>\u001b[0m in \u001b[0;36mtrainer\u001b[0;34m(model, optimizer, train_loader)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"step {step}, loss-> {train_loss.item():.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/flax/nnx/nnx/graph.py\u001b[0m in \u001b[0;36mupdate_context_manager_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1041\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate_context_manager_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mupdate_context_manager_wrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/flax/nnx/nnx/transforms/transforms.py\u001b[0m in \u001b[0;36mjit_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    357\u001b[0m     )\n\u001b[1;32m    358\u001b[0m     \u001b[0mgraphdef\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_graph_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m     out, output_state, output_graphdef = jitted_fn(\n\u001b[0m\u001b[1;32m    360\u001b[0m       \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m       \u001b[0m_nnx_jit_static\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mJitStaticInputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraphdef\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_constrain_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "    \u001b[0;31m[... skipping hidden 11 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/flax/nnx/nnx/transforms/transforms.py\u001b[0m in \u001b[0;36mjit_fn\u001b[0;34m(_nnx_jit_static, _nnx_jit_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    156\u001b[0m   \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert_graph_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_graph_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m   \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m   \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_graph_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_graph_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-111-1770eea1d049>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(model, optimizer, batch)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mgradfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_aux\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/flax/nnx/nnx/graph.py\u001b[0m in \u001b[0;36mupdate_context_manager_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1041\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate_context_manager_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mupdate_context_manager_wrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/flax/nnx/nnx/transforms/transforms.py\u001b[0m in \u001b[0;36mgrad_wrapper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    566\u001b[0m     \u001b[0m_argnums\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_argnums\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_argnums\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_argnums\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m     out = transform(\n\u001b[0m\u001b[1;32m    569\u001b[0m       \u001b[0mgrad_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m       \u001b[0margnums\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_argnums\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "    \u001b[0;31m[... skipping hidden 8 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/flax/nnx/nnx/transforms/transforms.py\u001b[0m in \u001b[0;36mgrad_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    510\u001b[0m   \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert_graph_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m   \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m   \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_graph_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-111-1770eea1d049>\u001b[0m in \u001b[0;36mloss_func\u001b[0;34m(model, batch)\u001b[0m\n\u001b[1;32m      9\u001b[0m     )#.to_device(img_latents.device)\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'mask shape {mask.shape}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_latents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;31m# loss = optax.squared_error(img_latents, logits).mean()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-110-03cf8b03a069>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x_input, cond, mask)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mz_noise_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtexp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx_input\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtexp\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mz_noise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mv_thetha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_noise_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrand_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         mean_dim = list(\n",
            "\u001b[0;32m<ipython-input-103-a43b23ee205a>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, t, y_cap, mask)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mpos_embed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_2d_sincos_pos_embed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mpsize_h\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mpos_embed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_embed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mpos_embed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_embed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpos_embed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36mbroadcast_to\u001b[0;34m(array, shape)\u001b[0m\n\u001b[1;32m   2576\u001b[0m   \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0m_NumPy\u001b[0m \u001b[0mbroadcasting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhttps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morg\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mstable\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbasics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcasting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2577\u001b[0m   \"\"\"\n\u001b[0;32m-> 2578\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_broadcast_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/numpy/util.py\u001b[0m in \u001b[0;36m_broadcast_to\u001b[0;34m(arr, shape)\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnlead\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcompatible\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m       \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Incompatible shapes for broadcasting: {} and requested shape {}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_in_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Incompatible shapes for broadcasting: (1, 64, 1024) and requested shape (4, -1, -1)"
          ]
        }
      ],
      "source": [
        "def loss_func(model, batch):\n",
        "    img_latents, label = batch\n",
        "    bs, height, width, channels = img_latents.shape\n",
        "    print(img_latents.shape)\n",
        "\n",
        "    img_latents = img_latents * config.vaescale_factor\n",
        "    mask = random_mask(\n",
        "        bs, height, width, patch_size=config.patch_size, mask_ratio=config.mask_ratio\n",
        "    )#.to_device(img_latents.device)\n",
        "    print(f'mask shape {mask.shape}')\n",
        "    loss = model(img_latents, label, mask)\n",
        "    # loss = optax.squared_error(img_latents, logits).mean()\n",
        "\n",
        "    return loss\n",
        "\n",
        "\n",
        "@nnx.jit\n",
        "def train_step(model, optimizer, batch):\n",
        "    gradfn = nnx.value_and_grad(loss_func, has_aux=True)\n",
        "    (loss, logits), grads = gradfn(model, batch)\n",
        "    optimizer.update(grads)\n",
        "    return loss\n",
        "\n",
        "\n",
        "def sample_images(model, vae, noise, embeddings):\n",
        "    # Use the stored embeddings\n",
        "    sampled_latents = model.sample(noise, embeddings)\n",
        "\n",
        "    # Decode latents to images\n",
        "    sampled_images = vae.decode(sampled_latents).sample\n",
        "    # images = sample_images\n",
        "    return sampled_images\n",
        "\n",
        "\n",
        "def trainer(model=rf_engine, optimizer=optimizer, train_loader=train_loader):\n",
        "    epochs = 2\n",
        "    train_loss = 0.0\n",
        "    model.train()\n",
        "    # wandb_logger(\n",
        "    #     key=None,\n",
        "    #     model=model,\n",
        "    #     project_name=\"transformer_playjax\",\n",
        "    #     run_name=\"tinygpt-1e-4-bs32-tpu\",\n",
        "    # )\n",
        "\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        for step, batch in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
        "\n",
        "            train_loss = train_step(model, optimizer, batch)\n",
        "            print(f\"step {step}, loss-> {train_loss.item():.4f}\")\n",
        "\n",
        "            # if step % 100 == 0:\n",
        "            #     sample_latents = model.sample()\n",
        "\n",
        "            # wandb.log({\"loss\": train_loss.item()})\n",
        "\n",
        "        print(f\"epoch {epoch+1}, train loss => {train_loss}\")\n",
        "        save_model(model.model, 'microdit_cifar1.safetensors')\n",
        "\n",
        "\n",
        "trainer()\n",
        "# wandb.finish()\n",
        "print(\"microdit test training in JAX\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SbrrY8GthkUO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-TLP5MSIhkUO"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2c38a75b7eb1447c81610e43c507dcd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_19c1bee13d9647468555c4b04d4ae166",
              "IPY_MODEL_c1127e9a09ee429eb320429dac03f32c",
              "IPY_MODEL_2fed7e9265d44ffa9f62987502013fcd"
            ],
            "layout": "IPY_MODEL_028272169cc24756b0dd515348038cf7"
          }
        },
        "19c1bee13d9647468555c4b04d4ae166": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8186960486b4662b41a5ddbc5a9d2c6",
            "placeholder": "​",
            "style": "IPY_MODEL_0d499f7caab2472aa08debe5c8cf2ee8",
            "value": ""
          }
        },
        "c1127e9a09ee429eb320429dac03f32c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5accd3e7541f4a89bcf05b916f064bd5",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ded02ace9cea4e639dd3ceab36899aaa",
            "value": 0
          }
        },
        "2fed7e9265d44ffa9f62987502013fcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5a3b162c9cc4c0b882aa1def06a77df",
            "placeholder": "​",
            "style": "IPY_MODEL_dea114a4d9c348be8898e7a61aa2d224",
            "value": " 0/0 [00:00&lt;?, ?it/s]"
          }
        },
        "028272169cc24756b0dd515348038cf7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8186960486b4662b41a5ddbc5a9d2c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d499f7caab2472aa08debe5c8cf2ee8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5accd3e7541f4a89bcf05b916f064bd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "ded02ace9cea4e639dd3ceab36899aaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a5a3b162c9cc4c0b882aa1def06a77df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dea114a4d9c348be8898e7a61aa2d224": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cdec84504c174422ba9c8e99c5ae1dd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0976f85e431645e98222f8b2063ee223",
              "IPY_MODEL_2bd4a506aaed4d5d91fff4def6932498",
              "IPY_MODEL_85644367060f4cb0b0a068a86a5d2b23"
            ],
            "layout": "IPY_MODEL_102f27c0a9344e11a6bb0e614baeb97a"
          }
        },
        "0976f85e431645e98222f8b2063ee223": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_abece1ae08f34e278ea96213691f50b3",
            "placeholder": "​",
            "style": "IPY_MODEL_f7a3aa96342b440c8702746cf747603b",
            "value": "100%"
          }
        },
        "2bd4a506aaed4d5d91fff4def6932498": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_881d5b59f8b9438eb30ad49649fefa09",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a32afe4d938d4df3becfcfbb1be044f1",
            "value": 4
          }
        },
        "85644367060f4cb0b0a068a86a5d2b23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4efb4ee931445a985f78063b9be142d",
            "placeholder": "​",
            "style": "IPY_MODEL_c6d16bc44ec24d77a8ebfca8d3fdaa3a",
            "value": " 4/4 [00:00&lt;00:00,  9.90it/s]"
          }
        },
        "102f27c0a9344e11a6bb0e614baeb97a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abece1ae08f34e278ea96213691f50b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7a3aa96342b440c8702746cf747603b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "881d5b59f8b9438eb30ad49649fefa09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a32afe4d938d4df3becfcfbb1be044f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e4efb4ee931445a985f78063b9be142d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6d16bc44ec24d77a8ebfca8d3fdaa3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "887e4c382fae4b74b9b64446c9393936": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_17132346ffcb4f19aa8648b754d13416",
              "IPY_MODEL_500aa0e1276148ba948fdcd124d55135",
              "IPY_MODEL_5eb5c51d934f4239bbdf073165b4f649"
            ],
            "layout": "IPY_MODEL_d7550837fd074c18bb7f87f455985756"
          }
        },
        "17132346ffcb4f19aa8648b754d13416": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78f1df6989b74a969bdef7c3ab421ddb",
            "placeholder": "​",
            "style": "IPY_MODEL_07f1807428a24ca7acd2aefde132b27b",
            "value": " 75%"
          }
        },
        "500aa0e1276148ba948fdcd124d55135": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd4742586ac640dfa5c7b4a3c12f2858",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_666d89e6fad241ca9889c264b27732f3",
            "value": 3
          }
        },
        "5eb5c51d934f4239bbdf073165b4f649": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4468268705c41da88047ac1ae29f8ac",
            "placeholder": "​",
            "style": "IPY_MODEL_15ae19a6c2fb46a7a4f1c5a0ed51f8e3",
            "value": " 3/4 [01:16&lt;00:00, 10.02it/s]"
          }
        },
        "d7550837fd074c18bb7f87f455985756": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78f1df6989b74a969bdef7c3ab421ddb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07f1807428a24ca7acd2aefde132b27b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd4742586ac640dfa5c7b4a3c12f2858": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "666d89e6fad241ca9889c264b27732f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e4468268705c41da88047ac1ae29f8ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15ae19a6c2fb46a7a4f1c5a0ed51f8e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f1981c49ef7e43d4ab4b1642cc119c51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_40602dc7e8444f3ba8081f907794b0f9",
              "IPY_MODEL_5cf87bfab367419c9397503c554be84f",
              "IPY_MODEL_f6c9b62b5897453089bcb2513e2babb2"
            ],
            "layout": "IPY_MODEL_11d306e6ddfd4b5dbae42a09cb3dad33"
          }
        },
        "40602dc7e8444f3ba8081f907794b0f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63a8a2b3e91a49518efcd0e4178c7947",
            "placeholder": "​",
            "style": "IPY_MODEL_0fd9f7a9a9a043ec9e19f5966bf77380",
            "value": "  0%"
          }
        },
        "5cf87bfab367419c9397503c554be84f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48e408ce26ca45d486b86e18b929bebd",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_31583619dc604c5c9730b6f3632a2223",
            "value": 0
          }
        },
        "f6c9b62b5897453089bcb2513e2babb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24f1c781437d49b8b5bc39bc6f5086b9",
            "placeholder": "​",
            "style": "IPY_MODEL_0e0cec1d1e83477ea91b19baf87710c4",
            "value": " 0/2 [00:01&lt;?, ?it/s]"
          }
        },
        "11d306e6ddfd4b5dbae42a09cb3dad33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63a8a2b3e91a49518efcd0e4178c7947": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fd9f7a9a9a043ec9e19f5966bf77380": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "48e408ce26ca45d486b86e18b929bebd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31583619dc604c5c9730b6f3632a2223": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "24f1c781437d49b8b5bc39bc6f5086b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e0cec1d1e83477ea91b19baf87710c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0eaa2c619fbc46a59331abb7de75b771": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_67df6b5090344c5b8e2e3e405dae9b68",
              "IPY_MODEL_dd3518da98aa44a68a50c6ca77133f91",
              "IPY_MODEL_d18ef27d30624ecb8ecb9970f391a245"
            ],
            "layout": "IPY_MODEL_f23d8493ee1c47418d24e48e142f97e7"
          }
        },
        "67df6b5090344c5b8e2e3e405dae9b68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d822f15f78e54a9ba7bc062328517352",
            "placeholder": "​",
            "style": "IPY_MODEL_d3f0efb5f1d1417fa16f23537fc9ae20",
            "value": "  0%"
          }
        },
        "dd3518da98aa44a68a50c6ca77133f91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e7852f255c240118a9603e59e1c8315",
            "max": 2500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_895ef9e5d09344558215e16e80ef115b",
            "value": 0
          }
        },
        "d18ef27d30624ecb8ecb9970f391a245": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ecb9b129e1bf446bb710683bd08e1411",
            "placeholder": "​",
            "style": "IPY_MODEL_10148f9f9d6b4cdcafa6c9b1d9701645",
            "value": " 0/2500 [00:01&lt;?, ?it/s]"
          }
        },
        "f23d8493ee1c47418d24e48e142f97e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d822f15f78e54a9ba7bc062328517352": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3f0efb5f1d1417fa16f23537fc9ae20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e7852f255c240118a9603e59e1c8315": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "895ef9e5d09344558215e16e80ef115b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ecb9b129e1bf446bb710683bd08e1411": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10148f9f9d6b4cdcafa6c9b1d9701645": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}