{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YIOS8m-3hkT1",
    "outputId": "8f40b74f-f1ba-4894-8041-02804a12fd92"
   },
   "outputs": [],
   "source": [
    "! pip install -U jax flax einops diffusers transformers datasets wandb tqdm numpy opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -U flax torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86,
     "referenced_widgets": [
      "2c38a75b7eb1447c81610e43c507dcd6",
      "19c1bee13d9647468555c4b04d4ae166",
      "c1127e9a09ee429eb320429dac03f32c",
      "2fed7e9265d44ffa9f62987502013fcd",
      "028272169cc24756b0dd515348038cf7",
      "d8186960486b4662b41a5ddbc5a9d2c6",
      "0d499f7caab2472aa08debe5c8cf2ee8",
      "5accd3e7541f4a89bcf05b916f064bd5",
      "ded02ace9cea4e639dd3ceab36899aaa",
      "a5a3b162c9cc4c0b882aa1def06a77df",
      "dea114a4d9c348be8898e7a61aa2d224"
     ]
    },
    "id": "6vuI7Wq6hkT3",
    "outputId": "2cbad199-5352-434c-c0c1-5a2daa7fdf8b"
   },
   "outputs": [],
   "source": [
    "import jax, math, flax#, cv2\n",
    "import os, wandb, time\n",
    "from jax import Array, numpy as jnp, random as jrand\n",
    "import numpy as np\n",
    "from flax import nnx\n",
    "from einops import rearrange\n",
    "from tqdm.auto import tqdm\n",
    "from typing import List, Tuple\n",
    "from functools import partial\n",
    "# from diffusers import AutoencoderKL\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader, IterableDataset\n",
    "from collections import namedtuple\n",
    "import flax.traverse_util\n",
    "from flax.serialization import to_state_dict\n",
    "import safetensors.flax as safejax\n",
    "from PIL import Image as pillow\n",
    "from diffusers.models.autoencoders.autoencoder_kl import AutoencoderKL\n",
    "# from transformers import AutoTokenizer, T5EncoderModel\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -U wheel && pip install -U \"jax[tpu]\" -f https://storage.googleapis.com/jax-releases/libtpu_releases.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls /dev/accel*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZX8CfdNJhkT5",
    "outputId": "45add57d-af7b-4c1a-a38c-a6837f44360b"
   },
   "outputs": [],
   "source": [
    "# rkey = jrand.key(3)\n",
    "# rngs = nnx.Rngs(3)\n",
    "# randkey = jrand.key(3)\n",
    "\n",
    "num_devices = jax.device_count()\n",
    "devices = jax.local_devices()\n",
    "print(f\"found {num_devices} JAX devices => {devices}\")\n",
    "for device in devices:\n",
    "    print(f\"{device} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "InQBQ3vchkT7"
   },
   "outputs": [],
   "source": [
    "class config:\n",
    "    vaescale_factor = 0.13025\n",
    "    batch_size = 128\n",
    "    img_size = 32\n",
    "    patch_size = (4, 4)\n",
    "    lr = 1e-4\n",
    "    mask_ratio = 0.75\n",
    "    epochs = 5\n",
    "    data_split = 10_000\n",
    "    cfg_scale = 2.0\n",
    "    vae_channels = 4\n",
    "    celebv_id = \"SwayStar123/CelebV-HQ\"\n",
    "    finevid_id = \"HuggingFaceFV/finevideo\"\n",
    "    pd12_id = \"Spawning/PD12M\"\n",
    "    vae_id = \"madebyollin/sdxl-vae-fp16-fix\"\n",
    "    t5_id = \"google-t5/t5-small\"\n",
    "    mini_data_id = \"uoft-cs/cifar10\"\n",
    "    device_0 = jax.default_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gMM87VZ4hkT9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XSc-5AIAhkT-"
   },
   "outputs": [],
   "source": [
    "# jax/numpy implementation of topk selection\n",
    "def jnp_topk(array: Array, k: int):\n",
    "    topk_tuple = namedtuple(\"topk\", [\"values\", \"ids\"])\n",
    "    array = jnp.asarray(array)\n",
    "    flat = array.ravel()\n",
    "\n",
    "    sort_indices = jnp.argpartition(flat, -k)[-k:]\n",
    "    argsort = jnp.argsort(-flat[sort_indices])  # get sorting ids\n",
    "\n",
    "    sort_idx = sort_indices[argsort]\n",
    "    values = flat[sort_idx]\n",
    "\n",
    "    idx = jnp.unravel_index(sort_idx, array.shape)\n",
    "\n",
    "    if len(idx) == 1:\n",
    "        (idx,) = idx\n",
    "\n",
    "    return topk_tuple(values=values, ids=idx)\n",
    "\n",
    "\n",
    "# save model params in safetensors file\n",
    "def save_model(model: nnx.Module, file: str, dtype):\n",
    "    _, state = nnx.split(model)\n",
    "    params = state.filter(nnx.Param)\n",
    "    state_dict = to_state_dict(params)\n",
    "\n",
    "    state_dict = flax.traverse_util.flatten_dict(state_dict, sep=\".\")\n",
    "\n",
    "    for key in list(state_dict.keys()):\n",
    "        if not isinstance(state_dict[key], Array):\n",
    "            state_dict[key] = jnp.array(state_dict[key])  # type: ignore\n",
    "\n",
    "        state_dict[key] = state_dict[key].astype(dtype)  # type: ignore\n",
    "\n",
    "    safejax.save_file(state_dict, file)  # type: ignore\n",
    "\n",
    "\n",
    "def apply_mask(x: Array, mask, patch_size):\n",
    "    # basically turns the masked values to 0s\n",
    "    bs, c, h, w = x.shape\n",
    "    numpatch_h = h // patch_size[0]\n",
    "    numpatch_w = w // patch_size[1]\n",
    "\n",
    "    mask = jnp.reshape(mask, shape=(bs, numpatch_h, numpatch_w))\n",
    "\n",
    "    mask = jnp.expand_dims(mask, axis=1)\n",
    "    mask = jnp.tile(mask, reps=(1, 1, patch_size[0], patch_size[1]))\n",
    "    mask = jnp.reshape(mask, shape=(bs, 1, h, w))\n",
    "\n",
    "    x_masked = x * mask\n",
    "\n",
    "    return x_masked\n",
    "\n",
    "\n",
    "def random_mask(bs, height, width, patch_size, mask_ratio):\n",
    "    num_patches = (height // patch_size[0]) * (width // patch_size[1])\n",
    "    num_patches_to_mask = int(num_patches * mask_ratio)\n",
    "\n",
    "    rand_array = jrand.normal(randkey, shape=(bs, num_patches))\n",
    "    indices = jnp.argsort(rand_array, axis=1)\n",
    "\n",
    "    mask = jnp.ones(shape=(bs, num_patches))\n",
    "\n",
    "    batch_mask_array = jnp.expand_dims(jnp.arange(bs), axis=1)\n",
    "    # mask[batch_mask_array, indices[:, :num_patches_to_mask]] = 0\n",
    "    new_mask = mask.at[batch_mask_array, indices[:, :num_patches_to_mask]].set(0)\n",
    "    mask = new_mask\n",
    "    mask = jnp.reshape(mask, shape=(bs, num_patches))\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "def remove_masked_patches(patches: Array, mask: Array):\n",
    "    mask = jnp.logical_not(jnp.bool(mask))\n",
    "\n",
    "    bs, num_patches, embed_dim = patches.shape\n",
    "    mask = jnp.expand_dims(mask, axis=-1)\n",
    "    mask = jnp.broadcast_to(mask, shape=(-1, -1, embed_dim))\n",
    "    mask_ids = jnp.nonzero(jnp.reshape(mask, (-1)))\n",
    "    unmasked_patches = jnp.reshape(patches, shape=-1)\n",
    "    unmasked_patches = jnp.take(unmasked_patches, mask_ids[0]).reshape(\n",
    "        bs, -1, embed_dim\n",
    "    )\n",
    "\n",
    "    return unmasked_patches\n",
    "\n",
    "\n",
    "def add_masked_patches(patches: Array, mask: Array):\n",
    "    # Ensure mask is a boolean tensor\n",
    "    mask = jnp.bool(mask)\n",
    "\n",
    "    bs, num_patches, embed_dim = mask.shape[0], mask.shape[1], patches.shape[-1]\n",
    "\n",
    "    # Create a tensor of zeros with the same shape and dtype as the patches tensor\n",
    "    full_patches = jnp.zeros(shape=(bs, num_patches, embed_dim))\n",
    "\n",
    "    # Iterate over each batch and place unmasked patches back in their original positions\n",
    "    for b in range(bs):\n",
    "        # Use the mask to place unmasked patches back in the correct positions\n",
    "        full_patches[b, mask[b]] = patches[b].astype(full_patches.dtype)\n",
    "\n",
    "    return full_patches\n",
    "\n",
    "\n",
    "## nov_14_0453\n",
    "\n",
    "# T5 text encoder\n",
    "# t5_tokenizer = AutoTokenizer.from_pretrained(config.t5_id)\n",
    "# t5_model = T5EncoderModel.from_pretrained(config.t5_id)\n",
    "\n",
    "\n",
    "# def text_t5_encode(text_input: str, tokenizer=t5_tokenizer, model=t5_model):\n",
    "#     input_ids = tokenizer(text_input, return_tensors=\"np\").input_ids  # Batch size 1\n",
    "#     outputs = model(input_ids=input_ids)\n",
    "#     last_hidden_states = outputs.last_hidden_state\n",
    "\n",
    "#     return last_hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rZ8sw2u2hkUC"
   },
   "outputs": [],
   "source": [
    "## data loading\n",
    "image_data = load_dataset(\n",
    "    config.mini_data_id, streaming=True, split=\"train\", trust_remote_code=True\n",
    ").take(config.data_split)\n",
    "\n",
    "vae = AutoencoderKL.from_pretrained(config.vae_id)#.to(config.device_0)\n",
    "\n",
    "def load_image(image):\n",
    "    # image = pillow.open(urlopen(url=url))\n",
    "    img_array = np.array(image)\n",
    "    resized = cv2.resize(img_array, dsize=(config.img_size, config.img_size))\n",
    "\n",
    "    return resized / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9oc8B6QohkUE",
    "outputId": "f957a7b3-9e00-4f8d-a73d-09bd5b88024c"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "randkey = jrand.key(3)\n",
    "\n",
    "\n",
    "# class ImageData(IterableDataset):\n",
    "#     def __init__(self, dataset=image_data):\n",
    "#         super().__init__()\n",
    "#         self.dataset = dataset\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return config.data_split\n",
    "\n",
    "#     def __iter__(self):\n",
    "#         for sample in self.dataset:\n",
    "#             image = sample[\"img_url\"]  # type: ignore\n",
    "#             image = load_image(image)\n",
    "#             img_latents = vae.encode(image)\n",
    "#             img_latents = img_latents.numpy()\n",
    "#             caption_encoded = text_t5_encode(sample[\"caption\"])  # type: ignore\n",
    "\n",
    "#             image = jnp.array(image)\n",
    "#             text_encoding = jnp.array(caption_encoded)\n",
    "\n",
    "#             yield image, text_encoding\n",
    "\n",
    "\n",
    "class ImageClassData(IterableDataset):\n",
    "    def __init__(self, dataset=image_data):\n",
    "        super().__init__()\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return config.data_split\n",
    "\n",
    "    def __iter__(self):\n",
    "        for sample in self.dataset:\n",
    "            image = sample[\"img\"]  # type: ignore\n",
    "            image = load_image(image)\n",
    "            # img_latents = vae.encode(torch.tensor(image))\n",
    "            # img_latents = img_latents.\n",
    "\n",
    "            image = jnp.array(image)\n",
    "            label = jnp.array(sample[\"label\"])\n",
    "\n",
    "            yield image, label\n",
    "\n",
    "def jax_collate(batch):\n",
    "    images, labels = zip(*batch)\n",
    "    batch = (jnp.array(images), jnp.array(labels))\n",
    "    batch = jax.tree_util.tree_map(jnp.array, batch)\n",
    "\n",
    "    return batch\n",
    "\n",
    "dataset = ImageClassData()\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size=4, collate_fn=jax_collate)\n",
    "\n",
    "iv = next(iter(train_loader))\n",
    "iv[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3zJDdGL_-dFE",
    "outputId": "252f78d7-d5e5-4fc9-ff65-6ffd4f05a91d"
   },
   "outputs": [],
   "source": [
    "iv[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o_k8aAkMhkUH"
   },
   "outputs": [],
   "source": [
    "# modulation with shift and scale\n",
    "def modulate(x_array: Array, shift, scale) -> Array:\n",
    "    x = x_array * scale.unsqueeze(1)\n",
    "    x = x + shift.unsqueeze(1)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "# equivalnet of F.lineat\n",
    "def linear(array: Array, weight: Array, bias: Array | None = None) -> Array:\n",
    "    out = jnp.dot(array, weight)\n",
    "\n",
    "    if bias is not None:\n",
    "        out += bias\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "se36QaX-hkUI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Svm9UMGahkUI"
   },
   "outputs": [],
   "source": [
    "# Adapted from https://github.com/facebookresearch/mae/blob/main/util/pos_embed.py\n",
    "def get_2d_sincos_pos_embed(embed_dim, grid_size, cls_token=False, extra_tokens=0):\n",
    "    \"\"\"\n",
    "    grid_size: int of the grid height and width\n",
    "    return:\n",
    "    pos_embed: [grid_size*grid_size, embed_dim] or [1+grid_size*grid_size, embed_dim] (w/ or w/o cls_token)\n",
    "    \"\"\"\n",
    "    grid_h = jnp.arange(grid_size, dtype=jnp.float32)\n",
    "    grid_w = jnp.arange(grid_size, dtype=jnp.float32)\n",
    "    grid = jnp.meshgrid(grid_w, grid_h)  # here w goes first\n",
    "    grid = jnp.stack(grid, axis=0)\n",
    "\n",
    "    grid = grid.reshape([2, 1, grid_size, grid_size])\n",
    "    pos_embed = get_2d_sincos_pos_embed_from_grid(embed_dim, grid)\n",
    "    if cls_token and extra_tokens > 0:\n",
    "        pos_embed = jnp.concatenate(\n",
    "            [jnp.zeros([extra_tokens, embed_dim]), pos_embed], axis=0\n",
    "        )\n",
    "    return pos_embed\n",
    "\n",
    "\n",
    "def get_2d_sincos_pos_embed_from_grid(embed_dim, grid):\n",
    "    assert embed_dim % 2 == 0\n",
    "\n",
    "    # use half of dimensions to encode grid_h\n",
    "    emb_h = get_1d_sincos_pos_embed_from_grid(embed_dim // 2, grid[0])  # (H*W, D/2)\n",
    "    emb_w = get_1d_sincos_pos_embed_from_grid(embed_dim // 2, grid[1])  # (H*W, D/2)\n",
    "\n",
    "    emb = jnp.concatenate([emb_h, emb_w], axis=1)  # (H*W, D)\n",
    "    return emb\n",
    "\n",
    "\n",
    "def get_1d_sincos_pos_embed_from_grid(embed_dim, pos):\n",
    "    \"\"\"\n",
    "    embed_dim: output dimension for each position\n",
    "    pos: a list of positions to be encoded: size (M,)\n",
    "    out: (M, D)\n",
    "    \"\"\"\n",
    "    assert embed_dim % 2 == 0\n",
    "    omega = jnp.arange(embed_dim // 2, dtype=jnp.float64)\n",
    "    omega /= embed_dim / 2.0\n",
    "    omega = 1.0 / 10000**omega  # (D/2,)\n",
    "\n",
    "    pos = pos.reshape(-1)  # (M,)\n",
    "    out = jnp.einsum(\"m,d->md\", pos, omega)  # (M, D/2), outer product\n",
    "\n",
    "    emb_sin = jnp.sin(out)  # (M, D/2)\n",
    "    emb_cos = jnp.cos(out)  # (M, D/2)\n",
    "\n",
    "    emb = jnp.concatenate([emb_sin, emb_cos], axis=1)  # (M, D)\n",
    "\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jjNQSobC-647"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VTK2dh1whkUJ",
    "outputId": "eb881e01-dbc0-47da-b0d6-b0b2d1a19d1c"
   },
   "outputs": [],
   "source": [
    "# input patchify layer, 2D image to patches\n",
    "class PatchEmbed(nnx.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        rngs: nnx.Rngs = rngs,\n",
    "        patch_size=(4,4),\n",
    "        img_size=(32, 32),\n",
    "        in_chan: int = 3,\n",
    "        embed_dim: int = 768,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.patch_size = (patch_size, patch_size)\n",
    "        self.img_size = img_size\n",
    "        self.gridsize = tuple([s // p for s, p in zip(img_size, patch_size)])\n",
    "        self.num_patches = self.gridsize[0] * self.gridsize[1]\n",
    "        linear_init = nnx.initializers.constant(0)\n",
    "\n",
    "        self.conv_project = nnx.Conv(\n",
    "            in_chan,\n",
    "            embed_dim,\n",
    "            kernel_size=patch_size,\n",
    "            strides=patch_size,\n",
    "            rngs=rngs,\n",
    "        )\n",
    "\n",
    "    def __call__(self, img: Array) -> Array:\n",
    "        x = self.conv_project(img)\n",
    "        x = jnp.reshape(x, shape=(x.shape[0], -1))\n",
    "        print(f'patchembed shape => {x.shape}')\n",
    "        return x\n",
    "\n",
    "patchem = PatchEmbed()\n",
    "patchimg = patchem(iv[0])\n",
    "\n",
    "# embeds a flat vector\n",
    "class VectorEmbedder(nnx.Module):\n",
    "    def __init__(self, input_dim, hidden_size, rngs=rngs):\n",
    "        super().__init__()\n",
    "        self.linear_1 = nnx.Linear(input_dim, hidden_size, rngs=rngs)\n",
    "        self.linear_2 = nnx.Linear(hidden_size, hidden_size, rngs=rngs)\n",
    "\n",
    "    def __call__(self, x: Array):\n",
    "        x = nnx.silu(self.linear_1(x))\n",
    "        x = self.linear_2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class TimestepEmbedder(nnx.Module):\n",
    "    def __init__(self, hidden_size, freq_embed_size=256):\n",
    "        super().__init__()\n",
    "        self.lin_1 = nnx.Linear(freq_embed_size, hidden_size, rngs=rngs)\n",
    "        self.lin_2 = nnx.Linear(hidden_size, hidden_size, rngs=rngs)\n",
    "        self.freq_embed_size = freq_embed_size\n",
    "\n",
    "    @staticmethod\n",
    "    def timestep_embedding(time_array: Array, dim, max_period=10000):\n",
    "        half = dim // 2\n",
    "        freqs = jnp.exp(-math.log(max_period) * jnp.arange(0, half) / half).to_device(\n",
    "            time_array.device\n",
    "        )\n",
    "        args = jnp.float_(time_array[:, None]) * freqs[None]\n",
    "\n",
    "        embedding = jnp.concat([jnp.cos(args), jnp.sin(args)], axis=-1)\n",
    "        if dim % 2:\n",
    "            embedding = jnp.concat(\n",
    "                [embedding, jnp.zeros_like(embedding[:, :1])], axis=-1\n",
    "            )\n",
    "\n",
    "        return embedding\n",
    "\n",
    "    def __call__(self, x: Array) -> Array:\n",
    "        t_freq = self.timestep_embedding(x, self.freq_embed_size)\n",
    "        t_embed = nnx.silu(self.lin_1(t_freq))\n",
    "\n",
    "        return self.lin_2(t_embed)\n",
    "\n",
    "\n",
    "class LabelEmbedder(nnx.Module):\n",
    "    def __init__(self, num_classes, hidden_size, drop):\n",
    "        super().__init__()\n",
    "        use_cfg_embeddings = drop > 0\n",
    "        self.embedding_table = nnx.Embed(\n",
    "            num_classes + use_cfg_embeddings, hidden_size, rngs=rngs\n",
    "        )\n",
    "        self.num_classes = num_classes\n",
    "        self.dropout = drop\n",
    "\n",
    "    def token_drop(self, labels, force_drop_ids=None) -> Array:\n",
    "        if force_drop_ids is None:\n",
    "            drop_ids = jrand.normal(key=rkey, shape=labels.shape[0]).to_device(\n",
    "                labels.device\n",
    "            )\n",
    "        else:\n",
    "            drop_ids = force_drop_ids == 1\n",
    "\n",
    "        labels = jnp.where(drop_ids, self.num_classes, labels)\n",
    "\n",
    "        return labels\n",
    "\n",
    "    def __call__(self, labels, train: bool, force_drop_ids=None) -> Array:\n",
    "        use_drop = self.dropout > 0\n",
    "        if (train and use_drop) or (force_drop_ids is not None):\n",
    "            labels = self.token_drop(labels, force_drop_ids)\n",
    "\n",
    "        label_embeds = self.embedding_table(labels)\n",
    "\n",
    "        return label_embeds\n",
    "\n",
    "\n",
    "class CaptionEmbedder(nnx.Module):\n",
    "    def __init__(self, cap_embed_dim, embed_dim):\n",
    "        super().__init__()\n",
    "        self.linear_1 = nnx.Linear(cap_embed_dim, embed_dim, rngs=rngs)\n",
    "        self.linear_2 = nnx.Linear(embed_dim, embed_dim, rngs=rngs)\n",
    "\n",
    "    def __call__(self, x: Array) -> Array:\n",
    "        x = nnx.silu(self.linear_1(x))\n",
    "        x = self.linear_2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# self attention block\n",
    "class SelfAttention(nnx.Module):\n",
    "    def __init__(self, attn_heads, embed_dim, rngs: nnx.Rngs, drop=0.1):\n",
    "        super().__init__()\n",
    "        self.attn_heads = attn_heads\n",
    "        self.head_dim = embed_dim // attn_heads\n",
    "\n",
    "        linear_init = nnx.initializers.xavier_uniform()\n",
    "        linear_bias_init = nnx.initializers.constant(0)\n",
    "\n",
    "        self.q_linear = nnx.Linear(\n",
    "            embed_dim,\n",
    "            embed_dim,\n",
    "            rngs=rngs,\n",
    "            bias_init=linear_bias_init,\n",
    "            kernel_init=linear_init,\n",
    "        )\n",
    "        self.k_linear = nnx.Linear(embed_dim, embed_dim, rngs=rngs)\n",
    "        self.v_linear = nnx.Linear(embed_dim, embed_dim, rngs=rngs)\n",
    "\n",
    "        self.outproject = nnx.Linear(\n",
    "            embed_dim, embed_dim, rngs=rngs, bias_init=linear_bias_init\n",
    "        )\n",
    "        self.dropout = nnx.Dropout(drop, rngs=rngs)\n",
    "\n",
    "    def __call__(self, x_input: jax.Array) -> jax.Array:\n",
    "        q = self.q_linear(x_input)\n",
    "        k = self.k_linear(x_input)\n",
    "        v = self.v_linear(x_input)\n",
    "\n",
    "        q, k, v = map(\n",
    "            lambda x: rearrange(x, \"b l (h d) -> b h l d\", h=self.attn_heads), (q, k, v)\n",
    "        )\n",
    "\n",
    "        qk = q @ jnp.matrix_transpose(k)\n",
    "        attn_logits = qk / math.sqrt(self.head_dim)  # attention computation\n",
    "\n",
    "        attn_score = nnx.softmax(attn_logits, axis=-1)\n",
    "        attn_output = attn_score @ v\n",
    "\n",
    "        output = rearrange(attn_output, \"b h l d -> b l (h d)\")\n",
    "        output = self.dropout(self.outproject(output))\n",
    "        print(f\"attn out shape => {output.shape}\")\n",
    "        return output\n",
    "\n",
    "\n",
    "class CrossAttention(nnx.Module):\n",
    "    def __init__(self, attn_heads, embed_dim, cond_dim, rngs: nnx.Rngs, drop=0.1):\n",
    "        super().__init__()\n",
    "        self.attn_heads = attn_heads\n",
    "        self.head_dim = embed_dim // attn_heads\n",
    "\n",
    "        linear_init = nnx.initializers.xavier_uniform()\n",
    "        linear_bias_init = nnx.initializers.constant(0)\n",
    "\n",
    "        self.q_linear = nnx.Linear(\n",
    "            embed_dim,\n",
    "            embed_dim,\n",
    "            rngs=rngs,\n",
    "            bias_init=linear_bias_init,\n",
    "            kernel_init=linear_init,\n",
    "        )\n",
    "\n",
    "        self.k_linear = nnx.Linear(cond_dim, embed_dim, rngs=rngs)\n",
    "        self.v_linear = nnx.Linear(cond_dim, embed_dim, rngs=rngs)\n",
    "\n",
    "        self.outproject = nnx.Linear(\n",
    "            embed_dim, embed_dim, rngs=rngs, bias_init=linear_bias_init\n",
    "        )\n",
    "        self.dropout = nnx.Dropout(drop, rngs=rngs)\n",
    "\n",
    "    def __call__(self, x_input: jax.Array, y_cond: Array) -> jax.Array:\n",
    "        q = self.q_linear(x_input)\n",
    "        k = self.k_linear(y_cond)\n",
    "        v = self.v_linear(y_cond)\n",
    "\n",
    "        q, k, v = map(\n",
    "            lambda x: rearrange(x, \"b l (h d) -> b h l d\", h=self.attn_heads), (q, k, v)\n",
    "        )\n",
    "\n",
    "        qk = q @ jnp.matrix_transpose(k)\n",
    "        attn_logits = qk / math.sqrt(self.head_dim)  # attention computation\n",
    "\n",
    "        attn_score = nnx.softmax(attn_logits, axis=-1)\n",
    "        attn_output = attn_score @ v\n",
    "\n",
    "        output = rearrange(attn_output, \"b h l d -> b l (h d)\")\n",
    "        output = self.dropout(self.outproject(output))\n",
    "        print(f\"attn out shape => {output.shape}\")\n",
    "        return output\n",
    "\n",
    "\n",
    "########################\n",
    "# Patch Mixer components\n",
    "########################\n",
    "\n",
    "\n",
    "class EncoderMLP(nnx.Module):\n",
    "    def __init__(self, hidden_size, rngs: nnx.Rngs, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.layernorm = nnx.LayerNorm(hidden_size, rngs=rngs)\n",
    "\n",
    "        self.linear1 = nnx.Linear(hidden_size, 2 * hidden_size, rngs=rngs)\n",
    "        self.linear2 = nnx.Linear(2 * hidden_size, hidden_size, rngs=rngs)\n",
    "        self.dropout = nnx.Dropout(dropout, rngs=rngs)\n",
    "\n",
    "    def __call__(self, x_input: jax.Array) -> jax.Array:\n",
    "        x = self.layernorm(x_input)\n",
    "        x = nnx.silu(self.linear1(x))\n",
    "        x = self.linear2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class TransformerEncoderBlock(nnx.Module):\n",
    "    def __init__(self, embed_dim, num_heads):\n",
    "        super().__init__()\n",
    "        self.layernorm = nnx.LayerNorm(embed_dim, epsilon=1e-6, rngs=rngs)\n",
    "        self.self_attention = SelfAttention(num_heads, embed_dim, rngs=rngs)\n",
    "        self.mlp_layer = EncoderMLP(embed_dim, rngs=rngs)\n",
    "\n",
    "    def __call__(self, x: Array):\n",
    "        x = x + self.layernorm(self.self_attention(x))\n",
    "        x = x + self.layernorm(self.mlp_layer(x))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uHfjqUuP-lOT"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class SimpleMLP(nnx.Module):\n",
    "    def __init__(self, embed_dim):\n",
    "        super().__init__()\n",
    "        self.linear_1 = nnx.Linear(embed_dim, embed_dim, rngs=rngs)\n",
    "        self.linear_2 = nnx.Linear(embed_dim, embed_dim, rngs=rngs)\n",
    "\n",
    "    def __call__(self, x: Array) -> Array:\n",
    "        x = nnx.silu(self.linear_1(x))\n",
    "        x = self.linear_2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "# Pool + MLP for (MHA + MLP)\n",
    "class PoolMLP(nnx.Module):\n",
    "    def __init__(self, embed_dim):\n",
    "        super().__init__()\n",
    "        self.linear_1 = nnx.Linear(embed_dim, embed_dim, rngs=rngs)\n",
    "        self.linear_2 = nnx.Linear(embed_dim, embed_dim, rngs=rngs)\n",
    "\n",
    "    def __call__(self, x: Array) -> Array:\n",
    "        x = nnx.avg_pool(x, 1, 1)\n",
    "        x = jnp.reshape(x, shape=(x.shape[0], -1))\n",
    "        x = nnx.gelu(self.linear_1(x))\n",
    "        x = self.linear_2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "#### MoE Gate\n",
    "class MoEGate(nnx.Module):\n",
    "    def __init__(\n",
    "        self, embed_dim, num_experts=8, experts_per_token=2, aux_loss_alpha=0.01\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.top_k = experts_per_token\n",
    "        self.routed_exoerts = num_experts\n",
    "        self.score_func = \"softmax\"\n",
    "        self.alpha = aux_loss_alpha\n",
    "        self.seq_aux = False\n",
    "\n",
    "        # top_k selection algo\n",
    "        self.norm_topk_prob = False\n",
    "        self.gating_dim = embed_dim\n",
    "        param_init = nnx.initializers.he_uniform()\n",
    "        self.weight = nnx.Param(jnp.empty((self.routed_exoerts, self.gating_dim)))\n",
    "        # self.linear_gate = nnx.Linear()\n",
    "\n",
    "    def __call__(self, hidden_states: Array) -> Tuple:\n",
    "        bsize, seq_len, h = hidden_states.shape\n",
    "        # gating score\n",
    "        hidden_states = jnp.reshape(hidden_states, (-1, h))\n",
    "        logits = jnp.dot(hidden_states, self.weight[\"Array\"])\n",
    "        scores = nnx.softmax(logits, axis=-1)\n",
    "\n",
    "        topk_idx, topk_weight = jax.lax.top_k(scores, k=self.top_k)\n",
    "\n",
    "        # normalize to sum to 1\n",
    "        if self.top_k > 1 and self.norm_topk_prob:\n",
    "            denominator = jnp.sum(topk_weight, axis=-1, keepdims=True) + 1e-20\n",
    "            topk_weight = topk_weight / denominator\n",
    "\n",
    "        # expert level computation of auxiliary loss\n",
    "        # always compute topk based on naive greedy topk method\n",
    "        if self.train and self.alpha > 0.0:\n",
    "            scores_for_aux = scores\n",
    "            aux_topk = self.top_k\n",
    "            aux_loss = 0.0\n",
    "\n",
    "            topk_idx_for_auxloss = jnp.reshape(topk_idx, (bsize, -1))\n",
    "            if self.seq_aux:\n",
    "                scores_for_seq_aux = jnp.reshape(scores_for_aux, (bsize, seq_len, -1))\n",
    "                ce = jnp.zeros(\n",
    "                    (bsize, self.routed_exoerts), device=hidden_states.device\n",
    "                )\n",
    "                ones_add = jnp.ones((bsize, seq_len * aux_topk))\n",
    "                ce = jnp.add.at(ce, 1, ones_add)\n",
    "                ce /= seq_len * aux_topk / self.routed_exoerts\n",
    "\n",
    "                aux_loss = (ce * scores_for_seq_aux.mean(axis=1)).sum(\n",
    "                    axis=1\n",
    "                ).mean() * self.alpha\n",
    "\n",
    "            else:\n",
    "                mask_ce = nnx.one_hot(\n",
    "                    jnp.reshape(topk_idx_for_auxloss, (-1)),\n",
    "                    num_classes=self.routed_exoerts,\n",
    "                )\n",
    "                ce = mask_ce.astype(jnp.float32).mean(0)\n",
    "                pi = scores_for_aux.mean()\n",
    "                fi = ce * self.routed_exoerts\n",
    "                aux_loss = (pi * fi).sum() * self.alpha\n",
    "\n",
    "        else:\n",
    "            aux_loss = None\n",
    "\n",
    "        print(f\"gate shape => {topk_weight.shape}\")\n",
    "\n",
    "        return topk_idx, topk_weight, aux_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7h5PEJ-fA5W7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gZ1NATHaA5Uh"
   },
   "outputs": [],
   "source": [
    "# mixture of experts MLP layer\n",
    "class MoEMLP(nnx.Module):\n",
    "    def __init__(self, hidden_size, intersize, pretrain_tp=2):\n",
    "        self.hidden_size = hidden_size\n",
    "        self.intersize = intersize\n",
    "        self.pretrain_tp = pretrain_tp\n",
    "        self.gate_project = nnx.Linear(\n",
    "            self.hidden_size, self.intersize, use_bias=False, rngs=rngs\n",
    "        )\n",
    "        self.up_project = nnx.Linear(\n",
    "            self.hidden_size, self.intersize, use_bias=False, rngs=rngs\n",
    "        )\n",
    "        self.down_project = nnx.Linear(\n",
    "            self.intersize, self.hidden_size, use_bias=False, rngs=rngs\n",
    "        )\n",
    "\n",
    "    def __call__(self, x_input: Array):\n",
    "        down_proj = None\n",
    "\n",
    "        if self.pretrain_tp > 1:\n",
    "            w_slice = self.intersize // self.pretrain_tp\n",
    "            gate_slices = jnp.split(self.gate_project.kernel[1:], w_slice, axis=0)\n",
    "            up_slices = jnp.split(self.up_project.kernel[1:], w_slice, axis=0)\n",
    "            down_slices = jnp.split(self.down_project.kernel[1:], w_slice, axis=1)\n",
    "\n",
    "            gate_proj = jnp.concat(\n",
    "                [linear(x_input, gate_slices[k]) for k in range(self.pretrain_tp)],\n",
    "                axis=-1,\n",
    "            )\n",
    "            up_proj = jnp.concat(\n",
    "                [linear(x_input, up_slices[k]) for k in range(self.pretrain_tp)],\n",
    "                axis=-1,\n",
    "            )\n",
    "            inter_states = jnp.split((nnx.silu(gate_proj) * up_proj), w_slice, axis=-1)\n",
    "            down_proj = [\n",
    "                linear(inter_states[k], down_slices[k]) for k in range(self.pretrain_tp)\n",
    "            ]\n",
    "            down_proj = sum(down_proj)\n",
    "\n",
    "        else:\n",
    "            activated_x = nnx.silu(self.gate_project(x_input)) * self.up_project(\n",
    "                x_input\n",
    "            )\n",
    "            down_proj = self.down_project(activated_x)\n",
    "\n",
    "\n",
    "        print(f\"moe mlp shape => {down_proj.shape}\")\n",
    "\n",
    "        return down_proj\n",
    "\n",
    "\n",
    "class SparseMoEBlock(nnx.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embed_dim,\n",
    "        mlp_ratio=4,\n",
    "        num_experts=8,\n",
    "        experts_per_token=2,\n",
    "        train: bool = True,\n",
    "        rngs=rngs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.experts_pertoken = experts_per_token\n",
    "        self.expert_models = [\n",
    "            MoEMLP(hidden_size=embed_dim, intersize=mlp_ratio * embed_dim)\n",
    "            for _ in range(num_experts)\n",
    "        ]\n",
    "        # self.experts = nnx.Sequential(*self.expert_models)\n",
    "        self.router_gate = MoEGate(embed_dim, num_experts)\n",
    "        self.n_shared_experts = 2\n",
    "        self.training = train\n",
    "\n",
    "        if self.n_shared_experts is not None:\n",
    "            intermediate_size = embed_dim * self.n_shared_experts\n",
    "            self.shared_experts = MoEMLP(\n",
    "                hidden_size=embed_dim, intersize=intermediate_size\n",
    "            )\n",
    "\n",
    "    def __call__(self, hidden_states: Array):\n",
    "        identity = hidden_states\n",
    "        og_shape = hidden_states.shape\n",
    "        topk_idx, topk_weight, aux_loss = self.router_gate(hidden_states)\n",
    "        y = jrand.normal(rkey, shape=og_shape)  # init as random array\n",
    "\n",
    "        hidden_states = jnp.reshape(hidden_states, (-1, hidden_states.shape[1:]))\n",
    "        flat_topk_idx = jnp.reshape(topk_idx, shape=(-1))\n",
    "\n",
    "        if self.train:\n",
    "            hidden_states = jnp.repeat(\n",
    "                hidden_states, repeats=self.experts_pertoken, axis=0\n",
    "            )\n",
    "            y = jnp.empty_like(hidden_states, dtype=hidden_states.dtype)\n",
    "\n",
    "            for k, expert in enumerate(self.expert_models):\n",
    "                y[flat_topk_idx == k] = expert(hidden_states[flat_topk_idx == k]).astype(hidden_states.dtype)  # type: ignore\n",
    "\n",
    "            y = jnp.reshape(y, shape=(*topk_weight.shape, -1)) * jnp.expand_dims(\n",
    "                topk_weight, axis=-1\n",
    "            ).sum(axis=1)\n",
    "            y = jnp.reshape(y, shape=(og_shape))\n",
    "\n",
    "            # TODO: Auxiliary loss add\n",
    "\n",
    "        else:\n",
    "            y = None\n",
    "\n",
    "        if self.shared_experts is not None:\n",
    "            y = y + self.shared_experts(identity)  # type: ignore\n",
    "\n",
    "        # if aux_loss is not None:\n",
    "        #     return y, aux_loss\n",
    "        print(f'sparse moe shape =>{y.shape}')\n",
    "        return y\n",
    "\n",
    "    def moe_infer(self, x_input):\n",
    "        pass\n",
    "\n",
    "moeblock = SparseMoEBlock(embed_dim=1024)\n",
    "\n",
    "# moeblock(iv[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jibFZcXNA5RY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208,
     "referenced_widgets": [
      "cdec84504c174422ba9c8e99c5ae1dd1",
      "0976f85e431645e98222f8b2063ee223",
      "2bd4a506aaed4d5d91fff4def6932498",
      "85644367060f4cb0b0a068a86a5d2b23",
      "102f27c0a9344e11a6bb0e614baeb97a",
      "abece1ae08f34e278ea96213691f50b3",
      "f7a3aa96342b440c8702746cf747603b",
      "881d5b59f8b9438eb30ad49649fefa09",
      "a32afe4d938d4df3becfcfbb1be044f1",
      "e4efb4ee931445a985f78063b9be142d",
      "c6d16bc44ec24d77a8ebfca8d3fdaa3a"
     ]
    },
    "id": "9F3lQnNY_FDZ",
    "outputId": "2758c871-8d72-4955-bc5a-41068864ca2b"
   },
   "outputs": [],
   "source": [
    "\n",
    "###############\n",
    "# DiT blocks_ #\n",
    "###############\n",
    "\n",
    "\n",
    "class DiTBlock(nnx.Module):\n",
    "    def __init__(self, hidden_size=1024, num_heads=6):\n",
    "        super().__init__()\n",
    "\n",
    "        # initializations\n",
    "        linear_init = nnx.initializers.xavier_uniform()\n",
    "        lnbias_init = nnx.initializers.constant(0)\n",
    "        lnweight_init = nnx.initializers.constant(0)\n",
    "\n",
    "        self.norm_1 = nnx.LayerNorm(\n",
    "            hidden_size, epsilon=1e-6, rngs=rngs, bias_init=lnbias_init\n",
    "        )\n",
    "        self.attention = SelfAttention(num_heads, hidden_size, rngs=rngs)\n",
    "        self.norm_2 = nnx.LayerNorm(hidden_size, epsilon=1e-6, rngs=rngs)\n",
    "\n",
    "        self.adaln_linear = nnx.Linear(\n",
    "            in_features=hidden_size,\n",
    "            out_features=hidden_size,\n",
    "            use_bias=True,\n",
    "            # bias_init=linear_init,\n",
    "            rngs=rngs,\n",
    "            # kernel_init=lnweight_init,\n",
    "        )\n",
    "        self.moe_block = SparseMoEBlock(hidden_size)\n",
    "        print('dit block online')\n",
    "\n",
    "    def __call__(self, x_img: Array):\n",
    "        x_input = self.adaln_linear(nnx.silu(x_img))\n",
    "        shift_msa, scale_msa, gate_msa, shift_mlp, scale_mlp, gate_mlp = (\n",
    "            jnp.array_split(x_input, 6)\n",
    "        )\n",
    "\n",
    "        attn_mod_x = self.attention(\n",
    "            modulate(self.norm_1(x_input), shift_msa, scale_msa)\n",
    "        )\n",
    "        x = x_input + jnp.expand_dims(gate_msa, 1) * attn_mod_x\n",
    "\n",
    "        mlp_mod_x = self.moe_block(modulate(self.norm_2(x), shift_mlp, scale_mlp))\n",
    "        x = x + jnp.expand_dims(gate_mlp, 1) * mlp_mod_x\n",
    "        print(f'x dit block {type(x)} {x.shape}')\n",
    "        return x\n",
    "\n",
    "\n",
    "class FinalMLP(nnx.Module):\n",
    "    def __init__(self, hidden_size, patch_size, out_channels):\n",
    "        super().__init__()\n",
    "        # linear_init = nnx.initializers.xavier_uniform()\n",
    "        linear_init = nnx.initializers.constant(0)\n",
    "\n",
    "        self.norm_final = nnx.LayerNorm(hidden_size, epsilon=1e-6, rngs=rngs)\n",
    "        self.linear = nnx.Linear(\n",
    "            hidden_size,\n",
    "            patch_size * patch_size * out_channels,\n",
    "            rngs=rngs,\n",
    "            kernel_init=linear_init,\n",
    "            bias_init=linear_init,\n",
    "        )\n",
    "        self.adaln_linear = nnx.Linear(\n",
    "            hidden_size,\n",
    "            2 * hidden_size,\n",
    "            rngs=rngs,\n",
    "            kernel_init=linear_init,\n",
    "            bias_init=linear_init,\n",
    "        )\n",
    "\n",
    "    def __call__(self, x_input: Array, cond: Array):\n",
    "        linear_cond = nnx.silu(self.adaln_linear(cond))\n",
    "        shift, scale = jnp.array_split(linear_cond, 2, axis=1)\n",
    "\n",
    "        x = modulate(self.norm_final(x_input), shift, scale)\n",
    "        x = self.linear(x)\n",
    "        print(f'final dit mlp {type(x)} {x.shape}')\n",
    "        return\n",
    "\n",
    "\n",
    "class DiTBackbone(nnx.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        patch_size=(4,4),\n",
    "        in_channels=3,\n",
    "        hidden_size=1024,\n",
    "        depth=4,\n",
    "        attn_heads=6,\n",
    "        learn_sigma=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.learn_sigma = learn_sigma\n",
    "        self.in_chan = in_channels\n",
    "        self.out_channels = in_channels * 2 if learn_sigma else in_channels\n",
    "        self.patch_size = patch_size\n",
    "        self.attn_heads = attn_heads\n",
    "\n",
    "        self.img_embedder = PatchEmbed(\n",
    "            img_size=(config.img_size, config.img_size), in_chan=in_channels, embed_dim=hidden_size\n",
    "        )\n",
    "        self.time_embedder = TimestepEmbedder(hidden_size)\n",
    "\n",
    "        num_patches = self.img_embedder.num_patches\n",
    "\n",
    "        self.pos_embed = nnx.Param(jnp.zeros(shape=(1, num_patches, hidden_size)))\n",
    "        pos_embed = get_2d_sincos_pos_embed(\n",
    "            self.pos_embed.value.shape[-1], int(self.img_embedder.num_patches**0.5)\n",
    "        )\n",
    "        sincos2d_data = jnp.expand_dims(pos_embed.astype(jnp.float32), axis=0)\n",
    "        print(f'sincos {type(sincos2d_data)} {sincos2d_data.shape}')\n",
    "        # self.pos_embed.value.copy_from(sincos2d_data)  # type: ignore\n",
    "        self.pos_embed.value = jnp.copy(sincos2d_data)\n",
    "\n",
    "        dit_blocks = [DiTBlock(hidden_size, num_heads=attn_heads) for _ in tqdm(range(depth))]\n",
    "        self.final_mlp = FinalMLP(hidden_size, patch_size[0], self.out_channels)\n",
    "        self.dit_layers = nnx.Sequential(*dit_blocks)\n",
    "        print('ditbackbone online')\n",
    "\n",
    "    def unpatchify(self, x: Array) -> Array:\n",
    "        c = self.out_channels\n",
    "        p = self.img_embedder.patch_size[0]\n",
    "        h = w = int(x.shape[1] ** 0.5)\n",
    "        assert h * w == x.shape[1]\n",
    "\n",
    "        x = jnp.reshape(x, shape=(x.shape[0], h, w, p, p, c))\n",
    "        x = jnp.einsum(\"nhwpqc->nchpwq\", x)\n",
    "        img = jnp.reshape(x, shape=(x.shape[0], c, h * p, w * p))\n",
    "\n",
    "        return img\n",
    "\n",
    "    def __call__(self, x: Array, t: Array, y_cond: Array):\n",
    "        x = self.img_embedder(x) + self.pos_embed\n",
    "        t_embed = self.time_embedder(t)\n",
    "\n",
    "        cond = t_embed + y_cond\n",
    "        x = self.dit_layers(x, cond)\n",
    "        x = self.final_mlp(x, cond)  # type: ignore\n",
    "        x = self.unpatchify(x)\n",
    "\n",
    "        print(f'ditback out -> {x.shape}')\n",
    "\n",
    "        return x\n",
    "\n",
    "    def cfg_forward(self, x_img, t, y_cond, cfg_scale):\n",
    "        half = x_img[: len(x_img) // 2]\n",
    "        combined = jnp.concat([half, half], axis=0)\n",
    "        model_out = self.__call__(combined, t, y_cond)\n",
    "\n",
    "        eps, rest = model_out[:, :3], model_out[:, 3:]\n",
    "        cond_eps, uncond_eps = jnp.split(eps, len(eps) // 2, axis=0)\n",
    "\n",
    "        half_eps = uncond_eps + cfg_scale * (cond_eps - uncond_eps)\n",
    "        eps = jnp.concat([half_eps, half_eps], axis=0)\n",
    "        cfg_out = jnp.concat([eps, rest], axis=1)\n",
    "\n",
    "        return cfg_out\n",
    "\n",
    "backbone = DiTBackbone()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HYhNiVNVI2Rw"
   },
   "outputs": [],
   "source": [
    "# backbone(iv[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sKOWZVSzhkUM"
   },
   "outputs": [],
   "source": [
    "# patch mixer module\n",
    "class PatchMixer(nnx.Module):\n",
    "    def __init__(self, embed_dim, attn_heads, n_layers=2):\n",
    "        super().__init__()\n",
    "        layers = [\n",
    "            TransformerEncoderBlock(embed_dim, attn_heads) for _ in range(n_layers)\n",
    "        ]\n",
    "        self.encoder_layers = nnx.Sequential(*layers)\n",
    "\n",
    "    def __call__(self, x: Array) -> Array:\n",
    "        x = self.encoder_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 512,
     "referenced_widgets": [
      "887e4c382fae4b74b9b64446c9393936",
      "17132346ffcb4f19aa8648b754d13416",
      "500aa0e1276148ba948fdcd124d55135",
      "5eb5c51d934f4239bbdf073165b4f649",
      "d7550837fd074c18bb7f87f455985756",
      "78f1df6989b74a969bdef7c3ab421ddb",
      "07f1807428a24ca7acd2aefde132b27b",
      "cd4742586ac640dfa5c7b4a3c12f2858",
      "666d89e6fad241ca9889c264b27732f3",
      "e4468268705c41da88047ac1ae29f8ac",
      "15ae19a6c2fb46a7a4f1c5a0ed51f8e3"
     ]
    },
    "id": "XhjbydUPhkUM",
    "outputId": "5f59bd95-70ba-474b-c4a1-9895c4e00c71"
   },
   "outputs": [],
   "source": [
    "#####################\n",
    "# Full Microdit model\n",
    "####################\n",
    "class MicroDiT(nnx.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        inchannels,\n",
    "        patch_size,\n",
    "        embed_dim,\n",
    "        num_layers,\n",
    "        attn_heads,\n",
    "        mlp_dim,\n",
    "        cond_embed_dim,\n",
    "        num_experts=4,\n",
    "        active_experts=2,\n",
    "        dropout=0.1,\n",
    "        patchmix_layers=2,\n",
    "        rngs=rngs,\n",
    "        num_classes=10,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "        self.patch_embedder = PatchEmbed(\n",
    "            rngs=rngs, patch_size=patch_size, in_chan=inchannels, embed_dim=embed_dim\n",
    "        )\n",
    "\n",
    "        # conditioning layers\n",
    "        self.time_embedder = TimestepEmbedder(embed_dim)\n",
    "        self.cap_embedder = CaptionEmbedder(cond_embed_dim, embed_dim)\n",
    "        self.label_embedder = LabelEmbedder(\n",
    "            num_classes=num_classes, hidden_size=embed_dim, drop=dropout)\n",
    "        self.cond_attention = CrossAttention(\n",
    "            attn_heads, embed_dim, cond_embed_dim, rngs=rngs\n",
    "        )\n",
    "        self.cond_mlp = SimpleMLP(embed_dim)\n",
    "\n",
    "        # pooling layer\n",
    "        self.pool_mlp = PoolMLP(embed_dim)\n",
    "\n",
    "        self.linear = nnx.Linear(self.embed_dim, self.embed_dim, rngs=rngs)\n",
    "\n",
    "        self.patch_mixer = PatchMixer(embed_dim, attn_heads, patchmix_layers)\n",
    "        self.ditbackbone = DiTBackbone(\n",
    "            patch_size=patch_size,\n",
    "            in_channels=inchannels,\n",
    "            hidden_size=embed_dim,\n",
    "            depth=num_layers,\n",
    "        )\n",
    "\n",
    "        self.outlin_1 = nnx.Linear(embed_dim, embed_dim, rngs=rngs)\n",
    "        self.final_linear = nnx.Linear(\n",
    "            embed_dim, patch_size[0] * patch_size[1] * inchannels, rngs=rngs\n",
    "        )\n",
    "\n",
    "    def __call__(self, x: Array, t: Array, y_cap: Array, mask=None):\n",
    "        bsize, channels, height, width = x.shape\n",
    "        psize_h, psize_w = self.patch_size\n",
    "\n",
    "        x = self.patch_embedder(x)\n",
    "\n",
    "        pos_embed = get_2d_sincos_pos_embed(self.embed_dim, height // psize_h)\n",
    "        pos_embed = jnp.expand_dims(pos_embed, axis=0)\n",
    "        pos_embed = jnp.broadcast_to(pos_embed, (bsize, -1, -1))\n",
    "        x = x + pos_embed\n",
    "\n",
    "        # cond_embed = self.cap_embedder(y_cap) # (b, embdim)\n",
    "        cond_embed = self.label_embedder(y_cap)\n",
    "        time_embed = self.time_embedder(t)\n",
    "        time_embed_unsqueeze = jnp.expand_dims(time_embed, axis=0)\n",
    "\n",
    "        mha_out = self.cond_attention(time_embed_unsqueeze, cond_embed).squeeze(axis=1)\n",
    "        mlp_out = self.cond_mlp(mha_out)\n",
    "\n",
    "        # pooling the conditions\n",
    "        pool_out = self.pool_mlp(jnp.expand_dims(mlp_out, axis=2))\n",
    "        pool_out = jnp.expand_dims((pool_out + time_embed), axis=1)\n",
    "\n",
    "        cond_signal = jnp.expand_dims(self.linear(mlp_out), axis=1)\n",
    "        cond_signal = jnp.broadcast_to(\n",
    "            (cond_signal + pool_out), shape=(-1, x.shape[1], -1)\n",
    "        )\n",
    "\n",
    "        x = x + cond_signal\n",
    "        x = self.patch_mixer(x)\n",
    "\n",
    "        if mask is not None:\n",
    "            x = remove_masked_patches(x, mask)\n",
    "\n",
    "        mlp_out_us = jnp.expand_dims(mlp_out, axis=1)  # unqueezed mlp output\n",
    "        cond = jnp.broadcast_to((mlp_out_us + pool_out), shape=(-1, x.shape[1], -1))\n",
    "\n",
    "        x = x + cond\n",
    "\n",
    "        x = self.ditbackbone(x, time_embed, cond_embed)\n",
    "\n",
    "        x = self.final_linear(x)\n",
    "\n",
    "        # add back masked patches\n",
    "        if mask is not None:\n",
    "            x = add_masked_patches(x, mask)\n",
    "\n",
    "        x = self.ditbackbone.unpatchify(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    # ahhhhhhhh, yess, full model\n",
    "    # wed_nov_13, 4:49\n",
    "\n",
    "    def sample(self, z_latent, cond, sample_steps=50, cfg=2.0):\n",
    "        b_size = z_latent.shape[0]\n",
    "        dt = 1.0 / sample_steps\n",
    "\n",
    "        dt = jnp.array([dt] * b_size)\n",
    "        dt = jnp.reshape(dt, shape=(b_size, *([1] * len(z_latent.shape[1:]))))\n",
    "\n",
    "        images = [z_latent]\n",
    "\n",
    "        for i in range(sample_steps, 0, -1):\n",
    "            t = i / sample_steps\n",
    "            t = (\n",
    "                jnp.array([t] * b_size)\n",
    "                # .to_device(z_latent.device)\n",
    "                .astype(z_latent.dtype)\n",
    "            )\n",
    "\n",
    "            vc = self(z_latent, t, cond, None)\n",
    "            null_cond = jnp.zeros_like(cond)\n",
    "            vu = self.__call__(z_latent, t, null_cond)\n",
    "            vc = vu + cfg * (vc - vu)\n",
    "\n",
    "            z = z_latent - dt * vc\n",
    "            images.append(z)\n",
    "\n",
    "        return images[-1] / config.vaescale_factor\n",
    "\n",
    "randin = jrand.normal(randkey, (1, 4, 32, 32))\n",
    "microdit = MicroDiT(\n",
    "    inchannels=3,\n",
    "    patch_size=(4, 4),\n",
    "    embed_dim=1024,\n",
    "    num_layers=4,\n",
    "    attn_heads=6,\n",
    "    mlp_dim=4 * 1024,\n",
    "    cond_embed_dim=768,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "lGLrvyc4JlJx",
    "outputId": "10965488-ef7e-469b-83ef-98624135ea7a"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "jax.clear_caches()\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IOq2gW7FhkUN",
    "outputId": "c35053a7-b856-4bc1-dd9c-c2bb21046894"
   },
   "outputs": [],
   "source": [
    "# rectifed flow forward pass, loss, and smapling\n",
    "class RectFlow(nnx.Module):\n",
    "    def __init__(self, model: nnx.Module, sigln: bool = True):\n",
    "        self.model = model\n",
    "        self.sigln = sigln\n",
    "\n",
    "    def __call__(self, x_input: Array, cond: Array, mask) -> Array:\n",
    "\n",
    "        b_size = x_input.shape[0]  # batch_sie\n",
    "        rand_t = None\n",
    "\n",
    "        if self.sigln:\n",
    "            rand = jrand.normal(randkey, (b_size,))#.to_device(x_input.device)\n",
    "            rand_t = nnx.sigmoid(rand)\n",
    "        else:\n",
    "            rand_t = jrand.normal(randkey, (b_size,))#.to_device(x_input.device)\n",
    "\n",
    "        inshape = [1] * len(x_input.shape[1:])\n",
    "        texp = rand_t.reshape([b_size, *(inshape)])\n",
    "\n",
    "        z_noise = jrand.normal(\n",
    "            randkey, x_input.shape\n",
    "        )  # input noise with same dim as image\n",
    "        z_noise_t = (1 - texp) * x_input + texp * z_noise\n",
    "\n",
    "        v_thetha = self.model(z_noise_t, rand_t, cond, mask)\n",
    "\n",
    "        mean_dim = list(\n",
    "            range(1, len(x_input.shape))\n",
    "        )  # across all dimensions except the batch dim\n",
    "        mean_square = (z_noise - x_input - v_thetha) ** 2  # squared difference\n",
    "        batchwise_mse_loss = jnp.mean(mean_square, axis=mean_dim)  # mean loss\n",
    "\n",
    "        return jnp.mean(batchwise_mse_loss)\n",
    "\n",
    "    def sample(\n",
    "        self,\n",
    "        input_noise: jax.Array,\n",
    "        cond,\n",
    "        zero_cond=None,\n",
    "        sample_steps: int = 50,\n",
    "        cfg=2.0,\n",
    "    ) -> List[jax.Array]:\n",
    "\n",
    "        batch_size = input_noise.shape[0]\n",
    "\n",
    "        # array reciprocal of sampling steps\n",
    "        d_steps = 1.0 / sample_steps\n",
    "\n",
    "        d_steps = jnp.array([d_steps] * batch_size)#.to_device(input_noise.device)\n",
    "        steps_dim = [1] * len(input_noise.shape[1:])\n",
    "        d_steps = d_steps.reshape([batch_size], *steps_dim)\n",
    "\n",
    "        images = [input_noise]  # noise sequence\n",
    "\n",
    "        for t_step in range(sample_steps):\n",
    "\n",
    "            genstep = t_step / sample_steps  # current step\n",
    "\n",
    "            genstep_batched = jnp.array([genstep] * batch_size)#.to_device(input_noise.device)\n",
    "\n",
    "            cond_output = self.model(\n",
    "                input_noise, genstep_batched, cond\n",
    "            )  # get model output for step\n",
    "\n",
    "            if zero_cond is not None:\n",
    "                # output for zero conditioning\n",
    "                uncond_output = self.model(input_noise, genstep_batched, zero_cond)\n",
    "                cond_output = uncond_output + cfg * (cond_output - uncond_output)\n",
    "\n",
    "            out_noise = input_noise - d_steps * cond_output\n",
    "\n",
    "            images.append(out_noise)\n",
    "\n",
    "        return images\n",
    "\n",
    "\n",
    "# model = MicroDiT(\n",
    "#     inchannels=3,\n",
    "#     patch_size=(4, 4),\n",
    "#     embed_dim=1024,\n",
    "#     num_layers=12,\n",
    "#     attn_heads=6,\n",
    "#     mlp_dim=4 * 1024,\n",
    "#     caption_embed_dim=768,\n",
    "# )\n",
    "\n",
    "rf_engine = RectFlow(microdit)\n",
    "graph, state = nnx.split(rf_engine)\n",
    "n_params = sum([p.size for p in jax.tree.leaves(state)])\n",
    "print(f\"number of parameters: {n_params/1e6:.3f}M\")\n",
    "\n",
    "optimizer = nnx.Optimizer(rf_engine, optax.adamw(learning_rate=config.lr))\n",
    "\n",
    "\n",
    "def wandb_logger(key: str, project_name, run_name):  # wandb logger\n",
    "    # initilaize wandb\n",
    "    wandb.login(key=key)\n",
    "    wandb.init(project=project_name, name=run_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vY09lxpbhkUN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "f1981c49ef7e43d4ab4b1642cc119c51",
      "40602dc7e8444f3ba8081f907794b0f9",
      "5cf87bfab367419c9397503c554be84f",
      "f6c9b62b5897453089bcb2513e2babb2",
      "11d306e6ddfd4b5dbae42a09cb3dad33",
      "63a8a2b3e91a49518efcd0e4178c7947",
      "0fd9f7a9a9a043ec9e19f5966bf77380",
      "48e408ce26ca45d486b86e18b929bebd",
      "31583619dc604c5c9730b6f3632a2223",
      "24f1c781437d49b8b5bc39bc6f5086b9",
      "0e0cec1d1e83477ea91b19baf87710c4",
      "0eaa2c619fbc46a59331abb7de75b771",
      "67df6b5090344c5b8e2e3e405dae9b68",
      "dd3518da98aa44a68a50c6ca77133f91",
      "d18ef27d30624ecb8ecb9970f391a245",
      "f23d8493ee1c47418d24e48e142f97e7",
      "d822f15f78e54a9ba7bc062328517352",
      "d3f0efb5f1d1417fa16f23537fc9ae20",
      "4e7852f255c240118a9603e59e1c8315",
      "895ef9e5d09344558215e16e80ef115b",
      "ecb9b129e1bf446bb710683bd08e1411",
      "10148f9f9d6b4cdcafa6c9b1d9701645"
     ]
    },
    "id": "dfNOgrzFhkUO",
    "outputId": "d2577e90-664f-4950-d66a-b4ae7f91d5dc"
   },
   "outputs": [],
   "source": [
    "def loss_func(model, batch):\n",
    "    img_latents, label = batch\n",
    "    bs, height, width, channels = img_latents.shape\n",
    "    print(img_latents.shape)\n",
    "\n",
    "    img_latents = img_latents * config.vaescale_factor\n",
    "    mask = random_mask(\n",
    "        bs, height, width, patch_size=config.patch_size, mask_ratio=config.mask_ratio\n",
    "    )#.to_device(img_latents.device)\n",
    "    print(f'mask shape {mask.shape}')\n",
    "    loss = model(img_latents, label, mask)\n",
    "    # loss = optax.squared_error(img_latents, logits).mean()\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "@nnx.jit\n",
    "def train_step(model, optimizer, batch):\n",
    "    gradfn = nnx.value_and_grad(loss_func, has_aux=True)\n",
    "    (loss, logits), grads = gradfn(model, batch)\n",
    "    optimizer.update(grads)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def sample_images(model, vae, noise, embeddings):\n",
    "    # Use the stored embeddings\n",
    "    sampled_latents = model.sample(noise, embeddings)\n",
    "\n",
    "    # Decode latents to images\n",
    "    sampled_images = vae.decode(sampled_latents).sample\n",
    "    # images = sample_images\n",
    "    return sampled_images\n",
    "\n",
    "\n",
    "def trainer(model=rf_engine, optimizer=optimizer, train_loader=train_loader):\n",
    "    epochs = 2\n",
    "    train_loss = 0.0\n",
    "    model.train()\n",
    "    # wandb_logger(\n",
    "    #     key=None,\n",
    "    #     model=model,\n",
    "    #     project_name=\"transformer_playjax\",\n",
    "    #     run_name=\"tinygpt-1e-4-bs32-tpu\",\n",
    "    # )\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        for step, batch in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "\n",
    "            train_loss = train_step(model, optimizer, batch)\n",
    "            print(f\"step {step}, loss-> {train_loss.item():.4f}\")\n",
    "\n",
    "            # if step % 100 == 0:\n",
    "            #     sample_latents = model.sample()\n",
    "\n",
    "            # wandb.log({\"loss\": train_loss.item()})\n",
    "\n",
    "        print(f\"epoch {epoch+1}, train loss => {train_loss}\")\n",
    "        save_model(model.model, 'microdit_cifar1.safetensors')\n",
    "\n",
    "\n",
    "trainer()\n",
    "# wandb.finish()\n",
    "print(\"microdit test training in JAX\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SbrrY8GthkUO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-TLP5MSIhkUO"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "028272169cc24756b0dd515348038cf7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "07f1807428a24ca7acd2aefde132b27b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0976f85e431645e98222f8b2063ee223": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_abece1ae08f34e278ea96213691f50b3",
      "placeholder": "",
      "style": "IPY_MODEL_f7a3aa96342b440c8702746cf747603b",
      "value": "100%"
     }
    },
    "0d499f7caab2472aa08debe5c8cf2ee8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0e0cec1d1e83477ea91b19baf87710c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0eaa2c619fbc46a59331abb7de75b771": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_67df6b5090344c5b8e2e3e405dae9b68",
       "IPY_MODEL_dd3518da98aa44a68a50c6ca77133f91",
       "IPY_MODEL_d18ef27d30624ecb8ecb9970f391a245"
      ],
      "layout": "IPY_MODEL_f23d8493ee1c47418d24e48e142f97e7"
     }
    },
    "0fd9f7a9a9a043ec9e19f5966bf77380": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "10148f9f9d6b4cdcafa6c9b1d9701645": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "102f27c0a9344e11a6bb0e614baeb97a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "11d306e6ddfd4b5dbae42a09cb3dad33": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "15ae19a6c2fb46a7a4f1c5a0ed51f8e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "17132346ffcb4f19aa8648b754d13416": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_78f1df6989b74a969bdef7c3ab421ddb",
      "placeholder": "",
      "style": "IPY_MODEL_07f1807428a24ca7acd2aefde132b27b",
      "value": "75%"
     }
    },
    "19c1bee13d9647468555c4b04d4ae166": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d8186960486b4662b41a5ddbc5a9d2c6",
      "placeholder": "",
      "style": "IPY_MODEL_0d499f7caab2472aa08debe5c8cf2ee8",
      "value": ""
     }
    },
    "24f1c781437d49b8b5bc39bc6f5086b9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2bd4a506aaed4d5d91fff4def6932498": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_881d5b59f8b9438eb30ad49649fefa09",
      "max": 4,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a32afe4d938d4df3becfcfbb1be044f1",
      "value": 4
     }
    },
    "2c38a75b7eb1447c81610e43c507dcd6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_19c1bee13d9647468555c4b04d4ae166",
       "IPY_MODEL_c1127e9a09ee429eb320429dac03f32c",
       "IPY_MODEL_2fed7e9265d44ffa9f62987502013fcd"
      ],
      "layout": "IPY_MODEL_028272169cc24756b0dd515348038cf7"
     }
    },
    "2fed7e9265d44ffa9f62987502013fcd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a5a3b162c9cc4c0b882aa1def06a77df",
      "placeholder": "",
      "style": "IPY_MODEL_dea114a4d9c348be8898e7a61aa2d224",
      "value": "0/0[00:00&lt;?,?it/s]"
     }
    },
    "31583619dc604c5c9730b6f3632a2223": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "40602dc7e8444f3ba8081f907794b0f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_63a8a2b3e91a49518efcd0e4178c7947",
      "placeholder": "",
      "style": "IPY_MODEL_0fd9f7a9a9a043ec9e19f5966bf77380",
      "value": "0%"
     }
    },
    "48e408ce26ca45d486b86e18b929bebd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4e7852f255c240118a9603e59e1c8315": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "500aa0e1276148ba948fdcd124d55135": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cd4742586ac640dfa5c7b4a3c12f2858",
      "max": 4,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_666d89e6fad241ca9889c264b27732f3",
      "value": 3
     }
    },
    "5accd3e7541f4a89bcf05b916f064bd5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "5cf87bfab367419c9397503c554be84f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_48e408ce26ca45d486b86e18b929bebd",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_31583619dc604c5c9730b6f3632a2223",
      "value": 0
     }
    },
    "5eb5c51d934f4239bbdf073165b4f649": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e4468268705c41da88047ac1ae29f8ac",
      "placeholder": "",
      "style": "IPY_MODEL_15ae19a6c2fb46a7a4f1c5a0ed51f8e3",
      "value": "3/4[01:16&lt;00:00,10.02it/s]"
     }
    },
    "63a8a2b3e91a49518efcd0e4178c7947": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "666d89e6fad241ca9889c264b27732f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "67df6b5090344c5b8e2e3e405dae9b68": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d822f15f78e54a9ba7bc062328517352",
      "placeholder": "",
      "style": "IPY_MODEL_d3f0efb5f1d1417fa16f23537fc9ae20",
      "value": "0%"
     }
    },
    "78f1df6989b74a969bdef7c3ab421ddb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "85644367060f4cb0b0a068a86a5d2b23": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e4efb4ee931445a985f78063b9be142d",
      "placeholder": "",
      "style": "IPY_MODEL_c6d16bc44ec24d77a8ebfca8d3fdaa3a",
      "value": "4/4[00:00&lt;00:00,9.90it/s]"
     }
    },
    "881d5b59f8b9438eb30ad49649fefa09": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "887e4c382fae4b74b9b64446c9393936": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_17132346ffcb4f19aa8648b754d13416",
       "IPY_MODEL_500aa0e1276148ba948fdcd124d55135",
       "IPY_MODEL_5eb5c51d934f4239bbdf073165b4f649"
      ],
      "layout": "IPY_MODEL_d7550837fd074c18bb7f87f455985756"
     }
    },
    "895ef9e5d09344558215e16e80ef115b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a32afe4d938d4df3becfcfbb1be044f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a5a3b162c9cc4c0b882aa1def06a77df": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "abece1ae08f34e278ea96213691f50b3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c1127e9a09ee429eb320429dac03f32c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5accd3e7541f4a89bcf05b916f064bd5",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ded02ace9cea4e639dd3ceab36899aaa",
      "value": 0
     }
    },
    "c6d16bc44ec24d77a8ebfca8d3fdaa3a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cd4742586ac640dfa5c7b4a3c12f2858": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cdec84504c174422ba9c8e99c5ae1dd1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0976f85e431645e98222f8b2063ee223",
       "IPY_MODEL_2bd4a506aaed4d5d91fff4def6932498",
       "IPY_MODEL_85644367060f4cb0b0a068a86a5d2b23"
      ],
      "layout": "IPY_MODEL_102f27c0a9344e11a6bb0e614baeb97a"
     }
    },
    "d18ef27d30624ecb8ecb9970f391a245": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ecb9b129e1bf446bb710683bd08e1411",
      "placeholder": "",
      "style": "IPY_MODEL_10148f9f9d6b4cdcafa6c9b1d9701645",
      "value": "0/2500[00:01&lt;?,?it/s]"
     }
    },
    "d3f0efb5f1d1417fa16f23537fc9ae20": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d7550837fd074c18bb7f87f455985756": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d8186960486b4662b41a5ddbc5a9d2c6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d822f15f78e54a9ba7bc062328517352": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dd3518da98aa44a68a50c6ca77133f91": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4e7852f255c240118a9603e59e1c8315",
      "max": 2500,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_895ef9e5d09344558215e16e80ef115b",
      "value": 0
     }
    },
    "dea114a4d9c348be8898e7a61aa2d224": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ded02ace9cea4e639dd3ceab36899aaa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e4468268705c41da88047ac1ae29f8ac": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e4efb4ee931445a985f78063b9be142d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ecb9b129e1bf446bb710683bd08e1411": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f1981c49ef7e43d4ab4b1642cc119c51": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_40602dc7e8444f3ba8081f907794b0f9",
       "IPY_MODEL_5cf87bfab367419c9397503c554be84f",
       "IPY_MODEL_f6c9b62b5897453089bcb2513e2babb2"
      ],
      "layout": "IPY_MODEL_11d306e6ddfd4b5dbae42a09cb3dad33"
     }
    },
    "f23d8493ee1c47418d24e48e142f97e7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f6c9b62b5897453089bcb2513e2babb2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_24f1c781437d49b8b5bc39bc6f5086b9",
      "placeholder": "",
      "style": "IPY_MODEL_0e0cec1d1e83477ea91b19baf87710c4",
      "value": "0/2[00:01&lt;?,?it/s]"
     }
    },
    "f7a3aa96342b440c8702746cf747603b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
