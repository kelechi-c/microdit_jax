{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install jax flax einops diffusers transformers wandb tqdm numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax, math, flax, cv2\n",
    "import os, wandb, time, optax\n",
    "from jax import Array, numpy as jnp, random as jrand\n",
    "import numpy as np\n",
    "from flax import nnx\n",
    "from einops import rearrange\n",
    "from tqdm.auto import tqdm\n",
    "from typing import List, Tuple\n",
    "from functools import partial\n",
    "from diffusers import AutoencoderKL\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader, IterableDataset\n",
    "from collections import namedtuple\n",
    "import flax.traverse_util\n",
    "from flax.serialization import to_state_dict\n",
    "import safetensors.flax as safejax\n",
    "from PIL import Image as pillow\n",
    "from diffusers.models.autoencoders.autoencoder_kl import AutoencoderKL\n",
    "# from transformers import AutoTokenizer, T5EncoderModel\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rkey = jrand.key(3)\n",
    "rngs = nnx.Rngs(3)\n",
    "randkey = jrand.key(3)\n",
    "\n",
    "num_devices = jax.device_count()\n",
    "devices = jax.devices()\n",
    "print(f\"found {num_devices} JAX devices => {devices}\")\n",
    "for device in devices:\n",
    "    print(f\"{device} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class config:\n",
    "    vaescale_factor = 0.13025\n",
    "    batch_size = 128\n",
    "    img_size = 256\n",
    "    patch_size = (4, 4)\n",
    "    lr = 1e-4\n",
    "    mask_ratio = 0.75\n",
    "    epochs = 5\n",
    "    data_split = 10_000\n",
    "    cfg_scale = 2.0\n",
    "    vae_channels = 4\n",
    "    celebv_id = \"SwayStar123/CelebV-HQ\"\n",
    "    finevid_id = \"HuggingFaceFV/finevideo\"\n",
    "    pd12_id = \"Spawning/PD12M\"\n",
    "    vae_id = \"madebyollin/sdxl-vae-fp16-fix\"\n",
    "    t5_id = \"google-t5/t5-small\"\n",
    "    mini_data_id = \"uoft-cs/cifar10\"\n",
    "    device_0 = jax.default_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jax/numpy implementation of topk selection\n",
    "def jnp_topk(array: Array, k: int):\n",
    "    topk_tuple = namedtuple(\"topk\", [\"values\", \"ids\"])\n",
    "    array = jnp.asarray(array)\n",
    "    flat = array.ravel()\n",
    "\n",
    "    sort_indices = jnp.argpartition(flat, -k)[-k:]\n",
    "    argsort = jnp.argsort(-flat[sort_indices])  # get sorting ids\n",
    "\n",
    "    sort_idx = sort_indices[argsort]\n",
    "    values = flat[sort_idx]\n",
    "\n",
    "    idx = jnp.unravel_index(sort_idx, array.shape)\n",
    "\n",
    "    if len(idx) == 1:\n",
    "        (idx,) = idx\n",
    "\n",
    "    return topk_tuple(values=values, ids=idx)\n",
    "\n",
    "\n",
    "# save model params in safetensors file\n",
    "def save_model(model: nnx.Module, file: str, dtype):\n",
    "    _, state = nnx.split(model)\n",
    "    params = state.filter(nnx.Param)\n",
    "    state_dict = to_state_dict(params)\n",
    "\n",
    "    state_dict = flax.traverse_util.flatten_dict(state_dict, sep=\".\")\n",
    "\n",
    "    for key in list(state_dict.keys()):\n",
    "        if not isinstance(state_dict[key], Array):\n",
    "            state_dict[key] = jnp.array(state_dict[key])  # type: ignore\n",
    "\n",
    "        state_dict[key] = state_dict[key].astype(dtype)  # type: ignore\n",
    "\n",
    "    safejax.save_file(state_dict, file)  # type: ignore\n",
    "\n",
    "\n",
    "def apply_mask(x: Array, mask, patch_size):\n",
    "    # basically turns the masked values to 0s\n",
    "    bs, c, h, w = x.shape\n",
    "    numpatch_h = h // patch_size[0]\n",
    "    numpatch_w = w // patch_size[1]\n",
    "\n",
    "    mask = jnp.reshape(mask, shape=(bs, numpatch_h, numpatch_w))\n",
    "\n",
    "    mask = jnp.expand_dims(mask, axis=1)\n",
    "    mask = jnp.tile(mask, reps=(1, 1, patch_size[0], patch_size[1]))\n",
    "    mask = jnp.reshape(mask, shape=(bs, 1, h, w))\n",
    "\n",
    "    x_masked = x * mask\n",
    "\n",
    "    return x_masked\n",
    "\n",
    "\n",
    "def random_mask(bs, height, width, patch_size, mask_ratio):\n",
    "    num_patches = (height // patch_size[0]) * (width // patch_size[1])\n",
    "    num_patches_to_mask = int(num_patches * mask_ratio)\n",
    "\n",
    "    rand_array = jrand.normal(randkey, shape=(bs, num_patches))\n",
    "    indices = jnp.argsort(rand_array, axis=1)\n",
    "\n",
    "    mask = jnp.ones(shape=(bs, num_patches))\n",
    "\n",
    "    batch_mask_array = jnp.expand_dims(jnp.arange(bs), axis=1)\n",
    "    mask[batch_mask_array, indices[:, :num_patches_to_mask]] = 0\n",
    "\n",
    "    mask = jnp.reshape(mask, shape=(bs, num_patches))\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "def remove_masked_patches(patches: Array, mask: Array):\n",
    "    mask = jnp.logical_not(jnp.bool(mask))\n",
    "\n",
    "    bs, num_patches, embed_dim = patches.shape\n",
    "    mask = jnp.expand_dims(mask, axis=-1)\n",
    "    mask = jnp.broadcast_to(mask, shape=(-1, -1, embed_dim))\n",
    "    mask_ids = jnp.nonzero(jnp.reshape(mask, (-1)))\n",
    "    unmasked_patches = jnp.reshape(patches, shape=-1)\n",
    "    unmasked_patches = jnp.take(unmasked_patches, mask_ids[0]).reshape(\n",
    "        bs, -1, embed_dim\n",
    "    )\n",
    "\n",
    "    return unmasked_patches\n",
    "\n",
    "\n",
    "def add_masked_patches(patches: Array, mask: Array):\n",
    "    # Ensure mask is a boolean tensor\n",
    "    mask = jnp.bool(mask)\n",
    "\n",
    "    bs, num_patches, embed_dim = mask.shape[0], mask.shape[1], patches.shape[-1]\n",
    "\n",
    "    # Create a tensor of zeros with the same shape and dtype as the patches tensor\n",
    "    full_patches = jnp.zeros(shape=(bs, num_patches, embed_dim))\n",
    "\n",
    "    # Iterate over each batch and place unmasked patches back in their original positions\n",
    "    for b in range(bs):\n",
    "        # Use the mask to place unmasked patches back in the correct positions\n",
    "        full_patches[b, mask[b]] = patches[b].astype(full_patches.dtype)\n",
    "\n",
    "    return full_patches\n",
    "\n",
    "\n",
    "## nov_14_0453\n",
    "\n",
    "# T5 text encoder\n",
    "# t5_tokenizer = AutoTokenizer.from_pretrained(config.t5_id)\n",
    "# t5_model = T5EncoderModel.from_pretrained(config.t5_id)\n",
    "\n",
    "\n",
    "# def text_t5_encode(text_input: str, tokenizer=t5_tokenizer, model=t5_model):\n",
    "#     input_ids = tokenizer(text_input, return_tensors=\"np\").input_ids  # Batch size 1\n",
    "#     outputs = model(input_ids=input_ids)\n",
    "#     last_hidden_states = outputs.last_hidden_state\n",
    "\n",
    "#     return last_hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data loading\n",
    "image_data = load_dataset(\n",
    "    config.mini_data_id, streaming=True, split=\"train\", trust_remote_code=True\n",
    ").take(config.split)\n",
    "\n",
    "vae = AutoencoderKL.from_pretrained(config.vae_id).to(config.device_0)\n",
    "\n",
    "def load_image(url):\n",
    "    image = pillow.open(urlopen(url=url))\n",
    "    img_array = np.array(image)\n",
    "    resized = cv2.resize(img_array, dsize=(config.img_size, config.img_size))\n",
    "\n",
    "    return resized / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randkey = jrand.key(3)\n",
    "\n",
    "\n",
    "# class ImageData(IterableDataset):\n",
    "#     def __init__(self, dataset=image_data):\n",
    "#         super().__init__()\n",
    "#         self.dataset = dataset\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return config.data_split\n",
    "\n",
    "#     def __iter__(self):\n",
    "#         for sample in self.dataset:\n",
    "#             image = sample[\"img_url\"]  # type: ignore\n",
    "#             image = load_image(image)\n",
    "#             img_latents = vae.encode(image)\n",
    "#             img_latents = img_latents.numpy()\n",
    "#             caption_encoded = text_t5_encode(sample[\"caption\"])  # type: ignore\n",
    "\n",
    "#             image = jnp.array(image)\n",
    "#             text_encoding = jnp.array(caption_encoded)\n",
    "\n",
    "#             yield image, text_encoding\n",
    "\n",
    "\n",
    "class ImageClassData(IterableDataset):\n",
    "    def __init__(self, dataset=image_data):\n",
    "        super().__init__()\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return config.data_split\n",
    "\n",
    "    def __iter__(self):\n",
    "        for sample in self.dataset:\n",
    "            image = sample[\"img_url\"]  # type: ignore\n",
    "            image = load_image(image)\n",
    "            img_latents = vae.encode(image)\n",
    "            img_latents = img_latents.numpy()\n",
    "\n",
    "            image = jnp.array(image)\n",
    "            label = jnp.array(sample[\"label\"])\n",
    "\n",
    "            yield image, label\n",
    "\n",
    "\n",
    "dataset = ImageClassData()\n",
    "train_loader = DataLoader(dataset, batch_size=config.batch_size)\n",
    "\n",
    "iv = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modulation with shift and scale\n",
    "def modulate(x_array: Array, shift, scale) -> Array:\n",
    "    x = x_array * scale.unsqueeze(1)\n",
    "    x = x + shift.unsqueeze(1)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "# equivalnet of F.lineat\n",
    "def linear(array: Array, weight: Array, bias: Array | None = None) -> Array:\n",
    "    out = jnp.dot(array, weight)\n",
    "\n",
    "    if bias is not None:\n",
    "        out += bias\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from https://github.com/facebookresearch/mae/blob/main/util/pos_embed.py\n",
    "def get_2d_sincos_pos_embed(embed_dim, grid_size, cls_token=False, extra_tokens=0):\n",
    "    \"\"\"\n",
    "    grid_size: int of the grid height and width\n",
    "    return:\n",
    "    pos_embed: [grid_size*grid_size, embed_dim] or [1+grid_size*grid_size, embed_dim] (w/ or w/o cls_token)\n",
    "    \"\"\"\n",
    "    grid_h = jnp.arange(grid_size, dtype=jnp.float32)\n",
    "    grid_w = jnp.arange(grid_size, dtype=jnp.float32)\n",
    "    grid = jnp.meshgrid(grid_w, grid_h)  # here w goes first\n",
    "    grid = jnp.stack(grid, axis=0)\n",
    "\n",
    "    grid = grid.reshape([2, 1, grid_size, grid_size])\n",
    "    pos_embed = get_2d_sincos_pos_embed_from_grid(embed_dim, grid)\n",
    "    if cls_token and extra_tokens > 0:\n",
    "        pos_embed = jnp.concatenate(\n",
    "            [jnp.zeros([extra_tokens, embed_dim]), pos_embed], axis=0\n",
    "        )\n",
    "    return pos_embed\n",
    "\n",
    "\n",
    "def get_2d_sincos_pos_embed_from_grid(embed_dim, grid):\n",
    "    assert embed_dim % 2 == 0\n",
    "\n",
    "    # use half of dimensions to encode grid_h\n",
    "    emb_h = get_1d_sincos_pos_embed_from_grid(embed_dim // 2, grid[0])  # (H*W, D/2)\n",
    "    emb_w = get_1d_sincos_pos_embed_from_grid(embed_dim // 2, grid[1])  # (H*W, D/2)\n",
    "\n",
    "    emb = jnp.concatenate([emb_h, emb_w], axis=1)  # (H*W, D)\n",
    "    return emb\n",
    "\n",
    "\n",
    "def get_1d_sincos_pos_embed_from_grid(embed_dim, pos):\n",
    "    \"\"\"\n",
    "    embed_dim: output dimension for each position\n",
    "    pos: a list of positions to be encoded: size (M,)\n",
    "    out: (M, D)\n",
    "    \"\"\"\n",
    "    assert embed_dim % 2 == 0\n",
    "    omega = jnp.arange(embed_dim // 2, dtype=jnp.float64)\n",
    "    omega /= embed_dim / 2.0\n",
    "    omega = 1.0 / 10000**omega  # (D/2,)\n",
    "\n",
    "    pos = pos.reshape(-1)  # (M,)\n",
    "    out = jnp.einsum(\"m,d->md\", pos, omega)  # (M, D/2), outer product\n",
    "\n",
    "    emb_sin = jnp.sin(out)  # (M, D/2)\n",
    "    emb_cos = jnp.cos(out)  # (M, D/2)\n",
    "\n",
    "    emb = jnp.concatenate([emb_sin, emb_cos], axis=1)  # (M, D)\n",
    "\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input patchify layer, 2D image to patches\n",
    "class PatchEmbed(nnx.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        rngs: nnx.Rngs = rngs,\n",
    "        patch_size=4,\n",
    "        img_size=256,\n",
    "        in_chan: int = 3,\n",
    "        embed_dim: int = 768,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.patch_size = (patch_size, patch_size)\n",
    "        self.img_size = img_size\n",
    "        self.gridsize = tuple([s // p for s, p in zip(img_size, patch_size)])\n",
    "        self.num_patches = self.gridsize[0] * self.gridsize[1]\n",
    "        linear_init = nnx.initializers.constant(0)\n",
    "\n",
    "        self.conv_project = nnx.Conv(\n",
    "            in_chan,\n",
    "            embed_dim,\n",
    "            kernel_size=patch_size,\n",
    "            strides=patch_size,\n",
    "            rngs=rngs,\n",
    "        )\n",
    "\n",
    "    def __call__(self, img: Array) -> Array:\n",
    "        x = self.conv_project(img)\n",
    "        x = x.flatten()\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "# embeds a flat vector\n",
    "class VectorEmbedder(nnx.Module):\n",
    "    def __init__(self, input_dim, hidden_size, rngs=rngs):\n",
    "        super().__init__()\n",
    "        self.linear_1 = nnx.Linear(input_dim, hidden_size, rngs=rngs)\n",
    "        self.linear_2 = nnx.Linear(hidden_size, hidden_size, rngs=rngs)\n",
    "\n",
    "    def __call__(self, x: Array):\n",
    "        x = nnx.silu(self.linear_1(x))\n",
    "        x = self.linear_2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class TimestepEmbedder(nnx.Module):\n",
    "    def __init__(self, hidden_size, freq_embed_size=256):\n",
    "        super().__init__()\n",
    "        self.lin_1 = nnx.Linear(freq_embed_size, hidden_size, rngs=rngs)\n",
    "        self.lin_2 = nnx.Linear(hidden_size, hidden_size, rngs=rngs)\n",
    "        self.freq_embed_size = freq_embed_size\n",
    "\n",
    "    @staticmethod\n",
    "    def timestep_embedding(time_array: Array, dim, max_period=10000):\n",
    "        half = dim // 2\n",
    "        freqs = jnp.exp(-math.log(max_period) * jnp.arange(0, half) / half).to_device(\n",
    "            time_array.device\n",
    "        )\n",
    "        args = jnp.float_(time_array[:, None]) * freqs[None]\n",
    "\n",
    "        embedding = jnp.concat([jnp.cos(args), jnp.sin(args)], axis=-1)\n",
    "        if dim % 2:\n",
    "            embedding = jnp.concat(\n",
    "                [embedding, jnp.zeros_like(embedding[:, :1])], axis=-1\n",
    "            )\n",
    "\n",
    "        return embedding\n",
    "\n",
    "    def __call__(self, x: Array) -> Array:\n",
    "        t_freq = self.timestep_embedding(x, self.freq_embed_size)\n",
    "        t_embed = nnx.silu(self.lin_1(t_freq))\n",
    "\n",
    "        return self.lin_2(t_embed)\n",
    "\n",
    "\n",
    "class LabelEmbedder(nnx.Module):\n",
    "    def __init__(self, num_classes, hidden_size, drop):\n",
    "        super().__init__()\n",
    "        use_cfg_embeddings = drop > 0\n",
    "        self.embedding_table = nnx.Embed(\n",
    "            num_classes + use_cfg_embeddings, hidden_size, rngs=rngs\n",
    "        )\n",
    "        self.num_classes = num_classes\n",
    "        self.dropout = drop\n",
    "\n",
    "    def token_drop(self, labels, force_drop_ids=None) -> Array:\n",
    "        if force_drop_ids is None:\n",
    "            drop_ids = jrand.normal(key=rkey, shape=labels.shape[0]).to_device(\n",
    "                labels.device\n",
    "            )\n",
    "        else:\n",
    "            drop_ids = force_drop_ids == 1\n",
    "\n",
    "        labels = jnp.where(drop_ids, self.num_classes, labels)\n",
    "\n",
    "        return labels\n",
    "\n",
    "    def __call__(self, labels, train: bool, force_drop_ids=None) -> Array:\n",
    "        use_drop = self.dropout > 0\n",
    "        if (train and use_drop) or (force_drop_ids is not None):\n",
    "            labels = self.token_drop(labels, force_drop_ids)\n",
    "\n",
    "        label_embeds = self.embedding_table(labels)\n",
    "\n",
    "        return label_embeds\n",
    "\n",
    "\n",
    "class CaptionEmbedder:\n",
    "    def __init__(self, cap_embed_dim, embed_dim):\n",
    "        super().__init__()\n",
    "        self.linear_1 = nnx.Linear(cap_embed_dim, embed_dim, rngs=rngs)\n",
    "        self.linear_2 = nnx.Linear(embed_dim, embed_dim, rngs=rngs)\n",
    "\n",
    "    def __call__(self, x: Array) -> Array:\n",
    "        x = nnx.silu(self.linear_1(x))\n",
    "        x = self.linear_2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class SimpleMLP(nnx.Module):\n",
    "    def __init__(self, embed_dim):\n",
    "        super().__init__()\n",
    "        self.linear_1 = nnx.Linear(embed_dim, embed_dim, rngs=rngs)\n",
    "        self.linear_2 = nnx.Linear(embed_dim, embed_dim, rngs=rngs)\n",
    "\n",
    "    def __call__(self, x: Array) -> Array:\n",
    "        x = nnx.silu(self.linear_1(x))\n",
    "        x = self.linear_2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "# Pool + MLP for (MHA + MLP)\n",
    "class PoolMLP(nnx.Module):\n",
    "    def __init__(self, embed_dim):\n",
    "        super().__init__()\n",
    "        self.linear_1 = nnx.Linear(embed_dim, embed_dim, rngs=rngs)\n",
    "        self.linear_2 = nnx.Linear(embed_dim, embed_dim, rngs=rngs)\n",
    "\n",
    "    def __call__(self, x: Array) -> Array:\n",
    "        x = nnx.avg_pool(x, 1, 1)\n",
    "        x = jnp.reshape(x, shape=(x.shape[0], -1))\n",
    "        x = nnx.gelu(self.linear_1(x))\n",
    "        x = self.linear_2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "#### MoE Gate\n",
    "class MoEGate(nnx.Module):\n",
    "    def __init__(\n",
    "        self, embed_dim, num_experts=8, experts_per_token=2, aux_loss_alpha=0.01\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.top_k = experts_per_token\n",
    "        self.routed_exoerts = num_experts\n",
    "        self.score_func = \"softmax\"\n",
    "        self.alpha = aux_loss_alpha\n",
    "        self.seq_aux = False\n",
    "\n",
    "        # top_k selection algo\n",
    "        self.norm_topk_prob = False\n",
    "        self.gating_dim = embed_dim\n",
    "        param_init = nnx.initializers.he_uniform()\n",
    "        self.weight = nnx.Param(jnp.empty((self.routed_exoerts, self.gating_dim)))\n",
    "        # self.linear_gate = nnx.Linear()\n",
    "\n",
    "    def __call__(self, hidden_states: Array) -> Tuple:\n",
    "        bsize, seq_len, h = hidden_states.shape\n",
    "        # gating score\n",
    "        hidden_states = jnp.reshape(hidden_states, (-1, h))\n",
    "        logits = jnp.dot(hidden_states, self.weight[\"Array\"])\n",
    "        scores = nnx.softmax(logits, axis=-1)\n",
    "\n",
    "        topk_idx, topk_weight = jax.lax.top_k(scores, k=self.top_k)\n",
    "\n",
    "        # normalize to sum to 1\n",
    "        if self.top_k > 1 and self.norm_topk_prob:\n",
    "            denominator = jnp.sum(topk_weight, axis=-1, keepdims=True) + 1e-20\n",
    "            topk_weight = topk_weight / denominator\n",
    "\n",
    "        # expert level computation of auxiliary loss\n",
    "        # always compute topk based on naive greedy topk method\n",
    "        if self.train and self.alpha > 0.0:\n",
    "            scores_for_aux = scores\n",
    "            aux_topk = self.top_k\n",
    "            aux_loss = 0.0\n",
    "\n",
    "            topk_idx_for_auxloss = jnp.reshape(topk_idx, (bsize, -1))\n",
    "            if self.seq_aux:\n",
    "                scores_for_seq_aux = jnp.reshape(scores_for_aux, (bsize, seq_len, -1))\n",
    "                ce = jnp.zeros(\n",
    "                    (bsize, self.routed_exoerts), device=hidden_states.device\n",
    "                )\n",
    "                ones_add = jnp.ones((bsize, seq_len * aux_topk))\n",
    "                ce = jnp.add.at(ce, 1, ones_add)\n",
    "                ce /= seq_len * aux_topk / self.routed_exoerts\n",
    "\n",
    "                aux_loss = (ce * scores_for_seq_aux.mean(axis=1)).sum(\n",
    "                    axis=1\n",
    "                ).mean() * self.alpha\n",
    "\n",
    "            else:\n",
    "                mask_ce = nnx.one_hot(\n",
    "                    jnp.reshape(topk_idx_for_auxloss, (-1)),\n",
    "                    num_classes=self.routed_exoerts,\n",
    "                )\n",
    "                ce = mask_ce.astype(jnp.float32).mean(0)\n",
    "                pi = scores_for_aux.mean()\n",
    "                fi = ce * self.routed_exoerts\n",
    "                aux_loss = (pi * fi).sum() * self.alpha\n",
    "\n",
    "        else:\n",
    "            aux_loss = None\n",
    "\n",
    "        return topk_idx, topk_weight, aux_loss\n",
    "\n",
    "\n",
    "# mixture of experts MLP layer\n",
    "class MoEMLP(nnx.Module):\n",
    "    def __init__(self, hidden_size, intersize, pretrain_tp=2):\n",
    "        self.hidden_size = hidden_size\n",
    "        self.intersize = intersize\n",
    "        self.pretrain_tp = pretrain_tp\n",
    "        self.gate_project = nnx.Linear(\n",
    "            self.hidden_size, self.intersize, use_bias=False, rngs=rngs\n",
    "        )\n",
    "        self.up_project = nnx.Linear(\n",
    "            self.hidden_size, self.intersize, use_bias=False, rngs=rngs\n",
    "        )\n",
    "        self.down_project = nnx.Linear(\n",
    "            self.intersize, self.hidden_size, use_bias=False, rngs=rngs\n",
    "        )\n",
    "\n",
    "    def __call__(self, x_input: Array):\n",
    "        down_proj = None\n",
    "\n",
    "        if self.pretrain_tp > 1:\n",
    "            w_slice = self.intersize // self.pretrain_tp\n",
    "            gate_slices = jnp.split(self.gate_project.kernel[1:], w_slice, axis=0)\n",
    "            up_slices = jnp.split(self.up_project.kernel[1:], w_slice, axis=0)\n",
    "            down_slices = jnp.split(self.down_project.kernel[1:], w_slice, axis=1)\n",
    "\n",
    "            gate_proj = jnp.concat(\n",
    "                [linear(x_input, gate_slices[k]) for k in range(self.pretrain_tp)],\n",
    "                axis=-1,\n",
    "            )\n",
    "            up_proj = jnp.concat(\n",
    "                [linear(x_input, up_slices[k]) for k in range(self.pretrain_tp)],\n",
    "                axis=-1,\n",
    "            )\n",
    "            inter_states = jnp.split((nnx.silu(gate_proj) * up_proj), w_slice, axis=-1)\n",
    "            down_proj = [\n",
    "                linear(inter_states[k], down_slices[k]) for k in range(self.pretrain_tp)\n",
    "            ]\n",
    "            down_proj = sum(down_proj)\n",
    "\n",
    "        else:\n",
    "            activated_x = nnx.silu(self.gate_project(x_input)) * self.up_project(\n",
    "                x_input\n",
    "            )\n",
    "            down_proj = self.down_project(activated_x)\n",
    "\n",
    "        return down_proj\n",
    "\n",
    "\n",
    "class SparseMoEBlock(nnx.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embed_dim,\n",
    "        mlp_ratio=4,\n",
    "        num_experts=8,\n",
    "        experts_per_token=2,\n",
    "        train: bool = True,\n",
    "        rngs=rngs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.experts_pertoken = experts_per_token\n",
    "        self.expert_models = [\n",
    "            MoEMLP(hidden_size=embed_dim, intersize=mlp_ratio * embed_dim)\n",
    "            for _ in range(num_experts)\n",
    "        ]\n",
    "        # self.experts = nnx.Sequential(*self.expert_models)\n",
    "        self.router_gate = MoEGate(embed_dim, num_experts)\n",
    "        self.n_shared_experts = 2\n",
    "        self.training = train\n",
    "\n",
    "        if self.n_shared_experts is not None:\n",
    "            intermediate_size = embed_dim * self.n_shared_experts\n",
    "            self.shared_experts = MoEMLP(\n",
    "                hidden_size=embed_dim, intersize=intermediate_size\n",
    "            )\n",
    "\n",
    "    def __call__(self, hidden_states: Array):\n",
    "        identity = hidden_states\n",
    "        og_shape = hidden_states.shape\n",
    "        topk_idx, topk_weight, aux_loss = self.router_gate(hidden_states)\n",
    "        y = jrand.normal(rkey, shape=og_shape)  # init as random array\n",
    "\n",
    "        hidden_states = jnp.reshape(hidden_states, (-1, hidden_states.shape[1:]))\n",
    "        flat_topk_idx = jnp.reshape(topk_idx, shape=(-1))\n",
    "\n",
    "        if self.train:\n",
    "            hidden_states = jnp.repeat(\n",
    "                hidden_states, repeats=self.experts_pertoken, axis=0\n",
    "            )\n",
    "            y = jnp.empty_like(hidden_states, dtype=hidden_states.dtype)\n",
    "\n",
    "            for k, expert in enumerate(self.expert_models):\n",
    "                y[flat_topk_idx == k] = expert(hidden_states[flat_topk_idx == k]).astype(hidden_states.dtype)  # type: ignore\n",
    "\n",
    "            y = jnp.reshape(y, shape=(*topk_weight.shape, -1)) * jnp.expand_dims(\n",
    "                topk_weight, axis=-1\n",
    "            ).sum(axis=1)\n",
    "            y = jnp.reshape(y, shape=(og_shape))\n",
    "            \n",
    "            # TODO: Auxiliary loss add\n",
    "\n",
    "        else:\n",
    "            y = None\n",
    "\n",
    "        if self.shared_experts is not None:\n",
    "            y = y + self.shared_experts(identity)  # type: ignore\n",
    "\n",
    "        return y\n",
    "\n",
    "    def moe_infer(self, x_input):\n",
    "        pass\n",
    "\n",
    "\n",
    "# self attention block\n",
    "class SelfAttention(nnx.Module):\n",
    "    def __init__(self, attn_heads, embed_dim, rngs: nnx.Rngs, drop=0.1):\n",
    "        super().__init__()\n",
    "        self.attn_heads = attn_heads\n",
    "        self.head_dim = embed_dim // attn_heads\n",
    "\n",
    "        linear_init = nnx.initializers.xavier_uniform()\n",
    "        linear_bias_init = nnx.initializers.constant(0)\n",
    "\n",
    "        self.q_linear = nnx.Linear(\n",
    "            embed_dim,\n",
    "            embed_dim,\n",
    "            rngs=rngs,\n",
    "            bias_init=linear_bias_init,\n",
    "            kernel_init=linear_init,\n",
    "        )\n",
    "        self.k_linear = nnx.Linear(embed_dim, embed_dim, rngs=rngs)\n",
    "        self.v_linear = nnx.Linear(embed_dim, embed_dim, rngs=rngs)\n",
    "\n",
    "        self.outproject = nnx.Linear(\n",
    "            embed_dim, embed_dim, rngs=rngs, bias_init=linear_bias_init\n",
    "        )\n",
    "        self.dropout = nnx.Dropout(drop, rngs=rngs)\n",
    "\n",
    "    def __call__(self, x_input: jax.Array) -> jax.Array:\n",
    "        q = self.q_linear(x_input)\n",
    "        k = self.k_linear(x_input)\n",
    "        v = self.v_linear(x_input)\n",
    "\n",
    "        q, k, v = map(\n",
    "            lambda x: rearrange(x, \"b l (h d) -> b h l d\", h=self.attn_heads), (q, k, v)\n",
    "        )\n",
    "\n",
    "        qk = q @ jnp.matrix_transpose(k)\n",
    "        attn_logits = qk / math.sqrt(self.head_dim)  # attention computation\n",
    "\n",
    "        attn_score = nnx.softmax(attn_logits, axis=-1)\n",
    "        attn_output = attn_score @ v\n",
    "\n",
    "        output = rearrange(attn_output, \"b h l d -> b l (h d)\")\n",
    "        output = self.dropout(self.outproject(output))\n",
    "        print(f\"attn out shape => {output.shape}\")\n",
    "        return output\n",
    "\n",
    "\n",
    "class CrossAttention(nnx.Module):\n",
    "    def __init__(self, attn_heads, embed_dim, cond_dim, rngs: nnx.Rngs, drop=0.1):\n",
    "        super().__init__()\n",
    "        self.attn_heads = attn_heads\n",
    "        self.head_dim = embed_dim // attn_heads\n",
    "\n",
    "        linear_init = nnx.initializers.xavier_uniform()\n",
    "        linear_bias_init = nnx.initializers.constant(0)\n",
    "\n",
    "        self.q_linear = nnx.Linear(\n",
    "            embed_dim,\n",
    "            embed_dim,\n",
    "            rngs=rngs,\n",
    "            bias_init=linear_bias_init,\n",
    "            kernel_init=linear_init,\n",
    "        )\n",
    "\n",
    "        self.k_linear = nnx.Linear(cond_dim, embed_dim, rngs=rngs)\n",
    "        self.v_linear = nnx.Linear(cond_dim, embed_dim, rngs=rngs)\n",
    "\n",
    "        self.outproject = nnx.Linear(\n",
    "            embed_dim, embed_dim, rngs=rngs, bias_init=linear_bias_init\n",
    "        )\n",
    "        self.dropout = nnx.Dropout(drop, rngs=rngs)\n",
    "\n",
    "    def __call__(self, x_input: jax.Array, y_cond: Array) -> jax.Array:\n",
    "        q = self.q_linear(x_input)\n",
    "        k = self.k_linear(y_cond)\n",
    "        v = self.v_linear(y_cond)\n",
    "\n",
    "        q, k, v = map(\n",
    "            lambda x: rearrange(x, \"b l (h d) -> b h l d\", h=self.attn_heads), (q, k, v)\n",
    "        )\n",
    "\n",
    "        qk = q @ jnp.matrix_transpose(k)\n",
    "        attn_logits = qk / math.sqrt(self.head_dim)  # attention computation\n",
    "\n",
    "        attn_score = nnx.softmax(attn_logits, axis=-1)\n",
    "        attn_output = attn_score @ v\n",
    "\n",
    "        output = rearrange(attn_output, \"b h l d -> b l (h d)\")\n",
    "        output = self.dropout(self.outproject(output))\n",
    "        print(f\"attn out shape => {output.shape}\")\n",
    "        return output\n",
    "\n",
    "\n",
    "###############\n",
    "# DiT blocks_ #\n",
    "###############\n",
    "\n",
    "\n",
    "class DiTBlock(nnx.Module):\n",
    "    def __init__(self, hidden_size=768, num_heads=6):\n",
    "        super().__init__()\n",
    "\n",
    "        # initializations\n",
    "        linear_init = nnx.initializers.xavier_uniform()\n",
    "        lnbias_init = nnx.initializers.constant(0)\n",
    "        lnweight_init = nnx.initializers.constant(0)\n",
    "\n",
    "        self.norm_1 = nnx.LayerNorm(\n",
    "            hidden_size, epsilon=1e-6, rngs=rngs, bias_init=lnbias_init\n",
    "        )\n",
    "        self.attention = SelfAttention(num_heads, hidden_size, rngs=rngs)\n",
    "        self.norm_2 = nnx.LayerNorm(hidden_size, epsilon=1e-6, rngs=rngs)\n",
    "\n",
    "        self.adaln_linear = nnx.Linear(\n",
    "            hidden_size,\n",
    "            6 * hidden_size,\n",
    "            use_bias=True,\n",
    "            bias_init=linear_init,\n",
    "            rngs=rngs,\n",
    "            kernel_init=lnweight_init,\n",
    "        )\n",
    "        self.moe_block = SparseMoEBlock(hidden_size)\n",
    "\n",
    "    def __call__(self, x_img: Array):\n",
    "        x_input = self.adaln_linear(nnx.silu(x_img))\n",
    "        shift_msa, scale_msa, gate_msa, shift_mlp, scale_mlp, gate_mlp = (\n",
    "            jnp.array_split(x_input, 6)\n",
    "        )\n",
    "\n",
    "        attn_mod_x = self.attention(\n",
    "            modulate(self.norm_1(x_input), shift_msa, scale_msa)\n",
    "        )\n",
    "        x = x_input + jnp.expand_dims(gate_msa, 1) * attn_mod_x\n",
    "\n",
    "        mlp_mod_x = self.moe_block(modulate(self.norm_2(x), shift_mlp, scale_mlp))\n",
    "        x = x + jnp.expand_dims(gate_mlp, 1) * mlp_mod_x\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class FinalMLP(nnx.Module):\n",
    "    def __init__(self, hidden_size, patch_size, out_channels):\n",
    "        super().__init__()\n",
    "        # linear_init = nnx.initializers.xavier_uniform()\n",
    "        linear_init = nnx.initializers.constant(0)\n",
    "\n",
    "        self.norm_final = nnx.LayerNorm(hidden_size, epsilon=1e-6, rngs=rngs)\n",
    "        self.linear = nnx.Linear(\n",
    "            hidden_size,\n",
    "            patch_size * patch_size * out_channels,\n",
    "            rngs=rngs,\n",
    "            kernel_init=linear_init,\n",
    "            bias_init=linear_init,\n",
    "        )\n",
    "        self.adaln_linear = nnx.Linear(\n",
    "            hidden_size,\n",
    "            2 * hidden_size,\n",
    "            rngs=rngs,\n",
    "            kernel_init=linear_init,\n",
    "            bias_init=linear_init,\n",
    "        )\n",
    "\n",
    "    def __call__(self, x_input: Array, cond: Array):\n",
    "        linear_cond = nnx.silu(self.adaln_linear(cond))\n",
    "        shift, scale = jnp.array_split(linear_cond, 2, axis=1)\n",
    "\n",
    "        x = modulate(self.norm_final(x_input), shift, scale)\n",
    "        x = self.linear(x)\n",
    "\n",
    "        return\n",
    "\n",
    "\n",
    "class DiTBackbone(nnx.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        patch_size=4,\n",
    "        in_channels=4,\n",
    "        hidden_size=1024,\n",
    "        depth=8,\n",
    "        attn_heads=6,\n",
    "        learn_sigma=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.learn_sigma = learn_sigma\n",
    "        self.in_chan = in_channels\n",
    "        self.out_channels = in_channels * 2 if learn_sigma else in_channels\n",
    "        self.patch_size = patch_size\n",
    "        self.attn_heads = attn_heads\n",
    "\n",
    "        self.img_embedder = PatchEmbed(\n",
    "            img_size=config.img_size, in_chan=in_channels, embed_dim=hidden_size\n",
    "        )\n",
    "        self.time_embedder = TimestepEmbedder(hidden_size)\n",
    "\n",
    "        num_patches = self.img_embedder.num_patches\n",
    "\n",
    "        self.pos_embed = nnx.Param(jnp.zeros(shape=(1, num_patches, hidden_size)))\n",
    "        pos_embed = get_2d_sincos_pos_embed(\n",
    "            self.pos_embed.shape[-1], int(self.img_embedder.num_patches**0.5)\n",
    "        )\n",
    "        sincos2d_data = jnp.expand_dims(pos_embed.astype(jnp.float32), axis=0)\n",
    "        self.pos_embed.copy_from(sincos2d_data)  # type: ignore\n",
    "\n",
    "        dit_blocks = [DiTBlock(hidden_size, num_heads=attn_heads) for _ in range(depth)]\n",
    "        self.dit_layers = nnx.Sequential(*dit_blocks)\n",
    "        self.final_mlp = FinalMLP(hidden_size, patch_size, self.out_channels)\n",
    "\n",
    "    def unpatchify(self, x: Array) -> Array:\n",
    "        c = self.out_channels\n",
    "        p = self.img_embedder.patch_size[0]\n",
    "        h = w = int(x.shape[1] ** 0.5)\n",
    "        assert h * w == x.shape[1]\n",
    "\n",
    "        x = jnp.reshape(x, shape=(x.shape[0], h, w, p, p, c))\n",
    "        x = jnp.einsum(\"nhwpqc->nchpwq\", x)\n",
    "        img = jnp.reshape(x, shape=(x.shape[0], c, h * p, w * p))\n",
    "\n",
    "        return img\n",
    "\n",
    "    def __call__(self, x: Array, t: Array, y_cond: Array):\n",
    "        x = self.img_embedder(x) + self.pos_embed\n",
    "        t_embed = self.time_embedder(t)\n",
    "\n",
    "        cond = t_embed + y_cond\n",
    "        x = self.dit_layers(x, cond)\n",
    "        x = self.final_mlp(x, cond)  # type: ignore\n",
    "        x = self.unpatchify(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def cfg_forward(self, x_img, t, y_cond, cfg_scale):\n",
    "        half = x_img[: len(x_img) // 2]\n",
    "        combined = jnp.concat([half, half], axis=0)\n",
    "        model_out = self.__call__(combined, t, y_cond)\n",
    "\n",
    "        eps, rest = model_out[:, :3], model_out[:, 3:]\n",
    "        cond_eps, uncond_eps = jnp.split(eps, len(eps) // 2, axis=0)\n",
    "\n",
    "        half_eps = uncond_eps + cfg_scale * (cond_eps - uncond_eps)\n",
    "        eps = jnp.concat([half_eps, half_eps], axis=0)\n",
    "        cfg_out = jnp.concat([eps, rest], axis=1)\n",
    "\n",
    "        return cfg_out\n",
    "\n",
    "\n",
    "########################\n",
    "# Patch Mixer components\n",
    "########################\n",
    "\n",
    "\n",
    "class EncoderMLP(nnx.Module):\n",
    "    def __init__(self, hidden_size, rngs: nnx.Rngs, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.layernorm = nnx.LayerNorm(hidden_size, rngs=rngs)\n",
    "\n",
    "        self.linear1 = nnx.Linear(hidden_size, 2 * hidden_size, rngs=rngs)\n",
    "        self.linear2 = nnx.Linear(2 * hidden_size, hidden_size, rngs=rngs)\n",
    "        self.dropout = nnx.Dropout(dropout, rngs=rngs)\n",
    "\n",
    "    def __call__(self, x_input: jax.Array) -> jax.Array:\n",
    "        x = self.layernorm(x_input)\n",
    "        x = nnx.silu(self.linear1(x))\n",
    "        x = self.linear2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class TransformerEncoderBlock(nnx.Module):\n",
    "    def __init__(self, embed_dim, num_heads):\n",
    "        super().__init__()\n",
    "        self.layernorm = nnx.LayerNorm(embed_dim, epsilon=1e-6, rngs=rngs)\n",
    "        self.self_attention = SelfAttention(num_heads, embed_dim, rngs=rngs)\n",
    "        self.mlp_layer = EncoderMLP(embed_dim, rngs=rngs)\n",
    "\n",
    "    def __call__(self, x: Array):\n",
    "        x = x + self.layernorm(self.self_attention(x))\n",
    "        x = x + self.layernorm(self.mlp_layer(x))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patch mixer module\n",
    "class PatchMixer(nnx.Module):\n",
    "    def __init__(self, embed_dim, attn_heads, n_layers=2):\n",
    "        super().__init__()\n",
    "        layers = [\n",
    "            TransformerEncoderBlock(embed_dim, attn_heads) for _ in range(n_layers)\n",
    "        ]\n",
    "        self.encoder_layers = nnx.Sequential(*layers)\n",
    "\n",
    "    def __call__(self, x: Array) -> Array:\n",
    "        x = self.encoder_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "# Full Microdit model\n",
    "####################\n",
    "class MicroDiT(nnx.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        inchannels,\n",
    "        patch_size,\n",
    "        embed_dim,\n",
    "        num_layers,\n",
    "        attn_heads,\n",
    "        mlp_dim,\n",
    "        caption_embed_dim,\n",
    "        num_experts=4,\n",
    "        active_experts=2,\n",
    "        dropout=0.1,\n",
    "        patchmix_layers=2,\n",
    "        rngs=rngs,\n",
    "        num_classes=10,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "        self.patch_embedder = PatchEmbed(\n",
    "            rngs=rngs, patch_size=patch_size, in_chan=inchannels, embed_dim=embed_dim\n",
    "        )\n",
    "\n",
    "        # conditioning layers\n",
    "        self.time_embedder = TimestepEmbedder(embed_dim)\n",
    "        self.cap_embedder = CaptionEmbedder(caption_embed_dim, embed_dim)\n",
    "        self.label_embedder = LabelEmbedder(\n",
    "            num_classes=num_classes, hidden_size=embed_dim\n",
    "        )\n",
    "        self.cond_attention = CrossAttention(\n",
    "            attn_heads, embed_dim, caption_embed_dim, rngs=rngs\n",
    "        )\n",
    "        self.cond_mlp = SimpleMLP(embed_dim)\n",
    "\n",
    "        # pooling layer\n",
    "        self.pool_mlp = PoolMLP(embed_dim)\n",
    "\n",
    "        self.linear = nnx.Linear(self.embed_dim, self.embed_dim, rngs=rngs)\n",
    "\n",
    "        self.patch_mixer = PatchMixer(embed_dim, attn_heads, patchmix_layers)\n",
    "        self.ditbackbone = DiTBackbone(\n",
    "            patch_size=patch_size,\n",
    "            in_channels=inchannels,\n",
    "            hidden_size=embed_dim,\n",
    "            depth=num_layers,\n",
    "        )\n",
    "\n",
    "        self.outlin_1 = nnx.Linear(embed_dim, embed_dim, rngs=rngs)\n",
    "        self.final_linear = nnx.Linear(\n",
    "            embed_dim, patch_size[0] * patch_size[1] * inchannels, rngs=rngs\n",
    "        )\n",
    "\n",
    "    def __call__(self, x: Array, t: Array, y_cap: Array, mask=None):\n",
    "        bsize, channels, height, width = x.shape\n",
    "        psize_h, psize_w = self.patch_size\n",
    "\n",
    "        x = self.patch_embedder(x)\n",
    "\n",
    "        pos_embed = get_2d_sincos_pos_embed(self.embed_dim, height // psize_h)\n",
    "        pos_embed = jnp.expand_dims(pos_embed.to_device(x.device), axis=0)\n",
    "        pos_embed = jnp.broadcast_to(pos_embed, (bsize, -1, -1))\n",
    "        x = x + pos_embed\n",
    "\n",
    "        # cond_embed = self.cap_embedder(y_cap) # (b, embdim)\n",
    "        cond_embed = self.label_embedder(y_cap)\n",
    "        time_embed = self.time_embedder(t)\n",
    "        time_embed_unsqueeze = jnp.expand_dims(time_embed, axis=0)\n",
    "\n",
    "        mha_out = self.cond_attention(time_embed_unsqueeze, cond_embed).squeeze(axis=1)\n",
    "        mlp_out = self.cond_mlp(mha_out)\n",
    "\n",
    "        # pooling the conditions\n",
    "        pool_out = self.pool_mlp(jnp.expand_dims(mlp_out, axis=2))\n",
    "        pool_out = jnp.expand_dims((pool_out + time_embed), axis=1)\n",
    "\n",
    "        cond_signal = jnp.expand_dims(self.linear(mlp_out), axis=1)\n",
    "        cond_signal = jnp.broadcast_to(\n",
    "            (cond_signal + pool_out), shape=(-1, x.shape[1], -1)\n",
    "        )\n",
    "\n",
    "        x = x + cond_signal\n",
    "        x = self.patch_mixer(x)\n",
    "\n",
    "        if mask is not None:\n",
    "            x = remove_masked_patches(x, mask)\n",
    "\n",
    "        mlp_out_us = jnp.expand_dims(mlp_out, axis=1)  # unqueezed mlp output\n",
    "        cond = jnp.broadcast_to((mlp_out_us + pool_out), shape=(-1, x.shape[1], -1))\n",
    "\n",
    "        x = x + cond\n",
    "\n",
    "        x = self.ditbackbone(x, time_embed, cond_embed)\n",
    "\n",
    "        x = self.final_linear(x)\n",
    "\n",
    "        # add back masked patches\n",
    "        if mask is not None:\n",
    "            x = add_masked_patches(x, mask)\n",
    "\n",
    "        x = self.ditbackbone.unpatchify(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    # ahhhhhhhh, yess, full model\n",
    "    # wed_nov_13, 4:49\n",
    "\n",
    "    def sample(self, z_latent, cond, sample_steps=50, cfg=2.0):\n",
    "        b_size = z_latent.shape[0]\n",
    "        dt = 1.0 / sample_steps\n",
    "\n",
    "        dt = jnp.array([dt] * b_size)\n",
    "        dt = jnp.reshape(dt, shape=(b_size, *([1] * len(z_latent.shape[1:]))))\n",
    "\n",
    "        images = [z_latent]\n",
    "\n",
    "        for i in range(sample_steps, 0, -1):\n",
    "            t = i / sample_steps\n",
    "            t = (\n",
    "                jnp.array([t] * b_size)\n",
    "                .to_device(z_latent.device)\n",
    "                .astype(z_latent.dtype)\n",
    "            )\n",
    "\n",
    "            vc = self(z_latent, t, cond, None)\n",
    "            null_cond = jnp.zeros_like(cond)\n",
    "            vu = self.__call__(z_latent, t, null_cond)\n",
    "            vc = vu + cfg * (vc - vu)\n",
    "\n",
    "            z = z_latent - dt * vc\n",
    "            images.append(z)\n",
    "\n",
    "        return images[-1] / config.vaescale_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rectifed flow forward pass, loss, and smapling\n",
    "class RectFlow:\n",
    "    def __init__(self, model: nnx.Module, sigln: bool = True):\n",
    "        self.model = model\n",
    "        self.sigln = sigln\n",
    "\n",
    "    def __call__(self, x_input: Array, cond: Array) -> Array:\n",
    "\n",
    "        b_size = x_input.shape[0]  # batch_sie\n",
    "        rand_t = None\n",
    "\n",
    "        if self.sigln:\n",
    "            rand = jrand.normal(randkey, (b_size,)).to_device(x_input.device)\n",
    "            rand_t = nnx.sigmoid(rand)\n",
    "        else:\n",
    "            rand_t = jrand.normal(randkey, (b_size,)).to_device(x_input.device)\n",
    "\n",
    "        inshape = [1] * len(x_input.shape[1:])\n",
    "        texp = rand_t.reshape([b_size, *(inshape)])\n",
    "\n",
    "        z_noise = jrand.normal(\n",
    "            randkey, x_input.shape\n",
    "        )  # input noise with same dim as image\n",
    "        z_noise_t = (1 - texp) * x_input + texp * z_noise\n",
    "\n",
    "        v_thetha = self.model(z_noise_t, rand_t, cond)\n",
    "\n",
    "        mean_dim = list(\n",
    "            range(1, len(x_input.shape))\n",
    "        )  # across all dimensions except the batch dim\n",
    "        mean_square = (z_noise - x_input - v_thetha) ** 2  # squared difference\n",
    "        batchwise_mse_loss = jnp.mean(mean_square, axis=mean_dim)  # mean loss\n",
    "\n",
    "        return jnp.mean(batchwise_mse_loss)\n",
    "\n",
    "    def sample(\n",
    "        self,\n",
    "        input_noise: jax.Array,\n",
    "        cond,\n",
    "        zero_cond=None,\n",
    "        sample_steps: int = 50,\n",
    "        cfg=2.0,\n",
    "    ) -> List[jax.Array]:\n",
    "\n",
    "        batch_size = input_noise.shape[0]\n",
    "\n",
    "        # array reciprocal of sampling steps\n",
    "        d_steps = 1.0 / sample_steps\n",
    "\n",
    "        d_steps = jnp.array([d_steps] * batch_size).to_device(input_noise.device)\n",
    "        steps_dim = [1] * len(input_noise.shape[1:])\n",
    "        d_steps = d_steps.reshape([batch_size], *steps_dim)\n",
    "\n",
    "        images = [input_noise]  # noise sequence\n",
    "\n",
    "        for t_step in range(sample_steps):\n",
    "\n",
    "            genstep = t_step / sample_steps  # current step\n",
    "\n",
    "            genstep_batched = jnp.array([genstep] * batch_size).to_device(\n",
    "                input_noise.device\n",
    "            )\n",
    "\n",
    "            cond_output = self.model(\n",
    "                input_noise, genstep_batched, cond\n",
    "            )  # get model output for step\n",
    "\n",
    "            if zero_cond is not None:\n",
    "                # output for zero conditioning\n",
    "                uncond_output = self.model(input_noise, genstep_batched, zero_cond)\n",
    "                cond_output = uncond_output + cfg * (cond_output - uncond_output)\n",
    "\n",
    "            out_noise = input_noise - d_steps * cond_output\n",
    "\n",
    "            images.append(out_noise)\n",
    "\n",
    "        return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = MicroDiT(\n",
    "    inchannels=3,\n",
    "    patch_size=(4, 4),\n",
    "    embed_dim=1024,\n",
    "    num_layers=12,\n",
    "    attn_heads=6,\n",
    "    mlp_dim=4 * 1024,\n",
    "    caption_embed_dim=768,\n",
    ")\n",
    "\n",
    "rf_engine = RectFlow(model)\n",
    "optimizer = nnx.Optimizer(rf_engine.model, optax.adamw(learning_rate=config.lr))\n",
    "\n",
    "# def preprocess_image(image_array):\n",
    "\n",
    "def wandb_logger(key: str, project_name, run_name):  # wandb logger\n",
    "    # initilaize wandb\n",
    "    wandb.login(key=key)\n",
    "    wandb.init(project=project_name, name=run_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(model, batch):\n",
    "    img_latents, label = batch\n",
    "    bs, channels, height, width = img_latents.shape\n",
    "    print(img_latents.shape)\n",
    "\n",
    "    img_latents = img_latents * config.vaescale_factor\n",
    "    mask = random_mask(\n",
    "        bs, height, width, patch_size=config.patch_size, mask_ratio=config.mask_ratio\n",
    "    ).to_device(img_latents.device)\n",
    "    loss = model(img_latents, label, mask)\n",
    "    # loss = optax.squared_error(img_latents, logits).mean()\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "@nnx.jit\n",
    "def train_step(model, optimizer, batch):\n",
    "    gradfn = nnx.value_and_grad(loss_func, has_aux=True)\n",
    "    (loss, logits), grads = gradfn(model, batch)\n",
    "    optimizer.update(grads)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def sample_images(model, vae, noise, embeddings):\n",
    "    # Use the stored embeddings\n",
    "    sampled_latents = model.sample(noise, embeddings)\n",
    "\n",
    "    # Decode latents to images\n",
    "    sampled_images = vae.decode(sampled_latents).sample\n",
    "    # images = sample_images\n",
    "    return sampled_images\n",
    "\n",
    "\n",
    "def trainer(model=rf_engine, optimizer=optimizer, train_loader=train_loader):\n",
    "    epochs = 2\n",
    "    train_loss = 0.0\n",
    "    model.model.train()\n",
    "    # wandb_logger(\n",
    "    #     key=None,\n",
    "    #     model=model,\n",
    "    #     project_name=\"transformer_playjax\",\n",
    "    #     run_name=\"tinygpt-1e-4-bs32-tpu\",\n",
    "    # )\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        for step, batch in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "\n",
    "            train_loss = train_step(model, optimizer, batch)\n",
    "            print(f\"step {step}, loss-> {train_loss.item():.4f}\")\n",
    "\n",
    "            # if step % 100 == 0:\n",
    "            #     sample_latents = model.sample()\n",
    "\n",
    "            # wandb.log({\"loss\": train_loss.item()})\n",
    "\n",
    "        print(f\"epoch {epoch+1}, train loss => {train_loss}\")\n",
    "\n",
    "\n",
    "trainer()\n",
    "# wandb.finish()\n",
    "print(\"microdit test training in JAX\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
